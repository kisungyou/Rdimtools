
@incollection{hinton_stochastic_2003,
	title = {Stochastic {Neighbor} {Embedding}},
	url = {http://papers.nips.cc/paper/2276-stochastic-neighbor-embedding.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 15},
	publisher = {MIT Press},
	author = {Hinton, Geoffrey E. and Roweis, Sam T.},
	editor = {Becker, S. and Thrun, S. and Obermayer, K.},
	year = {2003},
	pages = {857--864},
	file = {[Hinton.2003] Stochastic Neighbor Embedding.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/02. tSNE/[Hinton.2003] Stochastic Neighbor Embedding.pdf:application/pdf}
}

@article{belkin_laplacian_2003,
	title = {Laplacian {Eigenmaps} for {Dimensionality} {Reduction} and {Data} {Representation}},
	volume = {15},
	issn = {0899-7667, 1530-888X},
	url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976603321780317},
	doi = {10.1162/089976603321780317},
	language = {en},
	number = {6},
	urldate = {2016-06-19},
	journal = {Neural Computation},
	author = {Belkin, Mikhail and Niyogi, Partha},
	month = jun,
	year = {2003},
	pages = {1373--1396},
	file = {[Belkin.2003] Laplacian Eigenmaps for Dimensionality Reduction and Data Representation.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/03. LAPEIG/[Belkin.2003] Laplacian Eigenmaps for Dimensionality Reduction and Data Representation.pdf:application/pdf}
}

@article{coifman_diffusion_2006,
	title = {Diffusion maps},
	volume = {21},
	issn = {10635203},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1063520306000546},
	doi = {10.1016/j.acha.2006.04.006},
	language = {en},
	number = {1},
	urldate = {2016-07-04},
	journal = {Applied and Computational Harmonic Analysis},
	author = {Coifman, Ronald R. and Lafon, Stéphane},
	month = jul,
	year = {2006},
	pages = {5--30},
	file = {[Coifman_Lafon.2006] Diffusion maps.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/01. DM/[Coifman_Lafon.2006] Diffusion maps.pdf:application/pdf}
}

@article{van_der_maaten_visualizing_2008,
	title = {Visualizing data using t-{SNE}},
	volume = {9},
	number = {2579-2605},
	journal = {The Journal of Machine Learning Research},
	author = {van der Maaten, Laurens and Hinton, Geoffrey},
	year = {2008},
	pages = {85},
	file = {[van der Maaten.2008] Visualizing data using t-SNE.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/02. tSNE/[van der Maaten.2008] Visualizing data using t-SNE.pdf:application/pdf}
}

@article{van_der_maaten_learning_2009,
	title = {Learning a parametric embedding by preserving local structure},
	journal = {Proceedings of AI-STATS},
	author = {van der Maaten, Laurens},
	year = {2009},
	file = {[van der Maaten.2009] Learning a parametric embedding by preserving local structure.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/02. tSNE/[van der Maaten.2009] Learning a parametric embedding by preserving local structure.pdf:application/pdf}
}

@article{pearson_liii._1901,
	title = {{LIII}. {On} lines and planes of closest fit to systems of points in space},
	volume = {2},
	issn = {1941-5982, 1941-5990},
	url = {http://www.tandfonline.com/doi/abs/10.1080/14786440109462720},
	doi = {10.1080/14786440109462720},
	language = {en},
	number = {11},
	urldate = {2016-07-04},
	journal = {Philosophical Magazine Series 6},
	author = {Pearson, Karl},
	month = nov,
	year = {1901},
	pages = {559--572},
	file = {[Pearson.1901] LIII.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/03. PCA/[Pearson.1901] LIII.pdf:application/pdf}
}

@article{von_luxburg_tutorial_2007,
	title = {A tutorial on spectral clustering},
	volume = {17},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-007-9033-z},
	doi = {10.1007/s11222-007-9033-z},
	language = {en},
	number = {4},
	urldate = {2016-10-13},
	journal = {Statistics and Computing},
	author = {von Luxburg, Ulrike},
	month = dec,
	year = {2007},
	keywords = {Artificial Intelligence (incl. Robotics), Graph Laplacian, Mathematics, general, Numeric Computing, Spectral clustering, Statistics and Computing/Statistics Programs, Statistics, general},
	pages = {395--416},
	file = {[Luxburg.2007] A tutorial on spectral clustering.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/[Luxburg.2007] A tutorial on spectral clustering.pdf:application/pdf;[von Luxburg.2007] A tutorial on spectral clustering.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P3. SGT/S1. Basics/[von Luxburg.2007] A tutorial on spectral clustering.pdf:application/pdf;Snapshot:/home/kisung/.mozilla/firefox/7xt7fha3.default/zotero/storage/J2HE79IQ/s11222-007-9033-z.html:text/html}
}

@inproceedings{belkin_convergence_2006,
	title = {Convergence of laplacian eigenmaps},
	booktitle = {In {NIPS}},
	author = {Belkin, Mikhail and Niyogi, Partha},
	year = {2006},
	file = {[Belkin.2006] Convergence of laplacian eigenmaps.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/03. LAPEIG/[Belkin.2006] Convergence of laplacian eigenmaps.pdf:application/pdf}
}

@article{van_der_maaten_dimensionality_2009,
	title = {Dimensionality reduction: {A} comparative review},
	journal = {Technical Report TiCC TR 2009-005},
	author = {Van der Maaten, LJP and Postma, EO and Van den Herik, HJ},
	year = {2009},
	file = {[Van der Maaten.2009] Dimensionality reduction.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/[Van der Maaten.2009] Dimensionality reduction.pdf:application/pdf}
}

@inproceedings{bengio_out--sample_2003,
	title = {Out-of-{Sample} {Extensions} for {LLE}, {Isomap}, {MDS}, {Eigenmaps}, and {Spectral} {Clustering}},
	url = {http://papers.nips.cc/paper/2461-out-of-sample-extensions-for-lle-isomap-mds-eigenmaps-and-spectral-clustering},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 16 [{Neural} {Information} {Processing} {Systems}, {NIPS} 2003, {December} 8-13, 2003, {Vancouver} and {Whistler}, {British} {Columbia}, {Canada}]},
	author = {Bengio, Yoshua and Paiement, Jean-François and Vincent, Pascal and Delalleau, Olivier and Roux, Nicolas Le and Ouimet, Marie},
	year = {2003},
	pages = {177--184},
	file = {[Bengio.2003] Out-of-Sample Extensions for LLE, Isomap, MDS, Eigenmaps, and Spectral.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S3. Notes/[Bengio.2003] Out-of-Sample Extensions for LLE, Isomap, MDS, Eigenmaps, and Spectral.pdf:application/pdf}
}

@article{coifman_geometric_2005,
	title = {Geometric diffusions as a tool for harmonic analysis and structure definition of data: {Multiscale} methods},
	volume = {102},
	issn = {0027-8424, 1091-6490},
	shorttitle = {Geometric diffusions as a tool for harmonic analysis and structure definition of data},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0500896102},
	doi = {10.1073/pnas.0500896102},
	language = {en},
	number = {21},
	urldate = {2016-07-04},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Coifman, R. R. and Lafon, S. and Lee, A. B. and Maggioni, M. and Nadler, B. and Warner, F. and Zucker, S. W.},
	month = may,
	year = {2005},
	pages = {7432--7437},
	file = {[Coifman.2005] Geometric diffusions as a tool for harmonic analysis and structure definition.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/01. DM/[Coifman.2005] Geometric diffusions as a tool for harmonic analysis and structure definition.pdf:application/pdf}
}

@article{roweis_nonlinear_2000,
	title = {Nonlinear {Dimensionality} {Reduction} by {Locally} {Linear} {Embedding}},
	volume = {290},
	issn = {00368075, 10959203},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.290.5500.2323},
	doi = {10.1126/science.290.5500.2323},
	number = {5500},
	urldate = {2016-06-19},
	journal = {Science},
	author = {Roweis, S. T.},
	month = dec,
	year = {2000},
	pages = {2323--2326},
	file = {[Roweis.2000] Nonlinear Dimensionality Reduction by Locally Linear Embedding.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/[Roweis.2000] Nonlinear Dimensionality Reduction by Locally Linear Embedding.pdf:application/pdf}
}

@article{lee_landmark_2009,
	title = {Landmark {MDS} ensemble},
	volume = {42},
	issn = {00313203},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308005049},
	doi = {10.1016/j.patcog.2008.11.039},
	language = {en},
	number = {9},
	urldate = {2017-05-15},
	journal = {Pattern Recognition},
	author = {Lee, Seunghak and Choi, Seungjin},
	month = sep,
	year = {2009},
	pages = {2045--2053},
	file = {[Lee_Choi.2009] Landmark MDS ensemble.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/13. LMDS/[Lee_Choi.2009] Landmark MDS ensemble.pdf:application/pdf}
}

@incollection{silva_global_2002,
	address = {Cambridge, MA},
	title = {Global {Versus} {Local} {Methods} in {Nonlinear} {Dimensionality} {Reduction}},
	url = {http://books.nips.cc/papers/files/nips15/AA28.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 15},
	publisher = {MIT Press},
	author = {Silva, Vin D. and Tenenbaum, Joshua B.},
	editor = {Thrun, S. and Obermayer, K.},
	year = {2002},
	pages = {705--712},
	file = {[Silva_Tenenbaum.2002] Global Versus Local Methods in Nonlinear Dimensionality Reduction.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/13. LMDS/[Silva_Tenenbaum.2002] Global Versus Local Methods in Nonlinear Dimensionality Reduction.pdf:application/pdf}
}

@incollection{goos_kernel_1997,
	address = {Berlin, Heidelberg},
	title = {Kernel principal component analysis},
	volume = {1327},
	isbn = {978-3-540-63631-1 978-3-540-69620-9},
	url = {http://link.springer.com/10.1007/BFb0020217},
	urldate = {2017-05-16},
	booktitle = {Artificial {Neural} {Networks} — {ICANN}'97},
	publisher = {Springer Berlin Heidelberg},
	author = {Schölkopf, Bernhard and Smola, Alexander and Müller, Klaus-Robert},
	editor = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Gerstner, Wulfram and Germond, Alain and Hasler, Martin and Nicoud, Jean-Daniel},
	year = {1997},
	note = {DOI: 10.1007/BFb0020217},
	pages = {583--588},
	file = {[Schölkopf.1997] Kernel principal component analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/10. KPCA/[Schölkopf.1997] Kernel principal component analysis.pdf:application/pdf}
}

@article{sammon_nonlinear_1969,
	title = {A {Nonlinear} {Mapping} for {Data} {Structure} {Analysis}},
	volume = {C-18},
	issn = {0018-9340},
	url = {http://ieeexplore.ieee.org/document/1671271/},
	doi = {10.1109/T-C.1969.222678},
	number = {5},
	urldate = {2017-05-19},
	journal = {IEEE Transactions on Computers},
	author = {Sammon, J.W.},
	month = may,
	year = {1969},
	pages = {401--409},
	file = {[Sammon.1969] A Nonlinear Mapping for Data Structure Analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/11. Sammon/[Sammon.1969] A Nonlinear Mapping for Data Structure Analysis.pdf:application/pdf}
}

@article{weinberger_unsupervised_2006,
	title = {Unsupervised {Learning} of {Image} {Manifolds} by {Semidefinite} {Programming}},
	volume = {70},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/10.1007/s11263-005-4939-z},
	doi = {10.1007/s11263-005-4939-z},
	language = {en},
	number = {1},
	urldate = {2017-05-19},
	journal = {International Journal of Computer Vision},
	author = {Weinberger, Kilian Q. and Saul, Lawrence K.},
	month = oct,
	year = {2006},
	pages = {77--90},
	file = {[Weinberger.2006] Unsupervised Learning of Image Manifolds by Semidefinite Programming.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/07. MVU/[Weinberger.2006] Unsupervised Learning of Image Manifolds by Semidefinite Programming.pdf:application/pdf}
}

@article{camastra_data_2003,
	title = {Data dimensionality estimation methods: a survey},
	volume = {36},
	issn = {00313203},
	shorttitle = {Data dimensionality estimation methods},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320303001766},
	doi = {10.1016/S0031-3203(03)00176-6},
	language = {en},
	number = {12},
	urldate = {2017-05-19},
	journal = {Pattern Recognition},
	author = {Camastra, Francesco},
	month = dec,
	year = {2003},
	pages = {2945--2954},
	file = {[Camastra.2003] Data dimensionality estimation methods.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S4. Estimation/[Camastra.2003] Data dimensionality estimation methods.pdf:application/pdf}
}

@article{pestov_axiomatic_2008,
	title = {An axiomatic approach to intrinsic dimension of a dataset},
	volume = {21},
	issn = {08936080},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0893608007002511},
	doi = {10.1016/j.neunet.2007.12.030},
	language = {en},
	number = {2-3},
	urldate = {2017-05-19},
	journal = {Neural Networks},
	author = {Pestov, Vladimir},
	month = mar,
	year = {2008},
	pages = {204--213},
	file = {[Pestov.2008] An axiomatic approach to intrinsic dimension of a dataset.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S4. Estimation/[Pestov.2008] An axiomatic approach to intrinsic dimension of a dataset.pdf:application/pdf}
}

@article{grassberger_measuring_1983,
	title = {Measuring the strangeness of strange attractors},
	volume = {9},
	issn = {01672789},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0167278983902981},
	doi = {10.1016/0167-2789(83)90298-1},
	language = {en},
	number = {1-2},
	urldate = {2017-05-21},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Grassberger, Peter and Procaccia, Itamar},
	month = oct,
	year = {1983},
	pages = {189--208},
	file = {[Grassberger.1983] Measuring the strangeness of strange attractors.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S4. Estimation/2. correlation/[Grassberger.1983] Measuring the strangeness of strange attractors.pdf:application/pdf}
}

@article{granata_accurate_2016,
	title = {Accurate {Estimation} of the {Intrinsic} {Dimension} {Using} {Graph} {Distances}: {Unraveling} the {Geometric} {Complexity} of {Datasets}},
	volume = {6},
	issn = {2045-2322},
	shorttitle = {Accurate {Estimation} of the {Intrinsic} {Dimension} {Using} {Graph} {Distances}},
	url = {http://www.nature.com/articles/srep31377},
	doi = {10.1038/srep31377},
	language = {en},
	number = {1},
	urldate = {2017-05-20},
	journal = {Scientific Reports},
	author = {Granata, Daniele and Carnevale, Vincenzo},
	month = nov,
	year = {2016},
	file = {[Granata.2016] Accurate Estimation of the Intrinsic Dimension Using Graph Distances.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S4. Estimation/3. graph distance/[Granata.2016] Accurate Estimation of the Intrinsic Dimension Using Graph Distances.pdf:application/pdf}
}

@article{camastra_intrinsic_2016,
	title = {Intrinsic dimension estimation: {Advances} and open problems},
	volume = {328},
	issn = {00200255},
	shorttitle = {Intrinsic dimension estimation},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0020025515006179},
	doi = {10.1016/j.ins.2015.08.029},
	language = {en},
	urldate = {2017-05-21},
	journal = {Information Sciences},
	author = {Camastra, Francesco and Staiano, Antonino},
	month = jan,
	year = {2016},
	pages = {26--41},
	file = {[Camastra.2016] Intrinsic dimension estimation.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S4. Estimation/[Camastra.2016] Intrinsic dimension estimation.pdf:application/pdf}
}

@book{ott_chaos_2002,
	address = {Cambridge, U.K. ; New York},
	edition = {2nd ed},
	title = {Chaos in dynamical systems},
	isbn = {978-0-521-81196-5 978-0-521-01084-9},
	publisher = {Cambridge University Press},
	author = {Ott, Edward},
	year = {2002},
	keywords = {Chaotic behavior in systems}
}

@book{ma_manifold_2012,
	address = {Boca Raton, Fla. : London},
	title = {Manifold learning theory and applications},
	isbn = {978-1-4398-7109-6},
	publisher = {CRC ; Taylor \& Francis [distributor]},
	editor = {Ma, Yunqian and Fu, Yun},
	year = {2012},
	note = {OCLC: ocn751753027},
	keywords = {Manifolds (Mathematics)},
	file = {[Ma.2012] Manifold learning theory and applications.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/[Ma.2012] Manifold learning theory and applications.pdf:application/pdf}
}

@article{spearman_general_1904,
	title = {"{General} {Intelligence}," {Objectively} {Determined} and {Measured}},
	volume = {15},
	issn = {00029556},
	url = {http://www.jstor.org/stable/1412107?origin=crossref},
	doi = {10.2307/1412107},
	number = {2},
	urldate = {2017-05-22},
	journal = {The American Journal of Psychology},
	author = {Spearman, C.},
	month = apr,
	year = {1904},
	pages = {201},
	file = {[Spearman.1904] General Intelligence, Objectively Determined and Measured.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/05. FA/[Spearman.1904] General Intelligence, Objectively Determined and Measured.pdf:application/pdf}
}

@article{sorzano_survey_2014,
	title = {A survey of dimensionality reduction techniques},
	journal = {ArXiv e-prints},
	author = {Sorzano, C. O. S. and Vargas, J. and Montano, A. P.},
	year = {2014},
	keywords = {Computer Science - Learning, Statistics - Machine Learning, Quantitative Biology - Quantitative Methods},
	file = {[Sorzano.2014] A survey of dimensionality reduction techniques.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/[Sorzano.2014] A survey of dimensionality reduction techniques.pdf:application/pdf}
}

@inproceedings{he_neighborhood_2005,
	address = {Washington, DC, USA},
	series = {{ICCV} '05},
	title = {Neighborhood {Preserving} {Embedding}},
	isbn = {0-7695-2334-X-02},
	url = {http://dx.doi.org/10.1109/ICCV.2005.167},
	doi = {10.1109/ICCV.2005.167},
	booktitle = {Proceedings of the {Tenth} {IEEE} {International} {Conference} on {Computer} {Vision} - {Volume} 2},
	publisher = {IEEE Computer Society},
	author = {He, Xiaofei and Cai, Deng and Yan, Shuicheng and Zhang, Hong-Jiang},
	year = {2005},
	pages = {1208--1213},
	file = {[He.2005] Neighborhood Preserving Embedding.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/08. NPE/[He.2005] Neighborhood Preserving Embedding.pdf:application/pdf}
}

@phdthesis{he_locality_2005,
	address = {Chicago, IL, USA},
	title = {Locality {Preserving} {Projections}},
	school = {University of Chicago},
	author = {He, Xiaofei},
	year = {2005},
	file = {[He.2005] Locality Preserving Projections.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/07. LPP/[He.2005] Locality Preserving Projections.pdf:application/pdf}
}

@article{hotelling_analysis_1933,
	title = {Analysis of a complex of statistical variables into principal components.},
	volume = {24},
	issn = {0022-0663},
	url = {http://content.apa.org/journals/edu/24/6/417},
	doi = {10.1037/h0071325},
	language = {en},
	number = {6},
	urldate = {2017-05-25},
	journal = {Journal of Educational Psychology},
	author = {Hotelling, H.},
	year = {1933},
	pages = {417--441}
}

@article{kruskal_multidimensional_1964,
	title = {Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis},
	volume = {29},
	issn = {0033-3123, 1860-0980},
	url = {http://link.springer.com/10.1007/BF02289565},
	doi = {10.1007/BF02289565},
	language = {en},
	number = {1},
	urldate = {2017-05-25},
	journal = {Psychometrika},
	author = {Kruskal, J. B.},
	month = mar,
	year = {1964},
	pages = {1--27},
	file = {[Kruskal.1964] Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/02. MDS/[Kruskal.1964] Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis.pdf:application/pdf}
}

@incollection{beals_extensions_1984,
	address = {Providence, Rhode Island},
	title = {Extensions of {Lipschitz} mappings into a {Hilbert} space},
	volume = {26},
	isbn = {978-0-8218-5030-5 978-0-8218-7611-4},
	url = {http://www.ams.org/conm/026/},
	language = {en},
	urldate = {2017-05-25},
	booktitle = {Contemporary {Mathematics}},
	publisher = {American Mathematical Society},
	author = {Johnson, William B. and Lindenstrauss, Joram},
	editor = {Beals, Richard and Beck, Anatole and Bellow, Alexandra and Hajian, Arshag},
	year = {1984},
	note = {DOI: 10.1090/conm/026/737400},
	pages = {189--206},
	file = {[Johnson_Lindenstrauss.1984] Extensions of Lipschitz mappings into a Hilbert space.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/04. RNDPROJ/[Johnson_Lindenstrauss.1984] Extensions of Lipschitz mappings into a Hilbert space.pdf:application/pdf}
}

@article{zhang_principal_2004,
	title = {Principal {Manifolds} and {Nonlinear} {Dimensionality} {Reduction} via {Tangent} {Space} {Alignment}},
	volume = {26},
	issn = {1064-8275, 1095-7197},
	url = {http://epubs.siam.org/doi/10.1137/S1064827502419154},
	doi = {10.1137/S1064827502419154},
	language = {en},
	number = {1},
	urldate = {2017-05-27},
	journal = {SIAM Journal on Scientific Computing},
	author = {Zhang, Zhenyue and Zha, Hongyuan},
	month = jan,
	year = {2004},
	pages = {313--338},
	file = {[Zhang.2004] Principal Manifolds and Nonlinear Dimensionality Reduction via Tangent Space.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/14. LTSA/[Zhang.2004] Principal Manifolds and Nonlinear Dimensionality Reduction via Tangent Space.pdf:application/pdf}
}

@article{zhang_linear_2007,
	title = {Linear local tangent space alignment and application to face recognition},
	volume = {70},
	issn = {09252312},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231206004577},
	doi = {10.1016/j.neucom.2006.11.007},
	language = {en},
	number = {7-9},
	urldate = {2017-05-27},
	journal = {Neurocomputing},
	author = {Zhang, Tianhao and Yang, Jie and Zhao, Deli and Ge, Xinliang},
	month = mar,
	year = {2007},
	pages = {1547--1553},
	file = {[Zhang.2007] Linear local tangent space alignment and application to face recognition.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/09. LLTSA/[Zhang.2007] Linear local tangent space alignment and application to face recognition.pdf:application/pdf}
}

@article{achlioptas_database-friendly_2003,
	title = {Database-friendly random projections: {Johnson}-{Lindenstrauss} with binary coins},
	volume = {66},
	issn = {00220000},
	shorttitle = {Database-friendly random projections},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0022000003000254},
	doi = {10.1016/S0022-0000(03)00025-4},
	language = {en},
	number = {4},
	urldate = {2017-06-06},
	journal = {Journal of Computer and System Sciences},
	author = {Achlioptas, Dimitris},
	month = jun,
	year = {2003},
	pages = {671--687},
	file = {[Achlioptas.2003] Database-friendly random projections.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/04. RNDPROJ/[Achlioptas.2003] Database-friendly random projections.pdf:application/pdf}
}

@inproceedings{porte_introduction_2008,
	title = {An introduction to diffusion maps},
	booktitle = {In {The} 19th {Symposium} of the {Pattern} {Recognition} {Association} of {South} {Africa}},
	author = {Porte, J. De La and Herbst, B. M. and Hereman, W. and Walt, S. J. Van Der},
	year = {2008},
	file = {[Porte.2008] An introduction to diffusion maps.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/01. DM/[Porte.2008] An introduction to diffusion maps.pdf:application/pdf}
}

@inproceedings{nadler_diffusion_2005,
	address = {Cambridge, MA, USA},
	series = {{NIPS}'05},
	title = {Diffusion {Maps}, {Spectral} {Clustering} and {Eigenfunctions} of {Fokker}-{Planck} {Operators}},
	url = {http://dl.acm.org/citation.cfm?id=2976248.2976368},
	booktitle = {Proceedings of the 18th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Nadler, Boaz and Lafon, Stéphane and Coifman, Ronald R. and Kevrekidis, Ioannis G.},
	year = {2005},
	keywords = {algorithms and architectures, learning theory},
	pages = {955--962},
	file = {[Nadler.2005] Diffusion Maps, Spectral Clustering and Eigenfunctions of Fokker-Planck.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/01. DM/[Nadler.2005] Diffusion Maps, Spectral Clustering and Eigenfunctions of Fokker-Planck.pdf:application/pdf}
}

@article{paulovich_piece_2011,
	title = {Piece wise {Laplacian}-based {Projection} for {Interactive} {Data} {Exploration} and {Organization}},
	volume = {30},
	issn = {01677055},
	url = {http://doi.wiley.com/10.1111/j.1467-8659.2011.01958.x},
	doi = {10.1111/j.1467-8659.2011.01958.x},
	language = {en},
	number = {3},
	urldate = {2017-06-17},
	journal = {Computer Graphics Forum},
	author = {Paulovich, F.V. and Eler, D.M. and Poco, J. and Botha, C.P. and Minghim, R. and Nonato, L.G.},
	month = jun,
	year = {2011},
	pages = {1091--1100},
	file = {[Paulovich.2011] Piece wise Laplacian-based Projection for Interactive Data Exploration and.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/39. PLP/[Paulovich.2011] Piece wise Laplacian-based Projection for Interactive Data Exploration and.pdf:application/pdf}
}

@article{jenssen_kernel_2010,
	title = {Kernel {Entropy} {Component} {Analysis}},
	volume = {32},
	issn = {0162-8828},
	url = {http://ieeexplore.ieee.org/document/4912217/},
	doi = {10.1109/TPAMI.2009.100},
	number = {5},
	urldate = {2017-11-11},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Jenssen, R.},
	month = may,
	year = {2010},
	pages = {847--860},
	file = {[Jenssen.2010] Kernel Entropy Component Analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/43. KECA/[Jenssen.2010] Kernel Entropy Component Analysis.pdf:application/pdf}
}

@book{hyvarinen_independent_2001,
	address = {New York},
	title = {Independent component analysis},
	isbn = {978-0-471-40540-5},
	publisher = {J. Wiley},
	author = {Hyvarinen, Aapo and Karhunen, Juha and Oja, Erkki},
	year = {2001},
	keywords = {Independent component analysis},
	file = {[Hyvarinen.2001] Independent component analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/01. ICA/[Hyvarinen.2001] Independent component analysis.pdf:application/pdf}
}

@article{fisher_use_1936,
	title = {{THE} {USE} {OF} {MULTIPLE} {MEASUREMENTS} {IN} {TAXONOMIC} {PROBLEMS}},
	volume = {7},
	issn = {20501420},
	url = {http://doi.wiley.com/10.1111/j.1469-1809.1936.tb02137.x},
	doi = {10.1111/j.1469-1809.1936.tb02137.x},
	language = {en},
	number = {2},
	urldate = {2017-11-11},
	journal = {Annals of Eugenics},
	author = {Fisher, R. A.},
	month = sep,
	year = {1936},
	pages = {179--188},
	file = {[Fisher.1936] THE USE OF MULTIPLE MEASUREMENTS IN TAXONOMIC PROBLEMS.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/06. LDA/[Fisher.1936] THE USE OF MULTIPLE MEASUREMENTS IN TAXONOMIC PROBLEMS.pdf:application/pdf}
}

@book{fukunaga_introduction_1990,
	address = {Boston},
	edition = {2nd ed},
	series = {Computer science and scientific computing},
	title = {Introduction to statistical pattern recognition},
	isbn = {978-0-12-269851-4},
	publisher = {Academic Press},
	author = {Fukunaga, Keinosuke},
	year = {1990},
	keywords = {Mathematical models, Mathematical statistics, Pattern perception, Decision making, Statistical methods},
	file = {[Fukunaga.1990] Introduction to statistical pattern recognition.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/06. LDA/[Fukunaga.1990] Introduction to statistical pattern recognition.pdf:application/pdf}
}

@inproceedings{li_very_2006,
	address = {New York, NY, USA},
	series = {{KDD} '06},
	title = {Very {Sparse} {Random} {Projections}},
	isbn = {1-59593-339-5},
	url = {http://doi.acm.org/10.1145/1150402.1150436},
	doi = {10.1145/1150402.1150436},
	booktitle = {Proceedings of the 12th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Li, Ping and Hastie, Trevor J. and Church, Kenneth W.},
	year = {2006},
	keywords = {random projections, rates of convergence, sampling},
	pages = {287--296},
	file = {[Li.2006] Very Sparse Random Projections.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/04. RNDPROJ/[Li.2006] Very Sparse Random Projections.pdf:application/pdf}
}

@incollection{silva_global_2003,
	title = {Global {Versus} {Local} {Methods} in {Nonlinear} {Dimensionality} {Reduction}},
	url = {http://papers.nips.cc/paper/2141-global-versus-local-methods-in-nonlinear-dimensionality-reduction.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 15},
	publisher = {MIT Press},
	author = {Silva, Vin D. and Tenenbaum, Joshua B.},
	editor = {Becker, S. and Thrun, S. and Obermayer, K.},
	year = {2003},
	pages = {721--728},
	file = {[Silva_Tenenbaum.2003] Global Versus Local Methods in Nonlinear Dimensionality Reduction.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/05. LLE/[Silva_Tenenbaum.2003] Global Versus Local Methods in Nonlinear Dimensionality Reduction.pdf:application/pdf}
}

@inproceedings{cayton_robust_2006,
	address = {New York, NY, USA},
	series = {{ICML} '06},
	title = {Robust {Euclidean} {Embedding}},
	isbn = {1-59593-383-2},
	url = {http://doi.acm.org/10.1145/1143844.1143866},
	doi = {10.1145/1143844.1143866},
	booktitle = {Proceedings of the 23rd {International} {Conference} on {Machine} {Learning}},
	publisher = {ACM},
	author = {Cayton, Lawrence and Dasgupta, Sanjoy},
	year = {2006},
	pages = {169--176},
	file = {[Cayton_Dasgupta.2006] Robust Euclidean Embedding.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/27. REE/[Cayton_Dasgupta.2006] Robust Euclidean Embedding.pdf:application/pdf}
}

@inproceedings{walder_diffeomorphic_2009,
	address = {Red Hook, NY, USA},
	title = {Diffeomorphic {Dimensionality} {Reduction}},
	booktitle = {Advances in neural information processing systems 21},
	publisher = {Biologische Kybernetik},
	author = {Walder, C. and Schölkopf, B.},
	year = {2009},
	pages = {1713--1720},
	file = {[Walder_Schölkopf.2009] Diffeomorphic Dimensionality Reduction.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/04. DDR/[Walder_Schölkopf.2009] Diffeomorphic Dimensionality Reduction.pdf:application/pdf}
}

@article{noonan_nipals_1977,
	title = {{NIPALS} {Path} {Modelling} with {Latent} {Variables}: {Analysing} {School} {Survey} {Data} {Using} {Nonlinear} {Iterative} {Partial} {Least} {Squares} $^{\textrm{1}}$},
	volume = {21},
	issn = {0031-3831, 1470-1170},
	shorttitle = {{NIPALS} {Path} {Modelling} with {Latent} {Variables}},
	url = {http://www.tandfonline.com/doi/full/10.1080/0031383770210103},
	doi = {10.1080/0031383770210103},
	language = {en},
	number = {1},
	urldate = {2017-11-21},
	journal = {Scandinavian Journal of Educational Research},
	author = {Noonan, Richard and Wold, Herman},
	month = jan,
	year = {1977},
	pages = {33--61}
}

@incollection{wold_path_1975,
	title = {Path {Models} with {Latent} {Variables}: {The} {NIPALS} {Approach}},
	isbn = {978-0-12-103950-9},
	shorttitle = {Path {Models} with {Latent} {Variables}},
	url = {http://linkinghub.elsevier.com/retrieve/pii/B9780121039509500174},
	language = {en},
	urldate = {2017-11-21},
	booktitle = {Quantitative {Sociology}},
	publisher = {Elsevier},
	author = {Wold, Herman},
	year = {1975},
	note = {DOI: 10.1016/B978-0-12-103950-9.50017-4},
	pages = {307--357}
}

@incollection{rosipal_overview_2006,
	address = {Berlin, Heidelberg},
	title = {Overview and {Recent} {Advances} in {Partial} {Least} {Squares}},
	isbn = {978-3-540-34138-3},
	url = {https://doi.org/10.1007/11752790_2},
	abstract = {Partial Least Squares (PLS) is a wide class of methods for modeling relations between sets of observed variables by means of latent variables. It comprises of regression and classification tasks as well as dimension reduction techniques and modeling tools. The underlying assumption of all PLS methods is that the observed data is generated by a system or process which is driven by a small number of latent (not directly observed or measured) variables. Projections of the observed data to its latent structure by means of PLS was developed by Herman Wold and coworkers [48,49,52].},
	booktitle = {Subspace, {Latent} {Structure} and {Feature} {Selection}: {Statistical} and {Optimization} {Perspectives} {Workshop}, {SLSFS} 2005, {Bohinj}, {Slovenia}, {February} 23-25, 2005, {Revised} {Selected} {Papers}},
	publisher = {Springer Berlin Heidelberg},
	author = {Rosipal, Roman and Krämer, Nicole},
	editor = {Saunders, Craig and Grobelnik, Marko and Gunn, Steve and Shawe-Taylor, John},
	year = {2006},
	note = {DOI: 10.1007/11752790\_2},
	pages = {34--51},
	file = {[Rosipal_Krämer.2006] Overview and Recent Advances in Partial Least Squares.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/13. PLS/[Rosipal_Krämer.2006] Overview and Recent Advances in Partial Least Squares.pdf:application/pdf}
}

@book{borga_unified_1997,
	address = {Linköping, Sweden},
	title = {A {Unified} {Approach} to {PCA}, {PLS}, {MLR} and {CCA}},
	isbn = {9925-7521-8-3},
	publisher = {Linköping University, Department of Electrical Engineering},
	author = {Borga, Magnus and Landelius, Tomas and Knutsson, Hans},
	year = {1997},
	file = {[Borga.1997] A Unified Approach to PCA, PLS, MLR and CCA.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/[Borga.1997] A Unified Approach to PCA, PLS, MLR and CCA.pdf:application/pdf}
}

@article{hotelling_relations_1936,
	title = {{RELATIONS} {BETWEEN} {TWO} {SETS} {OF} {VARIATES}},
	volume = {28},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/28.3-4.321},
	doi = {10.1093/biomet/28.3-4.321},
	language = {en},
	number = {3-4},
	urldate = {2017-11-21},
	journal = {Biometrika},
	author = {Hotelling, H.},
	month = dec,
	year = {1936},
	pages = {321--377},
	file = {[Hotelling.1936] RELATIONS BETWEEN TWO SETS OF VARIATES.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/13. PLS/[Hotelling.1936] RELATIONS BETWEEN TWO SETS OF VARIATES.pdf:application/pdf}
}

@article{barker_partial_2003,
	title = {Partial least squares for discrimination},
	volume = {17},
	issn = {0886-9383, 1099-128X},
	url = {http://doi.wiley.com/10.1002/cem.785},
	doi = {10.1002/cem.785},
	language = {en},
	number = {3},
	urldate = {2017-11-21},
	journal = {Journal of Chemometrics},
	author = {Barker, Matthew and Rayens, William},
	month = mar,
	year = {2003},
	pages = {166--173},
	file = {[Barker_Rayens.2003] Partial least squares for discrimination.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/13. PLS/[Barker_Rayens.2003] Partial least squares for discrimination.pdf:application/pdf}
}

@article{cai_orthogonal_2006,
	title = {Orthogonal {Laplacianfaces} for {Face} {Recognition}},
	volume = {15},
	issn = {1057-7149},
	url = {http://ieeexplore.ieee.org/document/1710004/},
	doi = {10.1109/TIP.2006.881945},
	number = {11},
	urldate = {2017-11-21},
	journal = {IEEE Transactions on Image Processing},
	author = {Cai, D. and He, X. and Han, J. and Zhang, H.-J.},
	month = nov,
	year = {2006},
	pages = {3608--3614},
	file = {[Cai.2006] Orthogonal Laplacianfaces for Face Recognition.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/14. OLPP/[Cai.2006] Orthogonal Laplacianfaces for Face Recognition.pdf:application/pdf}
}

@inproceedings{cai_isometric_2007,
	address = {Vancouver, British Columbia, Canada},
	series = {{AAAI}'07},
	title = {Isometric {Projection}},
	isbn = {978-1-57735-323-2},
	url = {http://dl.acm.org/citation.cfm?id=1619645.1619730},
	booktitle = {Proceedings of the 22Nd {National} {Conference} on {Artificial} {Intelligence} - {Volume} 1},
	publisher = {AAAI Press},
	author = {Cai, Deng and He, Xiaofei and Han, Jiawei},
	year = {2007},
	pages = {528--533},
	file = {[Cai.2007] Isometric Projection.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/15. ISOPROJ/[Cai.2007] Isometric Projection.pdf:application/pdf}
}

@article{xiaofei_he_learning_2008,
	title = {Learning a {Maximum} {Margin} {Subspace} for {Image} {Retrieval}},
	volume = {20},
	issn = {1041-4347},
	url = {http://ieeexplore.ieee.org/document/4358969/},
	doi = {10.1109/TKDE.2007.190692},
	number = {2},
	urldate = {2017-11-21},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {{Xiaofei He} and {Deng Cai} and {Jiawei Han}},
	month = feb,
	year = {2008},
	pages = {189--201},
	file = {[Xiaofei He.2008] Learning a Maximum Margin Subspace for Image Retrieval.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/16. MMP/[Xiaofei He.2008] Learning a Maximum Margin Subspace for Image Retrieval.pdf:application/pdf}
}

@inproceedings{cai_locality_2007,
	address = {San Francisco, CA, USA},
	series = {{IJCAI}'07},
	title = {Locality {Sensitive} {Discriminant} {Analysis}},
	url = {http://dl.acm.org/citation.cfm?id=1625275.1625389},
	booktitle = {Proceedings of the 20th {International} {Joint} {Conference} on {Artifical} {Intelligence}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Cai, Deng and He, Xiaofei and Zhou, Kun and Han, Jiawei and Bao, Hujun},
	year = {2007},
	pages = {708--713},
	file = {[Cai.2007] Locality Sensitive Discriminant Analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/17. LSDA/[Cai.2007] Locality Sensitive Discriminant Analysis.pdf:application/pdf}
}

@article{zou_sparse_2006,
	title = {Sparse {Principal} {Component} {Analysis}},
	volume = {15},
	issn = {1061-8600, 1537-2715},
	url = {http://www.tandfonline.com/doi/abs/10.1198/106186006X113430},
	doi = {10.1198/106186006X113430},
	language = {en},
	number = {2},
	urldate = {2017-11-26},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Zou, Hui and Hastie, Trevor and Tibshirani, Robert},
	month = jun,
	year = {2006},
	pages = {265--286},
	file = {[Zou.2006] Sparse Principal Component Analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/18. SPCA/[Zou.2006] Sparse Principal Component Analysis.pdf:application/pdf}
}

@article{daspremont_direct_2007,
	title = {A {Direct} {Formulation} for {Sparse} {PCA} {Using} {Semidefinite} {Programming}},
	volume = {49},
	issn = {0036-1445, 1095-7200},
	url = {http://epubs.siam.org/doi/10.1137/050645506},
	doi = {10.1137/050645506},
	language = {en},
	number = {3},
	urldate = {2017-11-26},
	journal = {SIAM Review},
	author = {d'Aspremont, Alexandre and El Ghaoui, Laurent and Jordan, Michael I. and Lanckriet, Gert R. G.},
	month = jan,
	year = {2007},
	pages = {434--448},
	file = {[d'Aspremont.2007] A Direct Formulation for Sparse PCA Using Semidefinite Programming.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/18. SPCA/[d'Aspremont.2007] A Direct Formulation for Sparse PCA Using Semidefinite Programming.pdf:application/pdf}
}

@article{wang_survey_2015,
	title = {Survey on distance metric learning and dimensionality reduction in data mining},
	volume = {29},
	issn = {1384-5810, 1573-756X},
	url = {http://link.springer.com/10.1007/s10618-014-0356-z},
	doi = {10.1007/s10618-014-0356-z},
	language = {en},
	number = {2},
	urldate = {2017-11-27},
	journal = {Data Mining and Knowledge Discovery},
	author = {Wang, Fei and Sun, Jimeng},
	month = mar,
	year = {2015},
	pages = {534--564},
	file = {[Wang_Sun.2015] Survey on distance metric learning and dimensionality reduction in data mining.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S3. Notes/7. metric learning/[Wang_Sun.2015] Survey on distance metric learning and dimensionality reduction in data mining.pdf:application/pdf}
}

@inproceedings{goldberger_neighbourhood_2004,
	title = {Neighbourhood components analysis},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 17},
	publisher = {MIT Press},
	author = {Goldberger, Jacob and Roweis, Sam and Hinton, Geoff and Salakhutdinov, Ruslan},
	year = {2004},
	pages = {513--520},
	file = {[Goldberger.2004] Neighbourhood components analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/19. NCA/[Goldberger.2004] Neighbourhood components analysis.pdf:application/pdf}
}

@inproceedings{wang_feature_2007,
	title = {Feature {Extraction} by {Maximizing} the {Average} {Neighborhood} {Margin}},
	doi = {10.1109/CVPR.2007.383124},
	booktitle = {2007 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Wang, F. and Zhang, C.},
	month = jun,
	year = {2007},
	keywords = {Data mining, ANMM, average neighborhood margin maximization, computer vision, Computer vision, Covariance matrix, face recognition, feature extraction, Feature extraction, Kernel, linear discriminant analysis, Linear discriminant analysis, optimisation, Pattern recognition, Principal component analysis, Scattering, supervised linear feature extraction, Tensile stress},
	pages = {1--8},
	file = {[Wang_Zhang.2007] Feature Extraction by Maximizing the Average Neighborhood Margin.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/20. ANMM/[Wang_Zhang.2007] Feature Extraction by Maximizing the Average Neighborhood Margin.pdf:application/pdf}
}

@inproceedings{shaw_minimum_2007,
	title = {Minimum {Volume} {Embedding}},
	volume = {2 of JMLR: W\&CP},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Artificial} {Intelligence} and {Statistics} {March} 21-24, 2007, {San} {Juan}, {Puerto} {Rico}},
	author = {Shaw, B. and Jebara, T.},
	editor = {Meila, Marina and Shen, Xiaotong},
	month = mar,
	year = {2007},
	pages = {460--467},
	file = {[Shaw_Jebara.2007] Minimum Volume Embedding.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/50. MVE/[Shaw_Jebara.2007] Minimum Volume Embedding.pdf:application/pdf}
}

@article{arenas-garcia_kernel_2013,
	title = {Kernel {Multivariate} {Analysis} {Framework} for {Supervised} {Subspace} {Learning}: {A} {Tutorial} on {Linear} and {Kernel} {Multivariate} {Methods}},
	volume = {30},
	issn = {1053-5888},
	shorttitle = {Kernel {Multivariate} {Analysis} {Framework} for {Supervised} {Subspace} {Learning}},
	url = {http://ieeexplore.ieee.org/document/6530763/},
	doi = {10.1109/MSP.2013.2250591},
	number = {4},
	urldate = {2017-12-01},
	journal = {IEEE Signal Processing Magazine},
	author = {Arenas-Garcia, Jeronimo and Petersen, Kaare Brandt and Camps-Valls, Gustavo and Hansen, Lars Kai},
	month = jul,
	year = {2013},
	pages = {16--29},
	file = {[Arenas-Garcia.2013] Kernel Multivariate Analysis Framework for Supervised Subspace Learning.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/17. kMVA/[Arenas-Garcia.2013] Kernel Multivariate Analysis Framework for Supervised Subspace Learning.pdf:application/pdf}
}

@article{tipping_probabilistic_1999,
	title = {Probabilistic {Principal} {Component} {Analysis}},
	volume = {61},
	issn = {1369-7412, 1467-9868},
	url = {http://doi.wiley.com/10.1111/1467-9868.00196},
	doi = {10.1111/1467-9868.00196},
	language = {en},
	number = {3},
	urldate = {2017-12-01},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Tipping, Michael E. and Bishop, Christopher M.},
	month = aug,
	year = {1999},
	pages = {611--622},
	file = {[Tipping_Bishop.1999] Probabilistic Principal Component Analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/21. PPCA+BPCA/[Tipping_Bishop.1999] Probabilistic Principal Component Analysis.pdf:application/pdf}
}

@inproceedings{bishop_bayesian_1999,
	title = {Bayesian {PCA}},
	volume = {11},
	url = {https://www.microsoft.com/en-us/research/publication/bayesian-pca/},
	abstract = {The technique of principal component analysis (PCA) has recently been expressed as the maximum likelihood solution for a generative latent variable model. In this paper we use this probabilistic reformulation as the basis for a Bayesian treatment of PCA. Our key result is that effective dimensionality of the latent space (equivalent to the number of retained principal components) can be determined automatically as part of the Bayesian inference procedure. An important application of this framework is to mixtures of probabilistic PCA models, in which each component can determine its own effective complexity.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Bishop, Christopher},
	month = jan,
	year = {1999},
	pages = {382--388},
	file = {[Bishop.1999] Bayesian PCA.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/21. PPCA+BPCA/[Bishop.1999] Bayesian PCA.pdf:application/pdf}
}

@article{candes_robust_2011,
	title = {Robust principal component analysis?},
	volume = {58},
	issn = {00045411},
	url = {http://portal.acm.org/citation.cfm?doid=1970392.1970395},
	doi = {10.1145/1970392.1970395},
	language = {en},
	number = {3},
	urldate = {2017-12-03},
	journal = {Journal of the ACM},
	author = {Candès, Emmanuel J. and Li, Xiaodong and Ma, Yi and Wright, John},
	month = may,
	year = {2011},
	pages = {1--37},
	file = {[Candès.2011] Robust principal component analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/08. RPCA/[Candès.2011] Robust principal component analysis.pdf:application/pdf}
}

@article{einbeck_representing_2007,
	title = {Representing complex data using localized principal components with application to astronomical data},
	journal = {ArXiv e-prints},
	author = {Einbeck, J. and Evers, L. and Bailer-Jones, C.},
	year = {2007},
	keywords = {Astrophysics},
	file = {[Einbeck.2007] Representing complex data using localized principal components with application.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/49. LPCA/[Einbeck.2007] Representing complex data using localized principal components with application.pdf:application/pdf}
}

@techreport{engel_survey_2012,
	title = {A {Survey} of {Dimension} {Reduction} {Methods} for {High}-dimensional {Data} {Analysis} and {Visualization}},
	abstract = {Dimension reduction is commonly defined as the process of mapping high-dimensional data to a lower-dimensional embedding. Applications of dimension reduction include, but are not limited to, filtering, compression, regression, classification, feature analysis, and visualization. We review methods that compute a point-based visual representation of high-dimensional data sets to aid in exploratory data analysis. The aim is not to be exhaustive but to provide an overview of basic approaches, as well as to review select state-of-the-art methods. Our survey paper is an introduction to dimension reduction from a visualization point of view. Subsequently, a comparison of state-of-the-art methods outlines relations and shared research foci.},
	language = {eng},
	institution = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik GmbH, Wadern/Saarbruecken, Germany},
	author = {Engel, Daniel and Hüttenberger, Lars and Hamann, Bernd and Herbstritt, Marc},
	year = {2012},
	note = {DOI: 10.4230/OASIcs.VLUDS.2011.135},
	pages = {--},
	file = {[Engel.2012] A Survey of Dimension Reduction Methods for High-dimensional Data Analysis and.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/[Engel.2012] A Survey of Dimension Reduction Methods for High-dimensional Data Analysis and.pdf:application/pdf}
}

@article{agrafiotis_stochastic_2003,
	title = {Stochastic proximity embedding},
	volume = {24},
	issn = {0192-8651, 1096-987X},
	url = {http://doi.wiley.com/10.1002/jcc.10234},
	doi = {10.1002/jcc.10234},
	language = {en},
	number = {10},
	urldate = {2017-12-14},
	journal = {Journal of Computational Chemistry},
	author = {Agrafiotis, Dimitris K.},
	month = jul,
	year = {2003},
	pages = {1215--1221},
	file = {[Agrafiotis.2003] Stochastic proximity embedding.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/09. SPE/[Agrafiotis.2003] Stochastic proximity embedding.pdf:application/pdf}
}

@article{agrafiotis_stochastic_2010,
	title = {Stochastic {Proximity} {Embedding}: {Methods} and {Applications}},
	volume = {29},
	issn = {18681743},
	shorttitle = {Stochastic {Proximity} {Embedding}},
	url = {http://doi.wiley.com/10.1002/minf.201000134},
	doi = {10.1002/minf.201000134},
	language = {en},
	number = {11},
	urldate = {2017-12-14},
	journal = {Molecular Informatics},
	author = {Agrafiotis, Dimitris K. and Xu, Huafeng and Zhu, Fangqiang and Bandyopadhyay, Deepak and Liu, Pu},
	month = nov,
	year = {2010},
	pages = {758--770},
	file = {[Agrafiotis.2010] Stochastic Proximity Embedding.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/09. SPE/[Agrafiotis.2010] Stochastic Proximity Embedding.pdf:application/pdf}
}

@article{agrafiotis_self-organizing_2002,
	title = {A self-organizing principle for learning nonlinear manifolds},
	volume = {99},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.242424399},
	doi = {10.1073/pnas.242424399},
	language = {en},
	number = {25},
	urldate = {2017-12-14},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Agrafiotis, D. K. and Xu, H.},
	month = dec,
	year = {2002},
	pages = {15869--15872},
	file = {[Agrafiotis_Xu.2002] A self-organizing principle for learning nonlinear manifolds.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/09. SPE/[Agrafiotis_Xu.2002] A self-organizing principle for learning nonlinear manifolds.pdf:application/pdf}
}

@article{kambhatla_dimension_1997,
	title = {Dimension {Reduction} by {Local} {Principal} {Component} {Analysis}},
	volume = {9},
	issn = {0899-7667, 1530-888X},
	url = {http://www.mitpressjournals.org/doi/10.1162/neco.1997.9.7.1493},
	doi = {10.1162/neco.1997.9.7.1493},
	language = {en},
	number = {7},
	urldate = {2017-12-14},
	journal = {Neural Computation},
	author = {Kambhatla, Nandakishore and Leen, Todd K.},
	month = oct,
	year = {1997},
	pages = {1493--1516},
	file = {[Kambhatla_Leen.1997] Dimension Reduction by Local Principal Component Analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/49. LPCA/[Kambhatla_Leen.1997] Dimension Reduction by Local Principal Component Analysis.pdf:application/pdf}
}

@article{france_two-way_2011,
	title = {Two-{Way} {Multidimensional} {Scaling}: {A} {Review}},
	volume = {41},
	issn = {1094-6977, 1558-2442},
	shorttitle = {Two-{Way} {Multidimensional} {Scaling}},
	url = {http://ieeexplore.ieee.org/document/5613204/},
	doi = {10.1109/TSMCC.2010.2078502},
	number = {5},
	urldate = {2017-12-14},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	author = {France, Stephen L. and Carroll, J. Douglas},
	month = sep,
	year = {2011},
	pages = {644--661},
	file = {[France_Carroll.2011] Two-Way Multidimensional Scaling.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/25. MDS family/[France_Carroll.2011] Two-Way Multidimensional Scaling.pdf:application/pdf}
}

@book{borg_modern_2010,
	address = {New York, NY},
	title = {Modern multidimensional scaling: theory and applications},
	isbn = {978-1-4419-2046-1 978-0-387-28981-6},
	shorttitle = {Modern multidimensional scaling},
	abstract = {The book provides a comprehensive treatment of multidimensional scaling (MDS), a statistical technique used to analyze the structure of similarity or dissimilarity data in multidimensional space. Such data are widespread, for example, intercorrelations of attitude items, direct ratings of similarity on choice objects, or trade indices for a set of countries. MDS models such data as distances among points in a geometric space of low dimensionality. This makes complex data sets accessible to visual exploration and thus aids in seeing structure not obvious from the numbers. Other uses of MDS interpret the geometry and, in particular, the distance function as a psychological composition rule. The book may be used as an introduction to MDS for students in many areas including statistics, psychology, sociology, political sciences, and marketing. The prerequisite is a two-semester course in statistics for the social or managerial sciences. The book is also suited for several varieties of advanced courses on MDS, either with an emphasis on data analysis or with a focus on the psychology of similarity. All the mathematics required for more advanced topics is developed systematically.},
	language = {English},
	publisher = {Springer New York},
	author = {Borg, Ingwer and Groenen, Patrick J. F},
	year = {2010},
	note = {OCLC: 731879377}
}

@book{borg_modern_2010-1,
	address = {New York, NY},
	title = {Modern multidimensional scaling: theory and applications},
	isbn = {978-1-4419-2046-1 978-0-387-28981-6},
	shorttitle = {Modern multidimensional scaling},
	abstract = {The book provides a comprehensive treatment of multidimensional scaling (MDS), a statistical technique used to analyze the structure of similarity or dissimilarity data in multidimensional space. Such data are widespread, for example, intercorrelations of attitude items, direct ratings of similarity on choice objects, or trade indices for a set of countries. MDS models such data as distances among points in a geometric space of low dimensionality. This makes complex data sets accessible to visual exploration and thus aids in seeing structure not obvious from the numbers. Other uses of MDS interpret the geometry and, in particular, the distance function as a psychological composition rule. The book may be used as an introduction to MDS for students in many areas including statistics, psychology, sociology, political sciences, and marketing. The prerequisite is a two-semester course in statistics for the social or managerial sciences. The book is also suited for several varieties of advanced courses on MDS, either with an emphasis on data analysis or with a focus on the psychology of similarity. All the mathematics required for more advanced topics is developed systematically.},
	language = {English},
	publisher = {Springer New York},
	author = {Borg, Ingwer and Groenen, Patrick J. F},
	year = {2010},
	note = {OCLC: 731879377},
	file = {[Borg_Groenen.2010] Modern multidimensional scaling.pdf:/home/kisung/Dropbox/VBooks. Academic/[Borg_Groenen.2010] Modern multidimensional scaling.pdf:application/pdf}
}

@article{lee_nonlinear_2004,
	title = {Nonlinear projection with curvilinear distances: {Isomap} versus curvilinear distance analysis},
	volume = {57},
	issn = {09252312},
	shorttitle = {Nonlinear projection with curvilinear distances},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231204000645},
	doi = {10.1016/j.neucom.2004.01.007},
	language = {en},
	urldate = {2017-12-15},
	journal = {Neurocomputing},
	author = {Lee, John Aldo and Lendasse, Amaury and Verleysen, Michel},
	month = mar,
	year = {2004},
	pages = {49--76},
	file = {[Lee.2004] Nonlinear projection with curvilinear distances.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/24. CRCA/[Lee.2004] Nonlinear projection with curvilinear distances.pdf:application/pdf}
}

@article{demartines_curvilinear_1997,
	title = {Curvilinear component analysis: a self-organizing neural network for nonlinear mapping of data sets},
	volume = {8},
	issn = {10459227},
	shorttitle = {Curvilinear component analysis},
	url = {http://ieeexplore.ieee.org/document/554199/},
	doi = {10.1109/72.554199},
	number = {1},
	urldate = {2017-12-15},
	journal = {IEEE Transactions on Neural Networks},
	author = {Demartines, P. and Herault, J.},
	month = jan,
	year = {1997},
	pages = {148--154},
	file = {[Demartines_Herault.1997] Curvilinear component analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/24. CRCA/[Demartines_Herault.1997] Curvilinear component analysis.pdf:application/pdf}
}

@incollection{goos_curvilinear_1999,
	address = {Berlin, Heidelberg},
	title = {Curvilinear component analysis for high-dimensional data representation: {I}. {Theoretical} aspects and practical use in the presence of noise},
	volume = {1607},
	isbn = {978-3-540-66068-2 978-3-540-48772-2},
	shorttitle = {Curvilinear component analysis for high-dimensional data representation},
	url = {http://link.springer.com/10.1007/BFb0100530},
	urldate = {2017-12-15},
	booktitle = {Engineering {Applications} of {Bio}-{Inspired} {Artificial} {Neural} {Networks}},
	publisher = {Springer Berlin Heidelberg},
	author = {Hérault, Jeanny and Jausions-Picaud, Claire and Guérin-Dugué, Anne},
	editor = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Mira, José and Sánchez-Andrés, Juan V.},
	year = {1999},
	note = {DOI: 10.1007/BFb0100530},
	pages = {625--634}
}

@inproceedings{lee_curvilinear_2002,
	title = {Curvilinear {Distance} {Analysis} versus {Isomap}},
	booktitle = {{ESANN}},
	author = {Lee, John Aldo and Lendasse, Amaury and Verleysen, Michel},
	year = {2002},
	file = {[Lee.2002] Curvilinear Distance Analysis versus Isomap.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/24. CRCA/[Lee.2002] Curvilinear Distance Analysis versus Isomap.pdf:application/pdf}
}