
@book{ghosh_bayesian_2003,
	address = {New York},
	title = {Bayesian nonparametrics},
	isbn = {978-0-387-22654-5 978-0-585-47245-4 978-1-280-00998-3},
	url = {http://site.ebrary.com/id/10047830},
	abstract = {Bayesian nonparametrics has grown tremendously in the last three decades, especially in the last few years. This book is the first systematic treatment of Bayesian nonparametric methods and the theory behind them. While the book is of special interest to Bayesians, it will also appeal to statisticians in general because Bayesian nonparametrics offers a whole continuous spectrum of robust alternatives to purely parametric and purely nonparametric methods of classical statistics. The book is primarily aimed at graduate students and can be used as the text for a graduate course in Bayesian nonparametrics. Though the emphasis of the book is on nonparametrics, there is a substantial chapter on asymptotics of classical Bayesian parametric models. Jayanta Ghosh has been Director and Jawaharlal Nehru Professor at the Indian Statistical Institute and President of the International Statistical Institute. He is currently professor of statistics at Purdue University. He has been editor of Sankhya and served on the editorial boards of several journals including the Annals of Statistics. Apart from Bayesian analysis, his interests include asymptotics, stochastic modeling, high dimensional model selection, reliability and survival analysis and bioinformatics. R.V. Ramamoorthi is professor at the Department of Statistics and Probability at Michigan State University. He has published papers in the areas of sufficiency invariance, comparison of experiments, nonparametric survival analysis and Bayesian analysis. In addition to Bayesian nonparametrics, he is currently interested in Bayesian networks and graphical models. He is on the editorial board of Sankhya.},
	language = {English},
	urldate = {2016-10-16},
	publisher = {Springer},
	author = {Ghosh, J. K and Ramamoorthi, R. V},
	year = {2003},
	note = {OCLC: 53251717},
	file = {[Ghosh.2003] Bayesian nonparametrics_2.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/S6. Theory-Nonparametrics/[Ghosh.2003] Bayesian nonparametrics_2.pdf:application/pdf;[Ghosh.2003] Bayesian nonparametrics.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/S6. Theory-Nonparametrics/[Ghosh.2003] Bayesian nonparametrics.pdf:application/pdf;[Ghosh.2003] Bayesian nonparametrics.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/S6. Theory-Nonparametrics/[Ghosh.2003] Bayesian nonparametrics.pdf:application/pdf}
}

@incollection{hinton_stochastic_2003,
	title = {Stochastic {Neighbor} {Embedding}},
	url = {http://papers.nips.cc/paper/2276-stochastic-neighbor-embedding.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 15},
	publisher = {MIT Press},
	author = {Hinton, Geoffrey E. and Roweis, Sam T.},
	editor = {Becker, S. and Thrun, S. and Obermayer, K.},
	year = {2003},
	pages = {857--864},
	file = {[Hinton.2003] Stochastic Neighbor Embedding.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/02. tSNE/[Hinton.2003] Stochastic Neighbor Embedding.pdf:application/pdf}
}

@article{macmahon_community_2015,
	title = {Community {Detection} for {Correlation} {Matrices}},
	volume = {5},
	issn = {2160-3308},
	url = {http://link.aps.org/doi/10.1103/PhysRevX.5.021006},
	doi = {10.1103/PhysRevX.5.021006},
	language = {en},
	number = {2},
	urldate = {2016-10-17},
	journal = {Physical Review X},
	author = {MacMahon, Mel and Garlaschelli, Diego},
	month = apr,
	year = {2015},
	file = {[MacMahon.2015] Community Detection for Correlation Matrices.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P3. SGT/Topics/[MacMahon.2015] Community Detection for Correlation Matrices.pdf:application/pdf}
}

@article{pati_optimal_2015,
	title = {Optimal {Bayesian} estimation in stochastic block models},
	journal = {ArXiv e-prints},
	author = {Pati, D. and Bhattacharya, A.},
	month = may,
	year = {2015},
	keywords = {Mathematics - Statistics Theory},
	file = {[Pati.2015] Optimal Bayesian estimation in stochastic block models.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/SBM/[Pati.2015] Optimal Bayesian estimation in stochastic block models.pdf:application/pdf}
}

@article{holland_stochastic_1983,
	title = {Stochastic blockmodels: {First} steps},
	volume = {5},
	issn = {03788733},
	shorttitle = {Stochastic blockmodels},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0378873383900217},
	doi = {10.1016/0378-8733(83)90021-7},
	language = {en},
	number = {2},
	urldate = {2016-06-15},
	journal = {Social Networks},
	author = {Holland, Paul W. and Laskey, Kathryn Blackmond and Leinhardt, Samuel},
	month = jun,
	year = {1983},
	pages = {109--137},
	annote = {SBM01 : first introduction},
	file = {[Holland.1983] Stochastic blockmodels.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/SBM/[Holland.1983] Stochastic blockmodels.pdf:application/pdf;[Holland.1983] Stochastic blockmodels.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Detect Modules/[Holland.1983] Stochastic blockmodels.pdf:application/pdf}
}

@article{casella_explaining_2001,
	title = {Explaining the {Perfect} {Sampler}},
	volume = {55},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1198/000313001753272240},
	doi = {10.1198/000313001753272240},
	language = {en},
	number = {4},
	urldate = {2016-10-15},
	journal = {The American Statistician},
	author = {Casella, George and Lavine, Michael and Robert, Christian P},
	month = nov,
	year = {2001},
	pages = {299--305},
	file = {[Casella.2001] Explaining the Perfect Sampler.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/S2. Comp-MCMC/[Casella.2001] Explaining the Perfect Sampler.pdf:application/pdf}
}

@article{mwangi_review_2014,
	title = {A {Review} of {Feature} {Reduction} {Techniques} in {Neuroimaging}},
	volume = {12},
	issn = {1539-2791, 1559-0089},
	url = {http://link.springer.com/10.1007/s12021-013-9204-3},
	doi = {10.1007/s12021-013-9204-3},
	language = {en},
	number = {2},
	urldate = {2016-06-19},
	journal = {Neuroinformatics},
	author = {Mwangi, Benson and Tian, Tian Siva and Soares, Jair C.},
	month = apr,
	year = {2014},
	pages = {229--244},
	file = {[Mwangi.2014] A Review of Feature Reduction Techniques in Neuroimaging.pdf:/home/kisung/Dropbox/V5. Neuroscience/[Mwangi.2014] A Review of Feature Reduction Techniques in Neuroimaging.pdf:application/pdf}
}

@article{siegle_increased_2007,
	title = {Increased amygdala and decreased dorsolateral prefrontal {BOLD} responses in unipolar depression: related and independent features},
	volume = {61},
	issn = {0006-3223},
	shorttitle = {Increased amygdala and decreased dorsolateral prefrontal {BOLD} responses in unipolar depression},
	doi = {10.1016/j.biopsych.2006.05.048},
	abstract = {BACKGROUND: Major depressive disorder is characterized by increased and sustained emotional reactivity, which has been linked to sustained amygdala activity. It is also characterized by disruptions in executive control, linked to abnormal dorsolateral prefrontal cortex (DLPFC) function. These mechanisms have been hypothesized to interact in depression. This study explored relationships between amygdala and DLPFC activity during emotional and cognitive information processing in unipolar depression.
METHOD: Twenty-seven unmedicated patients with DSM-IV unipolar major depressive disorder and 25 never-depressed healthy control subjects completed tasks requiring executive control (digit sorting) and emotional information processing (personal relevance rating of words) during event-related functional magnetic resonance imaging (fMRI) assessment.
RESULTS: Relative to control subjects, depressed subjects displayed sustained amygdala reactivity on the emotional tasks and decreased DLPFC activity on the digit-sorting task. Decreased relationships between the time-series of amygdala and DLPFC activity were observed within tasks in depression, but different depressed individuals showed each type of bias.
CONCLUSIONS: Depression is associated with increased limbic activity in response to emotional information processing and decreased DLPFC activity in response to cognitive tasks though these may reflect separate mechanisms. Depressed individuals also display decreased relationships between amygdala and DLPFC activity, potentially signifying decreased functional relationships among these structures.},
	language = {eng},
	number = {2},
	journal = {Biol. Psychiatry},
	author = {Siegle, Greg J. and Thompson, Wesley and Carter, Cameron S. and Steinhauer, Stuart R. and Thase, Michael E.},
	month = jan,
	year = {2007},
	pmid = {17027931},
	keywords = {Adolescent, Adult, Amygdala, Attention, Brain Mapping, Cognition, Depressive Disorder, Major, Discrimination Learning, Dominance, Cerebral, Emotions, Female, Humans, Image Enhancement, Image Processing, Computer-Assisted, Imaging, Three-Dimensional, Magnetic Resonance Imaging, Male, Memory, Short-Term, Middle Aged, Nerve Net, Oxygen, Pattern Recognition, Visual, Prefrontal Cortex, Reaction Time},
	pages = {198--209},
	annote = {Functional Connectivity : lagged cross-correlation
 },
	file = {[Siegle.2007] Increased amygdala and decreased dorsolateral prefrontal BOLD responses in.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Define FC/[Siegle.2007] Increased amygdala and decreased dorsolateral prefrontal BOLD responses in.pdf:application/pdf}
}

@article{bucholz_new_1994,
	title = {A new, semi-structured psychiatric interview for use in genetic linkage studies: a report on the reliability of the {SSAGA}.},
	volume = {55},
	issn = {0096-882X, 1934-2683},
	shorttitle = {A new, semi-structured psychiatric interview for use in genetic linkage studies},
	url = {http://www.jsad.com/doi/10.15288/jsa.1994.55.149},
	doi = {10.15288/jsa.1994.55.149},
	language = {en},
	number = {2},
	urldate = {2016-07-04},
	journal = {Journal of Studies on Alcohol},
	author = {Bucholz, K K and Cadoret, R and Cloninger, C R and Dinwiddie, S H and Hesselbrock, V M and Nurnberger, J I and Reich, T and Schmidt, I and Schuckit, M A},
	month = mar,
	year = {1994},
	pages = {149--158},
	annote = {HCP:Data:Behavioral Scores:Alcohol and Cannabis Data Acquisition Test},
	file = {[Bucholz.1994] A new, semi-structured psychiatric interview for use in genetic linkage studies.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Data Issues/[Bucholz.1994] A new, semi-structured psychiatric interview for use in genetic linkage studies.pdf:application/pdf}
}

@book{kutner_applied_2005,
	address = {Boston},
	title = {Applied linear statistical models},
	isbn = {978-0-07-238688-2 978-0-07-112221-4 978-0-07-310874-2},
	abstract = {Applied Linear Statistical Models", 5e, is the long established leading authoritative text and reference on statistical modeling. For students in most any discipline where statistical analysis or interpretation is used, ALSM serves as the standard work. The text includes brief introductory and review material, and then proceeds through regression and modeling for the first half, and through ANOVA and Experimental Design in the second half. All topics are presented in a precise and clear style supported with solved examples, numbered formulae, graphic illustrations, and "Notes" to provide depth and statistical accuracy and precision. Applications used within the text and the hallmark problems, exercises, and projects are drawn from virtually all disciplines and fields providing motivation for students in virtually any college. The Fifth edition provides an increased use of computing and graphical analysis throughout, without sacrificing concepts or rigor. In general, the 5e uses larger data sets in examples and exercises, and where methods can be automated within software without loss of understanding, it is so done.},
	language = {English},
	publisher = {McGraw-Hill Irwin},
	author = {Kutner, Michael H and Nachtsheim, Chris and Neter, John and Li, William},
	year = {2005},
	note = {OCLC: 55502728},
	file = {[Kutner.2005] Applied linear statistical models.pdf:/home/kisung/Dropbox/VC. Coursework/P3. Statistics/2. Linear Models/[Kutner.2005] Applied linear statistical models.pdf:application/pdf}
}

@article{rue_approximate_2009,
	title = {Approximate {Bayesian} inference for latent {Gaussian} models by using integrated nested {Laplace} approximations},
	volume = {71},
	issn = {13697412, 14679868},
	url = {http://doi.wiley.com/10.1111/j.1467-9868.2008.00700.x},
	doi = {10.1111/j.1467-9868.2008.00700.x},
	language = {en},
	number = {2},
	urldate = {2016-10-15},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Rue, Håvard and Martino, Sara and Chopin, Nicolas},
	month = apr,
	year = {2009},
	pages = {319--392},
	file = {[Rue.2009] Approximate Bayesian inference for latent Gaussian models by using integrated.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/S1. Comp-Approximate/[Rue.2009] Approximate Bayesian inference for latent Gaussian models by using integrated.pdf:application/pdf}
}

@article{destrieux_automatic_2010,
	title = {Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature},
	volume = {53},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811910008542},
	doi = {10.1016/j.neuroimage.2010.06.010},
	language = {en},
	number = {1},
	urldate = {2016-06-29},
	journal = {NeuroImage},
	author = {Destrieux, Christophe and Fischl, Bruce and Dale, Anders and Halgren, Eric},
	month = oct,
	year = {2010},
	pages = {1--15},
	annote = {Freesurfer : Destrieux Atlas : aparc.a2009s.
},
	file = {[Destrieux.2010] Automatic parcellation of human cortical gyri and sulci using standard.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Data Issues/[Destrieux.2010] Automatic parcellation of human cortical gyri and sulci using standard.pdf:application/pdf}
}

@book{johnson_numerical_2009,
	address = {Mineola, N.Y},
	edition = {Dover ed},
	series = {Dover books on mathematics},
	title = {Numerical solution of partial differential equations by the finite element method},
	isbn = {978-0-486-46900-3},
	publisher = {Dover Publications},
	author = {Johnson, Claes},
	year = {2009},
	note = {OCLC: ocn227923865},
	keywords = {Differential equations, Partial, Finite element method, Numerical solutions},
	annote = {"This Dover edition, first published in 2009, is an unabridged republication of the work originally published in 1987 by Cambridge University Press, Cambridge, and Studentlitteratur, Lund, Sweden."},
	file = {[Johnson.2009] Numerical solution of partial differential equations by the finite element.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P1. PDE/S2. Yonsei-NPDE/[Johnson.2009] Numerical solution of partial differential equations by the finite element.pdf:application/pdf}
}

@article{attias_variational_2000,
	title = {A variational {Bayesian} framework for graphical models},
	volume = {12},
	number = {1-2},
	journal = {Advances in neural information processing systems},
	author = {Attias, Hagai},
	year = {2000},
	pages = {209--215},
	annote = {Variational Bayes : GMM},
	file = {[Attias.2000] A variational Bayesian framework for graphical models.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/Topics/[Attias.2000] A variational Bayesian framework for graphical models.pdf:application/pdf}
}

@article{jenkinson_improved_2002,
	title = {Improved optimization for the robust and accurate linear registration and motion correction of brain images},
	volume = {17},
	issn = {1053-8119},
	abstract = {Linear registration and motion correction are important components of structural and functional brain image analysis. Most modern methods optimize some intensity-based cost function to determine the best registration. To date, little attention has been focused on the optimization method itself, even though the success of most registration methods hinges on the quality of this optimization. This paper examines the optimization process in detail and demonstrates that the commonly used multiresolution local optimization methods can, and do, get trapped in local minima. To address this problem, two approaches are taken: (1) to apodize the cost function and (2) to employ a novel hybrid global-local optimization method. This new optimization method is specifically designed for registering whole brain images. It substantially reduces the likelihood of producing misregistrations due to being trapped by local minima. The increased robustness of the method, compared to other commonly used methods, is demonstrated by a consistency test. In addition, the accuracy of the registration is demonstrated by a series of experiments with motion correction. These motion correction experiments also investigate how the results are affected by different cost functions and interpolation methods.},
	language = {eng},
	number = {2},
	journal = {Neuroimage},
	author = {Jenkinson, Mark and Bannister, Peter and Brady, Michael and Smith, Stephen},
	month = oct,
	year = {2002},
	pmid = {12377157},
	keywords = {Acoustic Stimulation, Algorithms, Brain, Computer Simulation, Data Interpretation, Statistical, Fuzzy Logic, Humans, Image Interpretation, Computer-Assisted, Linear Models, Models, Neurological, Motion, Photic Stimulation, Reproducibility of Results},
	pages = {825--841},
	annote = {HCP Standard Pre-processing Protocol 1},
	file = {[Jenkinson.2002] Improved optimization for the robust and accurate linear registration and.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Data Issues/[Jenkinson.2002] Improved optimization for the robust and accurate linear registration and.pdf:application/pdf}
}

@article{belkin_laplacian_2003,
	title = {Laplacian {Eigenmaps} for {Dimensionality} {Reduction} and {Data} {Representation}},
	volume = {15},
	issn = {0899-7667, 1530-888X},
	url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976603321780317},
	doi = {10.1162/089976603321780317},
	language = {en},
	number = {6},
	urldate = {2016-06-19},
	journal = {Neural Computation},
	author = {Belkin, Mikhail and Niyogi, Partha},
	month = jun,
	year = {2003},
	pages = {1373--1396},
	annote = {Laplacian Eigenmaps : First, Original, Initial},
	file = {[Belkin.2003] Laplacian Eigenmaps for Dimensionality Reduction and Data Representation.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/03. LAPEIG/[Belkin.2003] Laplacian Eigenmaps for Dimensionality Reduction and Data Representation.pdf:application/pdf}
}

@article{cortes_support-vector_1995,
	title = {Support-vector networks},
	volume = {20},
	issn = {0885-6125, 1573-0565},
	url = {http://link.springer.com/10.1007/BF00994018},
	doi = {10.1007/BF00994018},
	language = {en},
	number = {3},
	urldate = {2016-07-04},
	journal = {Machine Learning},
	author = {Cortes, Corinna and Vapnik, Vladimir},
	month = sep,
	year = {1995},
	pages = {273--297},
	annote = {SVM: current standard incarnation using Soft Margin},
	file = {[Cortes_Vapnik.1995] Support-vector networks.pdf:/home/kisung/Dropbox/V3. Statistics/P6. ML/S2. Tools_Supervised/[Cortes_Vapnik.1995] Support-vector networks.pdf:application/pdf}
}

@article{kaiser_nonoptimal_2006,
	title = {Nonoptimal {Component} {Placement}, but {Short} {Processing} {Paths}, due to {Long}-{Distance} {Projections} in {Neural} {Systems}},
	volume = {2},
	issn = {1553-734X, 1553-7358},
	url = {http://dx.plos.org/10.1371/journal.pcbi.0020095},
	doi = {10.1371/journal.pcbi.0020095},
	language = {en},
	number = {7},
	urldate = {2016-07-12},
	journal = {PLoS Computational Biology},
	author = {Kaiser, Marcus and Hilgetag, Claus C.},
	year = {2006},
	pages = {e95},
	annote = {Modular Interaction based on structural topology 3}
}

@article{lian_multivariate_2015,
	title = {Multivariate time-series analysis and diffusion maps},
	volume = {116},
	issn = {01651684},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S016516841500136X},
	doi = {10.1016/j.sigpro.2015.04.003},
	language = {en},
	urldate = {2016-10-22},
	journal = {Signal Processing},
	author = {Lian, Wenzhao and Talmon, Ronen and Zaveri, Hitten and Carin, Lawrence and Coifman, Ronald},
	month = nov,
	year = {2015},
	pages = {13--28},
	file = {[Lian.2015] Multivariate time-series analysis and diffusion maps.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P3. SGT/Topics/[Lian.2015] Multivariate time-series analysis and diffusion maps.pdf:application/pdf}
}

@book{royden_real_2010,
	address = {Boston},
	title = {Real analysis},
	isbn = {978-0-13-143747-0 978-0-13-511355-4},
	language = {English},
	publisher = {Prentice Hall},
	author = {Royden, H. L and Fitzpatrick, Patrick and Royden, H. L},
	year = {2010},
	note = {OCLC: 456836719},
	file = {[Royden.2010] Real analysis.pdf:/home/kisung/Dropbox/V1. Pure Mathematics/P1. Analysis/S1. Yonsei-Real/[Royden.2010] Real analysis.pdf:application/pdf}
}

@article{smith_resting-state_2013,
	title = {Resting-state {fMRI} in the {Human} {Connectome} {Project}},
	volume = {80},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811913005338},
	doi = {10.1016/j.neuroimage.2013.05.039},
	language = {en},
	urldate = {2016-06-29},
	journal = {NeuroImage},
	author = {Smith, Stephen M. and Beckmann, Christian F. and Andersson, Jesper and Auerbach, Edward J. and Bijsterbosch, Janine and Douaud, Gwenaëlle and Duff, Eugene and Feinberg, David A. and Griffanti, Ludovica and Harms, Michael P. and Kelly, Michael and Laumann, Timothy and Miller, Karla L. and Moeller, Steen and Petersen, Steve and Power, Jonathan and Salimi-Khorshidi, Gholamreza and Snyder, Abraham Z. and Vu, An T. and Woolrich, Mark W. and Xu, Junqian and Yacoub, Essa and Uğurbil, Kamil and Van Essen, David C. and Glasser, Matthew F.},
	month = oct,
	year = {2013},
	pages = {144--168},
	file = {[Smith.2013] Resting-state fMRI in the Human Connectome Project.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Data Issues/[Smith.2013] Resting-state fMRI in the Human Connectome Project.pdf:application/pdf}
}

@article{hinton_reducing_2006,
	title = {Reducing the {Dimensionality} of {Data} with {Neural} {Networks}},
	volume = {313},
	issn = {0036-8075, 1095-9203},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1127647},
	doi = {10.1126/science.1127647},
	language = {en},
	number = {5786},
	urldate = {2016-06-23},
	journal = {Science},
	author = {Hinton, G. E.},
	month = jul,
	year = {2006},
	pages = {504--507},
	file = {[Hinton.2006] Reducing the Dimensionality of Data with Neural Networks.pdf:/home/kisung/Dropbox/V3. Statistics/P7. DL/[Hinton.2006] Reducing the Dimensionality of Data with Neural Networks.pdf:application/pdf}
}

@book{grimmett_one_2001,
	address = {Oxford ; New York},
	title = {One thousand exercises in probability},
	isbn = {978-0-19-857221-3},
	publisher = {Oxford University Press},
	author = {Grimmett, Geoffrey and Stirzaker, David},
	year = {2001},
	keywords = {Probabilities, Stochastic processes},
	file = {[Grimmett.2001] One thousand exercises in probability.pdf:/home/kisung/Dropbox/VC. Coursework/P1. Math/1. Probability/[Grimmett.2001] One thousand exercises in probability.pdf:application/pdf}
}

@article{friston_functional_1993,
	title = {Functional {Connectivity}: {The} {Principal}-{Component} {Analysis} of {Large} ({PET}) {Data} {Sets}},
	volume = {13},
	issn = {0271-678X, 1559-7016},
	shorttitle = {Functional {Connectivity}},
	url = {http://jcb.sagepub.com/lookup/doi/10.1038/jcbfm.1993.4},
	doi = {10.1038/jcbfm.1993.4},
	number = {1},
	urldate = {2016-06-25},
	journal = {Journal of Cerebral Blood Flow \& Metabolism},
	author = {Friston, K. J. and Frith, C. D. and Liddle, P. F. and Frackowiak, R. S. J.},
	month = jan,
	year = {1993},
	pages = {5--14},
	annote = {Apply PCA:Principal Component Analysis: to find eigenimages for PET},
	file = {[Friston.1993] Functional Connectivity.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - SPM/[Friston.1993] Functional Connectivity.pdf:application/pdf}
}

@article{glasser_minimal_2013,
	title = {The minimal preprocessing pipelines for the {Human} {Connectome} {Project}},
	volume = {80},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811913005053},
	doi = {10.1016/j.neuroimage.2013.04.127},
	language = {en},
	urldate = {2016-06-29},
	journal = {NeuroImage},
	author = {Glasser, Matthew F. and Sotiropoulos, Stamatios N. and Wilson, J. Anthony and Coalson, Timothy S. and Fischl, Bruce and Andersson, Jesper L. and Xu, Junqian and Jbabdi, Saad and Webster, Matthew and Polimeni, Jonathan R. and Van Essen, David C. and Jenkinson, Mark},
	month = oct,
	year = {2013},
	pages = {105--124},
	file = {[Glasser.2013] The minimal preprocessing pipelines for the Human Connectome Project.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Data Issues/[Glasser.2013] The minimal preprocessing pipelines for the Human Connectome Project.pdf:application/pdf}
}

@book{seo_nonlinear_2013,
	address = {Chichester, West Sussex, United Kingdom},
	title = {Nonlinear inverse problems in imaging},
	isbn = {978-0-470-66942-6},
	abstract = {"This book provides researchers and engineers in the imaging field with the skills they need to effectively deal with nonlinear inverse problems associated with different imaging modalities, including impedance imaging, optical tomography, elastography, and electrical source imaging. Focusing on numerically implementable methods, the book bridges the gap between theory and applications, helping readers tackle problems in applied mathematics and engineering. Complete, self-contained coverage includes basic concepts, models, computational methods, numerical simulations, examples, and case studies. Provides a step-by-step progressive treatment of topics for ease of understanding. Discusses the underlying physical phenomena as well as implementation details of image reconstruction algorithms as prerequisites for finding solutions to non linear inverse problems with practical significance and value. Includes end of chapter problems, case studies and examples with solutions throughout the book. Companion website will provide further examples and solutions, experimental data sets, open problems, teaching material such as PowerPoint slides and software including MATLAB m files. Essential reading for Graduate students and researchers in imaging science working across the areas of applied mathematics, biomedical engineering, and electrical engineering and specifically those involved in nonlinear imaging techniques, impedance imaging, optical tomography, elastography, and electrical source imaging"--},
	publisher = {Wiley, A John Wiley \& Sons, Ltd., Publication},
	author = {Seo, Jin Keun and Woo, E. J.},
	year = {2013},
	keywords = {Cross-sectional imaging, Image processing, Inverse problems (Differential equations), Mathematics, Nonlinear theories},
	file = {[Seo.2013] Nonlinear inverse problems in imaging.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P1. PDE/S1. Yonsei-PDE/[Seo.2013] Nonlinear inverse problems in imaging.pdf:application/pdf}
}

@article{hoff_latent_2002,
	title = {Latent {Space} {Approaches} to {Social} {Network} {Analysis}},
	volume = {97},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1198/016214502388618906},
	doi = {10.1198/016214502388618906},
	language = {en},
	number = {460},
	urldate = {2016-10-08},
	journal = {Journal of the American Statistical Association},
	author = {Hoff, Peter D and Raftery, Adrian E and Handcock, Mark S},
	month = dec,
	year = {2002},
	pages = {1090--1098},
	annote = {LSM01 : First introduced LSM in analysis},
	file = {[Hoff.2002] Latent Space Approaches to Social Network Analysis.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/LSM/[Hoff.2002] Latent Space Approaches to Social Network Analysis.pdf:application/pdf}
}

@article{karrer_stochastic_2011,
	title = {Stochastic blockmodels and community structure in networks},
	volume = {83},
	issn = {1539-3755, 1550-2376},
	url = {http://link.aps.org/doi/10.1103/PhysRevE.83.016107},
	doi = {10.1103/PhysRevE.83.016107},
	language = {en},
	number = {1},
	urldate = {2016-10-08},
	journal = {Physical Review E},
	author = {Karrer, Brian and Newman, M. E. J.},
	month = jan,
	year = {2011},
	annote = {SBM01 : degree-corrected / DC-SBM is first introduced.},
	file = {[Karrer.2011] Stochastic blockmodels and community structure in networks.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/SBM/[Karrer.2011] Stochastic blockmodels and community structure in networks.pdf:application/pdf}
}

@article{diaconis_markov_2008,
	title = {The {Markov} chain {Monte} {Carlo} revolution},
	volume = {46},
	issn = {0273-0979},
	url = {http://www.ams.org/journal-getitem?pii=S0273-0979-08-01238-X},
	doi = {10.1090/S0273-0979-08-01238-X},
	language = {en},
	number = {2},
	urldate = {2016-10-15},
	journal = {Bulletin of the American Mathematical Society},
	author = {Diaconis, Persi},
	month = nov,
	year = {2008},
	pages = {179--205},
	file = {[Diaconis.2008] The Markov chain Monte Carlo revolution.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/S2. Comp-MCMC/[Diaconis.2008] The Markov chain Monte Carlo revolution.pdf:application/pdf}
}

@book{hastie_elements_2009,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {The {Elements} of {Statistical} {Learning}},
	isbn = {978-0-387-84857-0 978-0-387-84858-7},
	url = {http://link.springer.com/10.1007/978-0-387-84858-7},
	urldate = {2016-06-15},
	publisher = {Springer New York},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
	year = {2009},
	annote = {extend conventional clustering methods by converting network data into distance-based expression},
	file = {[Hastie.2009] The Elements of Statistical Learning.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Detect Modules/[Hastie.2009] The Elements of Statistical Learning.pdf:application/pdf}
}

@article{durante_bayesian_2014,
	title = {Bayesian dynamic financial networks with time-varying predictors},
	volume = {93},
	issn = {01677152},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S016771521400217X},
	doi = {10.1016/j.spl.2014.06.015},
	language = {en},
	urldate = {2016-10-22},
	journal = {Statistics \& Probability Letters},
	author = {Durante, Daniele and Dunson, David B.},
	month = oct,
	year = {2014},
	pages = {19--26},
	file = {[Durante.2014] Bayesian dynamic financial networks with time-varying predictors.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/LSM/[Durante.2014] Bayesian dynamic financial networks with time-varying predictors.pdf:application/pdf}
}

@article{zhou_matlab_2009,
	title = {{MATLAB} toolbox for functional connectivity},
	volume = {47},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811909006004},
	doi = {10.1016/j.neuroimage.2009.05.089},
	language = {en},
	number = {4},
	urldate = {2016-06-09},
	journal = {NeuroImage},
	author = {Zhou, Dongli and Thompson, Wesley K. and Siegle, Greg},
	month = oct,
	year = {2009},
	pages = {1590--1607},
	annote = {SURVEY / REVIEW for Functional Connectivity measures}
}

@article{chklovskii_maps_2004,
	title = {{MAPS} {IN} {THE} {BRAIN}: {What} {Can} {We} {Learn} from {Them}?},
	volume = {27},
	issn = {0147-006X, 1545-4126},
	shorttitle = {{MAPS} {IN} {THE} {BRAIN}},
	url = {http://www.annualreviews.org/doi/10.1146/annurev.neuro.27.070203.144226},
	doi = {10.1146/annurev.neuro.27.070203.144226},
	language = {en},
	number = {1},
	urldate = {2016-07-12},
	journal = {Annual Review of Neuroscience},
	author = {Chklovskii, Dmitri B. and Koulakov, Alexei A.},
	month = jul,
	year = {2004},
	pages = {369--392},
	annote = {Modular Interaction based on structural topology 2}
}

@article{newman_finding_2004,
	title = {Finding and evaluating community structure in networks},
	volume = {69},
	issn = {1539-3755, 1550-2376},
	url = {http://link.aps.org/doi/10.1103/PhysRevE.69.026113},
	doi = {10.1103/PhysRevE.69.026113},
	language = {en},
	number = {2},
	urldate = {2016-06-15},
	journal = {Physical Review E},
	author = {Newman, M. E. J. and Girvan, M.},
	month = feb,
	year = {2004},
	annote = {SEMINAL WORK : Modularity Quality Function is first introduced},
	file = {[Newman.2004] Finding and evaluating community structure in networks.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P4. Network/S2. Modularity/[Newman.2004] Finding and evaluating community structure in networks.pdf:application/pdf}
}

@article{coifman_diffusion_2006,
	title = {Diffusion maps},
	volume = {21},
	issn = {10635203},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1063520306000546},
	doi = {10.1016/j.acha.2006.04.006},
	language = {en},
	number = {1},
	urldate = {2016-07-04},
	journal = {Applied and Computational Harmonic Analysis},
	author = {Coifman, Ronald R. and Lafon, Stéphane},
	month = jul,
	year = {2006},
	pages = {5--30},
	annote = {Diffusion Maps:2nd:Main Paper},
	file = {[Coifman_Lafon.2006] Diffusion maps.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/01. DM/[Coifman_Lafon.2006] Diffusion maps.pdf:application/pdf}
}

@article{bullmore_complex_2009,
	title = {Complex brain networks: graph theoretical analysis of structural and functional systems},
	volume = {10},
	issn = {1471-003X, 1471-0048},
	shorttitle = {Complex brain networks},
	url = {http://www.nature.com/doifinder/10.1038/nrn2575},
	doi = {10.1038/nrn2575},
	number = {3},
	urldate = {2016-06-19},
	journal = {Nature Reviews Neuroscience},
	author = {Bullmore, Ed and Sporns, Olaf},
	month = mar,
	year = {2009},
	pages = {186--198},
	annote = {graph and network theory for systems neuroscience},
	file = {[Bullmore.2009] Complex brain networks.pdf:/home/kisung/Dropbox/V5. Neuroscience/[Bullmore.2009] Complex brain networks.pdf:application/pdf}
}

@book{rasmussen_gaussian_2006,
	address = {Cambridge, Mass},
	series = {Adaptive computation and machine learning},
	title = {Gaussian processes for machine learning},
	isbn = {978-0-262-18253-9},
	publisher = {MIT Press},
	author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
	year = {2006},
	note = {OCLC: ocm61285753},
	keywords = {Data processing, Gaussian processes, Mathematical models, machine learning},
	file = {[Rasmussen.2006] Gaussian processes for machine learning.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/S3. Process-Gaussian/[Rasmussen.2006] Gaussian processes for machine learning.pdf:application/pdf}
}

@article{bullmore_economy_2012,
	title = {The economy of brain network organization},
	issn = {1471-003X, 1471-0048},
	url = {http://www.nature.com/doifinder/10.1038/nrn3214},
	doi = {10.1038/nrn3214},
	urldate = {2016-07-12},
	journal = {Nature Reviews Neuroscience},
	author = {Bullmore, Ed and Sporns, Olaf},
	month = apr,
	year = {2012},
	annote = {Modular Interaction based on structural topology 1}
}

@article{gomez_analysis_2009,
	title = {Analysis of community structure in networks of correlated data},
	volume = {80},
	issn = {1539-3755, 1550-2376},
	url = {http://link.aps.org/doi/10.1103/PhysRevE.80.016114},
	doi = {10.1103/PhysRevE.80.016114},
	language = {en},
	number = {1},
	urldate = {2016-10-17},
	journal = {Physical Review E},
	author = {Gómez, Sergio and Jensen, Pablo and Arenas, Alex},
	month = jul,
	year = {2009},
	file = {[Gómez.2009] Analysis of community structure in networks of correlated data.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P3. SGT/Topics/[Gómez.2009] Analysis of community structure in networks of correlated data.pdf:application/pdf}
}

@article{liu_extending_2012,
	title = {Extending modularity by incorporating distance functions in the null model},
	volume = {abs/1210.4007},
	url = {http://arxiv.org/abs/1210.4007},
	journal = {CoRR},
	author = {Liu, Xin and Murata, Tsuyoshi and Wakita, Ken},
	year = {2012},
	file = {[Liu.2012] Extending modularity by incorporating distance functions in the null model.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P4. Network/S2. Modularity/[Liu.2012] Extending modularity by incorporating distance functions in the null model.pdf:application/pdf}
}

@article{van_der_maaten_visualizing_2008,
	title = {Visualizing data using t-{SNE}},
	volume = {9},
	number = {2579-2605},
	journal = {The Journal of Machine Learning Research},
	author = {van der Maaten, Laurens and Hinton, Geoffrey},
	year = {2008},
	pages = {85},
	annote = {t-SNE : original paper},
	file = {[van der Maaten.2008] Visualizing data using t-SNE.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/02. tSNE/[van der Maaten.2008] Visualizing data using t-SNE.pdf:application/pdf}
}

@book{james_introduction_2013,
	address = {New York},
	series = {Springer texts in statistics},
	title = {An introduction to statistical learning: with applications in {R}},
	isbn = {978-1-4614-7137-0},
	shorttitle = {An introduction to statistical learning},
	number = {103},
	publisher = {Springer},
	editor = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
	year = {2013},
	note = {OCLC: ocn828488009},
	keywords = {Mathematical models, Mathematical statistics, R (Computer program language), Statistics},
	annote = {Includes index},
	file = {[James.2013] An introduction to statistical learning.pdf:/home/kisung/Dropbox/VC. Coursework/P3. Statistics/1. Data Mining/[James.2013] An introduction to statistical learning.pdf:application/pdf}
}

@book{neter_student_2004,
	address = {New York, NY},
	title = {Student solutions manual for use with {Applied} linear regression models, fourth edition},
	isbn = {978-0-07-291839-7},
	language = {English},
	publisher = {McGraw-Hill/Irwin},
	author = {Neter, John and Kutner, Michael H and Nachtsheim, Christopher J},
	year = {2004},
	note = {OCLC: 56188631},
	file = {[Neter.2004] Student solutions manual for use with Applied linear regression models, fourth.pdf:/home/kisung/Dropbox/VC. Coursework/P3. Statistics/2. Linear Models/[Neter.2004] Student solutions manual for use with Applied linear regression models, fourth.pdf:application/pdf}
}

@article{biswal_functional_1995,
	title = {Functional connectivity in the motor cortex of resting human brain using echo-planar {MRI}},
	volume = {34},
	issn = {0740-3194},
	abstract = {An MRI time course of 512 echo-planar images (EPI) in resting human brain obtained every 250 ms reveals fluctuations in signal intensity in each pixel that have a physiologic origin. Regions of the sensorimotor cortex that were activated secondary to hand movement were identified using functional MRI methodology (FMRI). Time courses of low frequency ({\textless} 0.1 Hz) fluctuations in resting brain were observed to have a high degree of temporal correlation (P {\textless} 10(-3)) within these regions and also with time courses in several other regions that can be associated with motor function. It is concluded that correlation of low frequency fluctuations, which may arise from fluctuations in blood oxygenation or flow, is a manifestation of functional connectivity of the brain.},
	language = {eng},
	number = {4},
	journal = {Magn Reson Med},
	author = {Biswal, B. and Yetkin, F. Z. and Haughton, V. M. and Hyde, J. S.},
	month = oct,
	year = {1995},
	pmid = {8524021},
	keywords = {Acoustic Stimulation, Adult, Brain, Cerebrovascular Circulation, Echo-Planar Imaging, Electroencephalography, Female, Fingers, Hand, Humans, Magnetic Resonance Imaging, Male, Motor Cortex, Motor Skills, Movement, Neurons, Oxygen, Photic Stimulation, Psychomotor Performance, Rest, Somatosensory Cortex},
	pages = {537--541},
	annote = {Functional Connectivity : Correlation, Cross-Correlation, Zero-order correlation},
	file = {[Biswal.1995] Functional connectivity in the motor cortex of resting human brain using.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Define FC/[Biswal.1995] Functional connectivity in the motor cortex of resting human brain using.pdf:application/pdf}
}

@article{lambiotte_random_2014,
	title = {Random {Walks}, {Markov} {Processes} and the {Multiscale} {Modular} {Organization} of {Complex} {Networks}},
	volume = {1},
	issn = {2327-4697},
	url = {http://ieeexplore.ieee.org/document/7010026/},
	doi = {10.1109/TNSE.2015.2391998},
	number = {2},
	urldate = {2016-10-18},
	journal = {IEEE Transactions on Network Science and Engineering},
	author = {Lambiotte, Renaud and Delvenne, Jean-Charles and Barahona, Mauricio},
	month = jul,
	year = {2014},
	pages = {76--90},
	file = {[Lambiotte.2014] Random Walks, Markov Processes and the Multiscale Modular Organization of.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P4. Network/S2. Modularity/[Lambiotte.2014] Random Walks, Markov Processes and the Multiscale Modular Organization of.pdf:application/pdf}
}

@article{liang_equivalent_2015,
	title = {An {Equivalent} {Measure} of {Partial} {Correlation} {Coefficients} for {High}-{Dimensional} {Gaussian} {Graphical} {Models}},
	volume = {110},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/full/10.1080/01621459.2015.1012391},
	doi = {10.1080/01621459.2015.1012391},
	language = {en},
	number = {511},
	urldate = {2016-09-03},
	journal = {Journal of the American Statistical Association},
	author = {Liang, Faming and Song, Qifan and Qiu, Peihua},
	month = jul,
	year = {2015},
	pages = {1248--1265},
	file = {[Liang.2015] An Equivalent Measure of Partial Correlation Coefficients for High-Dimensional.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/[Liang.2015] An Equivalent Measure of Partial Correlation Coefficients for High-Dimensional.pdf:application/pdf}
}

@article{van_essen_human_2012,
	title = {The {Human} {Connectome} {Project}: {A} data acquisition perspective},
	volume = {62},
	issn = {10538119},
	shorttitle = {The {Human} {Connectome} {Project}},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811912001954},
	doi = {10.1016/j.neuroimage.2012.02.018},
	language = {en},
	number = {4},
	urldate = {2016-06-29},
	journal = {NeuroImage},
	author = {Van Essen, D.C. and Ugurbil, K. and Auerbach, E. and Barch, D. and Behrens, T.E.J. and Bucholz, R. and Chang, A. and Chen, L. and Corbetta, M. and Curtiss, S.W. and Della Penna, S. and Feinberg, D. and Glasser, M.F. and Harel, N. and Heath, A.C. and Larson-Prior, L. and Marcus, D. and Michalareas, G. and Moeller, S. and Oostenveld, R. and Petersen, S.E. and Prior, F. and Schlaggar, B.L. and Smith, S.M. and Snyder, A.Z. and Xu, J. and Yacoub, E.},
	month = oct,
	year = {2012},
	pages = {2222--2231},
	annote = {HCP : Overview for the last 5 years},
	file = {[Van Essen.2012] The Human Connectome Project.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Data Issues/[Van Essen.2012] The Human Connectome Project.pdf:application/pdf}
}

@article{fischl_automatically_2004,
	title = {Automatically parcellating the human cerebral cortex},
	volume = {14},
	issn = {1047-3211},
	abstract = {We present a technique for automatically assigning a neuroanatomical label to each location on a cortical surface model based on probabilistic information estimated from a manually labeled training set. This procedure incorporates both geometric information derived from the cortical model, and neuroanatomical convention, as found in the training set. The result is a complete labeling of cortical sulci and gyri. Examples are given from two different training sets generated using different neuroanatomical conventions, illustrating the flexibility of the algorithm. The technique is shown to be comparable in accuracy to manual labeling.},
	language = {eng},
	number = {1},
	journal = {Cereb. Cortex},
	author = {Fischl, Bruce and van der Kouwe, André and Destrieux, Christophe and Halgren, Eric and Ségonne, Florent and Salat, David H. and Busa, Evelina and Seidman, Larry J. and Goldstein, Jill and Kennedy, David and Caviness, Verne and Makris, Nikos and Rosen, Bruce and Dale, Anders M.},
	month = jan,
	year = {2004},
	pmid = {14654453},
	keywords = {Algorithms, Anisotropy, Artificial Intelligence, Bayes Theorem, Brain Mapping, Cerebral Cortex, Functional Laterality, Humans, Image Processing, Computer-Assisted, Markov Chains, Models, Neurological, Models, Statistical, Schizophrenia},
	pages = {11--22},
	annote = {Freesurfer : citation : parcellation 2},
	file = {[Fischl.2004] Automatically parcellating the human cerebral cortex.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Data Issues/[Fischl.2004] Automatically parcellating the human cerebral cortex.pdf:application/pdf}
}

@book{duda_pattern_2001,
	address = {New York},
	edition = {2nd ed},
	title = {Pattern classification},
	isbn = {978-0-471-05669-0},
	publisher = {Wiley},
	author = {Duda, Richard O. and Hart, Peter E. and Stork, David G.},
	year = {2001},
	keywords = {Pattern recognition systems, Statistical decision},
	annote = {"A Wiley-Interscience Publication."},
	file = {[Duda.2001] Pattern classification.pdf:/home/kisung/Dropbox/V3. Statistics/P6. ML/S5. Lecture-Yonsei/[Duda.2001] Pattern classification.pdf:application/pdf}
}

@article{binkiewicz_covariate-assisted_2014,
	title = {Covariate-assisted spectral clustering},
	journal = {ArXiv e-prints},
	author = {Binkiewicz, N. and Vogelstein, J. T. and Rohe, K.},
	month = nov,
	year = {2014},
	keywords = {Computer Science - Learning, Mathematics - Statistics Theory, Statistics - Machine Learning, Statistics - Methodology},
	file = {[Binkiewicz.2014] Covariate-assisted spectral clustering.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P3. SGT/Topics/[Binkiewicz.2014] Covariate-assisted spectral clustering.pdf:application/pdf}
}

@article{sun_measuring_2004,
	title = {Measuring interregional functional connectivity using coherence and partial coherence analyses of {fMRI} data},
	volume = {21},
	issn = {1053-8119},
	doi = {10.1016/j.neuroimage.2003.09.056},
	abstract = {Understanding functional connectivity within the brain is crucial to understanding neural function; even the simplest cognitive operations are supported by highly distributed neural circuits. We developed a novel method to measure task-related functional interactions between neural regions by applying coherence and partial coherence analyses to functional magnetic resonance imaging (fMRI) data. Coherence and partial coherence are spectral measures that estimate the linear time-invariant (LTI) relationship between time series. They can be used to generate maps of task-specific connectivity associated with seed regions of interest (ROIs). These maps may then be compared across tasks, revealing nodes with task-related changes of connectivity to the seed ROI. To validate the method, we applied it to an event-related fMRI data set acquired while subjects performed two sequence tapping tasks, one of which required more bimanual coordination. Areas showing increased functional connectivity with both tasks were the same as those showing increased activity. Furthermore, though there were no significant differences in mean activity between the two tasks, significant increases in interhemispheric coherence were found between the primary motor (M1) and premotor (PM) regions for the task requiring more bimanual coordination. This increase in interhemispheric connectivity is supported by other brain imaging techniques as well as patient studies.},
	language = {eng},
	number = {2},
	journal = {Neuroimage},
	author = {Sun, Felice T. and Miller, Lee M. and D'Esposito, Mark},
	month = feb,
	year = {2004},
	pmid = {14980567},
	keywords = {Adolescent, Adult, Attention, Brain, Brain Mapping, Dominance, Cerebral, Female, Fourier Analysis, Functional Laterality, Humans, Image Enhancement, Image Processing, Computer-Assisted, Linear Models, Magnetic Resonance Imaging, Male, Mathematical Computing, Motor Activity, Motor Cortex, Nerve Net, Oxygen Consumption, Psychomotor Performance},
	pages = {647--658},
	annote = {Functional Connectivity : Cross-coherence, spectral coherence},
	file = {[Sun.2004] Measuring interregional functional connectivity using coherence and partial.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Define FC/[Sun.2004] Measuring interregional functional connectivity using coherence and partial.pdf:application/pdf}
}

@book{demmel_applied_1997,
	address = {Philadelphia},
	title = {Applied numerical linear algebra},
	isbn = {978-0-89871-389-3},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Demmel, James W.},
	year = {1997},
	keywords = {Algebras, Linear, Numerical calculations},
	file = {[Demmel.1997] Applied numerical linear algebra.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P2. Numerical/S1. Yonsei-Analysis/[Demmel.1997] Applied numerical linear algebra.pdf:application/pdf}
}

@book{gelman_bayesian_2014,
	address = {Boca Raton},
	edition = {Third edition},
	series = {Chapman \& {Hall}/{CRC} texts in statistical science},
	title = {Bayesian data analysis},
	isbn = {978-1-4398-4095-5},
	abstract = {"Preface This book is intended to have three roles and to serve three associated audiences: an introductory text on Bayesian inference starting from first principles, a graduate text on effective current approaches to Bayesian modeling and computation in statistics and related fields, and a handbook of Bayesian methods in applied statistics for general users of and researchers in applied statistics. Although introductory in its early sections, the book is definitely not elementary in the sense of a first text in statistics. The mathematics used in our book is basic probability and statistics, elementary calculus, and linear algebra. A review of probability notation is given in Chapter 1 along with a more detailed list of topics assumed to have been studied. The practical orientation of the book means that the reader's previous experience in probability, statistics, and linear algebra should ideally have included strong computational components. To write an introductory text alone would leave many readers with only a taste of the conceptual elements but no guidance for venturing into genuine practical applications, beyond those where Bayesian methods agree essentially with standard non-Bayesian analyses. On the other hand, we feel it would be a mistake to present the advanced methods without first introducing the basic concepts from our data-analytic perspective. Furthermore, due to the nature of applied statistics, a text on current Bayesian methodology would be incomplete without a variety of worked examples drawn from real applications. To avoid cluttering the main narrative, there are bibliographic notes at the end of each chapter and references at the end of the book"--},
	publisher = {CRC Press},
	author = {Gelman, Andrew},
	year = {2014},
	keywords = {Bayesian statistical decision theory, MATHEMATICS / Probability \& Statistics / General},
	file = {[Gelman.2014] Bayesian data analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/SLect_Gelman/[Gelman.2014] Bayesian data analysis.pdf:application/pdf}
}

@book{tan_introduction_2006,
	address = {Boston},
	edition = {1st ed},
	title = {Introduction to data mining},
	isbn = {978-0-321-32136-7},
	publisher = {Pearson Addison Wesley},
	author = {Tan, Pang-Ning and Steinbach, Michael and Kumar, Vipin},
	year = {2006},
	keywords = {Data mining},
	file = {[Tan.2006] Introduction to data mining_3.pdf:/home/kisung/Dropbox/VC. Coursework/P3. Statistics/1. Data Mining/[Tan.2006] Introduction to data mining_3.pdf:application/pdf;[Tan.2006] Introduction to data mining.pdf:/home/kisung/Dropbox/VC. Coursework/P3. Statistics/1. Data Mining/[Tan.2006] Introduction to data mining.pdf:application/pdf}
}

@article{van_den_heuvel_rich-club_2011,
	title = {Rich-{Club} {Organization} of the {Human} {Connectome}},
	volume = {31},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3539-11.2011},
	doi = {10.1523/JNEUROSCI.3539-11.2011},
	language = {en},
	number = {44},
	urldate = {2016-07-12},
	journal = {Journal of Neuroscience},
	author = {van den Heuvel, M. P. and Sporns, O.},
	month = nov,
	year = {2011},
	pages = {15775--15786},
	annote = {Modular Interaction based on structural topology 4}
}

@article{bressler_large-scale_2010,
	title = {Large-scale brain networks in cognition: emerging methods and principles},
	volume = {14},
	issn = {13646613},
	shorttitle = {Large-scale brain networks in cognition},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661310000896},
	doi = {10.1016/j.tics.2010.04.004},
	language = {en},
	number = {6},
	urldate = {2016-07-12},
	journal = {Trends in Cognitive Sciences},
	author = {Bressler, Steven L. and Menon, Vinod},
	month = jun,
	year = {2010},
	pages = {277--290},
	annote = {multiple local clusters are recruited to construct a single cognitive function}
}

@book{banerjee_hierarchical_2015,
	address = {Boca Raton},
	edition = {Second edition},
	series = {Monographs on statistics and applied probability},
	title = {Hierarchical modeling and analysis for spatial data},
	isbn = {978-1-4398-1917-3},
	number = {135},
	publisher = {CRC Press, Taylor \& Francis Group},
	author = {Banerjee, Sudipto and Carlin, Bradley P. and Gelfand, Alan E.},
	year = {2015},
	keywords = {Mathematical models, Spatial analysis (Statistics)},
	annote = {"A Chapman \& Hall book."},
	file = {[Banerjee.2015] Hierarchical modeling and analysis for spatial data.pdf:/home/kisung/Dropbox/V3. Statistics/P8. SpatioTemporal/S1. Spatial Analysis/[Banerjee.2015] Hierarchical modeling and analysis for spatial data.pdf:application/pdf}
}

@article{desikan_automated_2006,
	title = {An automated labeling system for subdividing the human cerebral cortex on {MRI} scans into gyral based regions of interest},
	volume = {31},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811906000437},
	doi = {10.1016/j.neuroimage.2006.01.021},
	language = {en},
	number = {3},
	urldate = {2016-07-03},
	journal = {NeuroImage},
	author = {Desikan, Rahul S. and Ségonne, Florent and Fischl, Bruce and Quinn, Brian T. and Dickerson, Bradford C. and Blacker, Deborah and Buckner, Randy L. and Dale, Anders M. and Maguire, R. Paul and Hyman, Bradley T. and Albert, Marilyn S. and Killiany, Ronald J.},
	month = jul,
	year = {2006},
	pages = {968--980},
	annote = {Freesurfer : citation : parcellation 1},
	file = {[Desikan.2006] An automated labeling system for subdividing the human cerebral cortex on MRI.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Data Issues/[Desikan.2006] An automated labeling system for subdividing the human cerebral cortex on MRI.pdf:application/pdf}
}

@article{rosvall_maps_2008,
	title = {Maps of random walks on complex networks reveal community structure},
	volume = {105},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0706851105},
	doi = {10.1073/pnas.0706851105},
	language = {en},
	number = {4},
	urldate = {2016-06-15},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Rosvall, M. and Bergstrom, C. T.},
	month = jan,
	year = {2008},
	pages = {1118--1123},
	annote = {Infomap: community detection via random walks},
	file = {[Rosvall.2008] Maps of random walks on complex networks reveal community structure.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Detect Modules/[Rosvall.2008] Maps of random walks on complex networks reveal community structure.pdf:application/pdf}
}

@article{park_structural_2013,
	title = {Structural and {Functional} {Brain} {Networks}: {From} {Connections} to {Cognition}},
	volume = {342},
	issn = {0036-8075, 1095-9203},
	shorttitle = {Structural and {Functional} {Brain} {Networks}},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1238411},
	doi = {10.1126/science.1238411},
	language = {en},
	number = {6158},
	urldate = {2016-06-08},
	journal = {Science},
	author = {Park, H.-J. and Friston, K.},
	month = nov,
	year = {2013},
	pages = {1238411--1238411},
	file = {[Park.2013] Structural and Functional Brain Networks.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Define FC/[Park.2013] Structural and Functional Brain Networks.pdf:application/pdf}
}

@misc{penny_variational_2000,
	title = {Variational {Bayes} for 1-d {Mixture} {Models}},
	author = {Penny, Will},
	year = {2000},
	file = {[Penny.2000] Variational Bayes for 1-d Mixture Models.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/Topics/[Penny.2000] Variational Bayes for 1-d Mixture Models.pdf:application/pdf}
}

@article{traag_community_2009,
	title = {Community detection in networks with positive and negative links},
	volume = {80},
	issn = {1539-3755, 1550-2376},
	url = {http://link.aps.org/doi/10.1103/PhysRevE.80.036115},
	doi = {10.1103/PhysRevE.80.036115},
	language = {en},
	number = {3},
	urldate = {2016-10-17},
	journal = {Physical Review E},
	author = {Traag, V. A. and Bruggeman, Jeroen},
	month = sep,
	year = {2009},
	file = {[Traag.2009] Community detection in networks with positive and negative links.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P3. SGT/Topics/[Traag.2009] Community detection in networks with positive and negative links.pdf:application/pdf}
}

@book{chung_spectral_1997,
	address = {Providence, R.I},
	series = {Regional conference series in mathematics},
	title = {Spectral graph theory},
	isbn = {978-0-8218-0315-8},
	number = {no. 92},
	publisher = {Published for the Conference Board of the mathematical sciences by the American Mathematical Society},
	author = {Chung, Fan R. K.},
	year = {1997},
	keywords = {Congresses, Eigenvalues, Graph theory},
	annote = {"CBMS Conference on Recent Advances in Spectral Graph Theory held at California State University at Fresno, June 6-10, 1994"--T.p. verso},
	file = {[Chung.1997] Spectral graph theory.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P3. SGT/S1. Basics/[Chung.1997] Spectral graph theory.pdf:application/pdf}
}

@article{van_der_maaten_learning_2009,
	title = {Learning a parametric embedding by preserving local structure},
	journal = {Proceedings of AI-STATS},
	author = {van der Maaten, Laurens},
	year = {2009},
	annote = {t-SNE with regression schemes for out-of-sample extensions},
	file = {[van der Maaten.2009] Learning a parametric embedding by preserving local structure.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/02. tSNE/[van der Maaten.2009] Learning a parametric embedding by preserving local structure.pdf:application/pdf}
}

@article{bounova_overview_2012,
	title = {Overview of metrics and their correlation patterns for multiple-metric topology analysis on heterogeneous graph ensembles},
	volume = {85},
	issn = {1539-3755, 1550-2376},
	url = {http://link.aps.org/doi/10.1103/PhysRevE.85.016117},
	doi = {10.1103/PhysRevE.85.016117},
	language = {en},
	number = {1},
	urldate = {2016-06-21},
	journal = {Physical Review E},
	author = {Bounova, Gergana and de Weck, Olivier},
	month = jan,
	year = {2012},
	annote = {MIT network toolbox}
}

@article{sarzynska_null_2016,
	title = {Null models for community detection in spatially embedded, temporal networks},
	volume = {4},
	issn = {2051-1310, 2051-1329},
	url = {http://comnet.oxfordjournals.org/lookup/doi/10.1093/comnet/cnv027},
	doi = {10.1093/comnet/cnv027},
	language = {en},
	number = {3},
	urldate = {2016-10-18},
	journal = {Journal of Complex Networks},
	author = {Sarzynska, Marta and Leicht, Elizabeth A. and Chowell, Gerardo and Porter, Mason A.},
	month = sep,
	year = {2016},
	pages = {363--406},
	file = {[Sarzynska.2016] Null models for community detection in spatially embedded, temporal networks.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P4. Network/S2. Modularity/[Sarzynska.2016] Null models for community detection in spatially embedded, temporal networks.pdf:application/pdf}
}

@article{pearson_liii._1901,
	title = {{LIII}. {On} lines and planes of closest fit to systems of points in space},
	volume = {2},
	issn = {1941-5982, 1941-5990},
	url = {http://www.tandfonline.com/doi/abs/10.1080/14786440109462720},
	doi = {10.1080/14786440109462720},
	language = {en},
	number = {11},
	urldate = {2016-07-04},
	journal = {Philosophical Magazine Series 6},
	author = {Pearson, Karl},
	month = nov,
	year = {1901},
	pages = {559--572},
	annote = {PCA : Original Paper by Pearson},
	file = {[Pearson.1901] LIII.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/03. PCA/[Pearson.1901] LIII.pdf:application/pdf}
}

@article{sporns_modular_2016,
	title = {Modular {Brain} {Networks}},
	volume = {67},
	issn = {0066-4308},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4782188/},
	doi = {10.1146/annurev-psych-122414-033634},
	abstract = {The development of new technologies for mapping structural and functional brain connectivity has led to the creation of comprehensive network maps of neuronal circuits and systems. The architecture of these brain networks can be examined and analyzed with a large variety of graph theory tools. Methods for detecting modules, or network communities, are of particular interest because they uncover major building blocks or subnetworks that are particularly densely connected, often corresponding to specialized functional components. A large number of methods for community detection have become available and are now widely applied in network neuroscience. This article first surveys a number of these methods, with an emphasis on their advantages and shortcomings; then it summarizes major findings on the existence of modules in both structural and functional brain networks and briefly considers their potential functional roles in brain evolution, wiring minimization, and the emergence of functional specialization and complex dynamics.},
	urldate = {2016-05-25},
	journal = {Annu Rev Psychol},
	author = {Sporns, Olaf and Betzel, Richard F.},
	month = jan,
	year = {2016},
	pmid = {26393868},
	pmcid = {PMC4782188},
	pages = {613--640},
	file = {[Sporns.2016] Modular Brain Networks.pdf:/home/kisung/Dropbox/V5. Neuroscience/D20160413/[Sporns.2016] Modular Brain Networks.pdf:application/pdf}
}

@book{scholkopf_learning_2002,
	address = {Cambridge, Mass},
	series = {Adaptive computation and machine learning},
	title = {Learning with kernels: support vector machines, regularization, optimization, and beyond},
	isbn = {978-0-262-19475-4},
	shorttitle = {Learning with kernels},
	publisher = {MIT Press},
	author = {Schölkopf, Bernhard and Smola, Alexander J.},
	year = {2002},
	keywords = {Kernel functions, support vector machines},
	annote = {Kernel Trick is well described},
	file = {[Schölkopf.2002] Learning with kernels.pdf:/home/kisung/Dropbox/V3. Statistics/P6. Machine Learning/S1. Additional Topics/[Schölkopf.2002] Learning with kernels.pdf:application/pdf}
}

@article{von_luxburg_tutorial_2007,
	title = {A tutorial on spectral clustering},
	volume = {17},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-007-9033-z},
	doi = {10.1007/s11222-007-9033-z},
	language = {en},
	number = {4},
	urldate = {2016-10-13},
	journal = {Statistics and Computing},
	author = {von Luxburg, Ulrike},
	month = dec,
	year = {2007},
	keywords = {Artificial Intelligence (incl. Robotics), Graph Laplacian, Mathematics, general, Numeric Computing, Spectral clustering, Statistics and Computing/Statistics Programs, Statistics, general},
	pages = {395--416},
	file = {[Luxburg.2007] A tutorial on spectral clustering.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/[Luxburg.2007] A tutorial on spectral clustering.pdf:application/pdf;[von Luxburg.2007] A tutorial on spectral clustering.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P3. SGT/S1. Basics/[von Luxburg.2007] A tutorial on spectral clustering.pdf:application/pdf;Snapshot:/home/kisung/.mozilla/firefox/7xt7fha3.default/zotero/storage/J2HE79IQ/s11222-007-9033-z.html:text/html}
}

@article{giuseppe_introduction_2011,
	title = {An introduction to spectral distances in networks},
	copyright = {©2011 \&copy; The authors and IOS Press. All rights reserved.},
	issn = {0922-6389},
	url = {http://www.medra.org/servlet/aliasResolver?alias=iospressISSNISBN&issn=0922-6389&volume=226&spage=227},
	doi = {10.3233/978-1-60750-692-8-227},
	abstract = {Many functions have been recently defined to assess the similarity among networks as tools for quantitative comparison. They stem from very different frameworks - and they are tuned for dealing with different situations. Here we show an overview of the spectral distances, highlighting their behavior in some basic cases of static and dynamic synthetic and real networks. In particular, we show examples where spectral distances are more effective than classical methods in assessing network differences.},
	urldate = {2016-10-17},
	journal = {Frontiers in Artificial Intelligence and Applications},
	author = {Giuseppe, Jurman and Roberto, Visintainer and Cesare, Furlanello},
	year = {2011},
	pages = {227--234},
	file = {[Giuseppe.2011] An introduction to spectral distances in networks.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P3. SGT/Topics/[Giuseppe.2011] An introduction to spectral distances in networks.pdf:application/pdf}
}

@inproceedings{belkin_convergence_2006,
	title = {Convergence of laplacian eigenmaps},
	booktitle = {In {NIPS}},
	author = {Belkin, Mikhail and Niyogi, Partha},
	year = {2006},
	file = {[Belkin.2006] Convergence of laplacian eigenmaps.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/03. LAPEIG/[Belkin.2006] Convergence of laplacian eigenmaps.pdf:application/pdf}
}

@article{park_evaluation_2013,
	title = {Evaluation of {Node}-{Inhomogeneity} {Effects} on the {Functional} {Brain} {Network} {Properties} {Using} an {Anatomy}-{Constrained} {Hierarchical} {Brain} {Parcellation}},
	volume = {8},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0074935},
	doi = {10.1371/journal.pone.0074935},
	language = {en},
	number = {9},
	urldate = {2016-07-12},
	journal = {PLoS ONE},
	author = {Park, Bumhee and Ko, Jeong Hoon and Lee, Jong Doo and Park, Hae-Jeong},
	editor = {Zuo, Xi-Nian},
	month = sep,
	year = {2013},
	pages = {e74935},
	annote = {nodal heterogeneity reseults in inconsistent FC constructions}
}

@article{kyeong_functional_2014,
	title = {Functional network organizations of two contrasting temperament groups in dimensions of novelty seeking and harm avoidance},
	volume = {1575},
	issn = {00068993},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0006899314007525},
	doi = {10.1016/j.brainres.2014.05.037},
	language = {en},
	urldate = {2016-07-12},
	journal = {Brain Research},
	author = {Kyeong, Sunghyon and Kim, Eunjoo and Park, Hae-Jeong and Hwang, Dong-Uk},
	month = aug,
	year = {2014},
	pages = {33--44},
	annote = {modularity of the brain varies across individuals across characters}
}

@article{erdos_random_1959,
	title = {On random graphs {I}.},
	volume = {6},
	journal = {Publ. Math. Debrecen},
	author = {Erdős, Paul and Rényi, Alfréd},
	year = {1959},
	pages = {290--297},
	annote = {Introduction to ER model, Erdos Renyi Random Graph Model, The Very First Start of the topic},
	file = {[Erdős.1959] On random graphs I.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P4. Network/[Erdős.1959] On random graphs I.pdf:application/pdf}
}

@article{geerligs_functional_2016,
	title = {Functional connectivity and structural covariance between regions of interest can be measured more accurately using multivariate distance correlation},
	volume = {135},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811916300878},
	doi = {10.1016/j.neuroimage.2016.04.047},
	language = {en},
	urldate = {2016-06-19},
	journal = {NeuroImage},
	author = {Geerligs, Linda and {Cam-CAN} and Henson, Richard N.},
	month = jul,
	year = {2016},
	pages = {16--31},
	annote = {use of Wikipedia and Szelesky's distance correlation as of measurements for functional connectivity},
	file = {[Geerligs.2016] Functional connectivity and structural covariance between regions of interest.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Define FC/[Geerligs.2016] Functional connectivity and structural covariance between regions of interest.pdf:application/pdf}
}

@article{van_der_maaten_dimensionality_2009,
	title = {Dimensionality reduction: {A} comparative review},
	journal = {Technical Report TiCC TR 2009-005},
	author = {Van der Maaten, LJP and Postma, EO and Van den Herik, HJ},
	year = {2009},
	file = {[Van der Maaten.2009] Dimensionality reduction.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/[Van der Maaten.2009] Dimensionality reduction.pdf:application/pdf}
}

@incollection{goos_comparing_2003,
	address = {Berlin, Heidelberg},
	title = {Comparing {Clusterings} by the {Variation} of {Information}},
	volume = {2777},
	isbn = {978-3-540-40720-1 978-3-540-45167-9},
	url = {http://link.springer.com/10.1007/978-3-540-45167-9_14},
	urldate = {2016-06-10},
	booktitle = {Learning {Theory} and {Kernel} {Machines}},
	publisher = {Springer Berlin Heidelberg},
	author = {Meilă, Marina},
	editor = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Schölkopf, Bernhard and Warmuth, Manfred K.},
	year = {2003},
	pages = {173--187},
	annote = {Variation of Information : First Suggested and Proved that it is truly METRIC, has UPPER BOUNDS, n-invariance and other properties},
	file = {[Meilă.2003] Comparing Clusterings by the Variation of Information.pdf:/home/kisung/Dropbox/V3. Statistics/P6. ML/S1. Additional Topics/1. Clustering Comparison/[Meilă.2003] Comparing Clusterings by the Variation of Information.pdf:application/pdf}
}

@article{figueiredo_unsupervised_2002,
	title = {Unsupervised learning of finite mixture models},
	volume = {24},
	issn = {0162-8828},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=990138},
	doi = {10.1109/34.990138},
	number = {3},
	urldate = {2016-07-25},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Figueiredo, M.A.T. and Jain, A.K.},
	month = mar,
	year = {2002},
	pages = {381--396},
	annote = {Finite Mixture Models and Unsupervised Learning},
	file = {[Figueiredo.2002] Unsupervised learning of finite mixture models.pdf:/home/kisung/Dropbox/V3. Statistics/P6. Machine Learning/S4. Tools_Unsupervised/[Figueiredo.2002] Unsupervised learning of finite mixture models.pdf:application/pdf}
}

@book{phadia_prior_2013,
	address = {New York},
	edition = {1st edition},
	title = {Prior processes and their applications: nonparametric bayesian estimation},
	isbn = {978-3-642-39279-5},
	shorttitle = {Prior processes and their applications},
	publisher = {Springer},
	author = {Phadia, Eswar G.},
	year = {2013},
	file = {[Phadia.2013] Prior processes and their applications.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/S4. Process-Prior/[Phadia.2013] Prior processes and their applications.pdf:application/pdf}
}

@book{tsybakov_introduction_2009,
	address = {New York ; London},
	series = {Springer series in statistics},
	title = {Introduction to nonparametric estimation},
	isbn = {978-0-387-79051-0 978-0-387-79052-7},
	publisher = {Springer},
	author = {Tsybakov, Alexandre B.},
	year = {2009},
	note = {OCLC: ocn300399286},
	keywords = {Estimation theory, Nonparametric statistics},
	file = {[Tsybakov.2009] Introduction to nonparametric estimation.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/[Tsybakov.2009] Introduction to nonparametric estimation.pdf:application/pdf}
}

@article{salvador_undirected_2005,
	title = {Undirected graphs of frequency-dependent functional connectivity in whole brain networks},
	volume = {360},
	issn = {0962-8436, 1471-2970},
	url = {http://rstb.royalsocietypublishing.org/cgi/doi/10.1098/rstb.2005.1645},
	doi = {10.1098/rstb.2005.1645},
	language = {en},
	number = {1457},
	urldate = {2016-06-09},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Salvador, R. and Suckling, J. and Schwarzbauer, C. and Bullmore, E.},
	month = may,
	year = {2005},
	pages = {937--946},
	annote = {Functional Connectivity : extension of bivariate measures to multivariate cross-correllation, multivariate coherence and multivariate mutual information},
	file = {[Salvador.2005] Undirected graphs of frequency-dependent functional connectivity in whole brain.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Define FC/[Salvador.2005] Undirected graphs of frequency-dependent functional connectivity in whole brain.pdf:application/pdf}
}

@article{shirkhorshidi_comparison_2015,
	title = {A {Comparison} {Study} on {Similarity} and {Dissimilarity} {Measures} in {Clustering} {Continuous} {Data}},
	volume = {10},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0144059},
	doi = {10.1371/journal.pone.0144059},
	language = {en},
	number = {12},
	urldate = {2016-10-18},
	journal = {PLOS ONE},
	author = {Shirkhorshidi, Ali Seyed and Aghabozorgi, Saeed and Wah, Teh Ying},
	editor = {Dalby, Andrew R.},
	month = dec,
	year = {2015},
	pages = {e0144059},
	file = {[Shirkhorshidi.2015] A Comparison Study on Similarity and Dissimilarity Measures in Clustering.PDF:/home/kisung/Dropbox/V2. Applied Mathematics/P4. Network/Topics/[Shirkhorshidi.2015] A Comparison Study on Similarity and Dissimilarity Measures in Clustering.PDF:application/pdf}
}

@book{shumway_time_2011,
	address = {New York, NY},
	series = {Springer {Texts} in {Statistics}},
	title = {Time {Series} {Analysis} and {Its} {Applications}},
	isbn = {978-1-4419-7864-6 978-1-4419-7865-3},
	url = {http://link.springer.com/10.1007/978-1-4419-7865-3},
	urldate = {2016-06-09},
	publisher = {Springer New York},
	author = {Shumway, Robert H. and Stoffer, David S.},
	year = {2011},
	annote = {Functional Connectivity : using whole time-series signals indicates the assumption of stationary signals, inferring that the relationships are probabilistically consistent over time.}
}

@article{sternberg_modular_2011,
	title = {Modular processes in mind and brain},
	volume = {28},
	issn = {0264-3294, 1464-0627},
	url = {http://www.tandfonline.com/doi/abs/10.1080/02643294.2011.557231},
	doi = {10.1080/02643294.2011.557231},
	language = {en},
	number = {3-4},
	urldate = {2016-07-12},
	journal = {Cognitive Neuropsychology},
	author = {Sternberg, Saul},
	month = jun,
	year = {2011},
	pages = {156--208},
	annote = {Brain has a modular architecture that segregates functions in a hierarchical manner}
}

@inproceedings{bengio_out--sample_2003,
	title = {Out-of-{Sample} {Extensions} for {LLE}, {Isomap}, {MDS}, {Eigenmaps}, and {Spectral} {Clustering}},
	url = {http://papers.nips.cc/paper/2461-out-of-sample-extensions-for-lle-isomap-mds-eigenmaps-and-spectral-clustering},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 16 [{Neural} {Information} {Processing} {Systems}, {NIPS} 2003, {December} 8-13, 2003, {Vancouver} and {Whistler}, {British} {Columbia}, {Canada}]},
	author = {Bengio, Yoshua and Paiement, Jean-François and Vincent, Pascal and Delalleau, Olivier and Roux, Nicolas Le and Ouimet, Marie},
	year = {2003},
	pages = {177--184},
	annote = {New data * out-of-sample data * and how to approximate},
	file = {[Bengio.2003] Out-of-Sample Extensions for LLE, Isomap, MDS, Eigenmaps, and Spectral.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S3. Notes/[Bengio.2003] Out-of-Sample Extensions for LLE, Isomap, MDS, Eigenmaps, and Spectral.pdf:application/pdf}
}

@article{coifman_geometric_2005,
	title = {Geometric diffusions as a tool for harmonic analysis and structure definition of data: {Multiscale} methods},
	volume = {102},
	issn = {0027-8424, 1091-6490},
	shorttitle = {Geometric diffusions as a tool for harmonic analysis and structure definition of data},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0500896102},
	doi = {10.1073/pnas.0500896102},
	language = {en},
	number = {21},
	urldate = {2016-07-04},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Coifman, R. R. and Lafon, S. and Lee, A. B. and Maggioni, M. and Nadler, B. and Warner, F. and Zucker, S. W.},
	month = may,
	year = {2005},
	pages = {7432--7437},
	annote = {Diffusion Maps:1st:PNAS Introduction Paper},
	file = {[Coifman.2005] Geometric diffusions as a tool for harmonic analysis and structure definition.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/01. DM/[Coifman.2005] Geometric diffusions as a tool for harmonic analysis and structure definition.pdf:application/pdf}
}

@book{bishop_pattern_2006,
	address = {New York},
	series = {Information science and statistics},
	title = {Pattern recognition and machine learning},
	isbn = {978-0-387-31073-2},
	publisher = {Springer},
	author = {Bishop, Christopher M.},
	year = {2006},
	keywords = {Pattern perception, machine learning},
	file = {[Bishop.2006] Pattern recognition and machine learning.pdf:/home/kisung/Dropbox/V3. Statistics/P6. ML/[Bishop.2006] Pattern recognition and machine learning.pdf:application/pdf}
}

@article{jenkinson_fsl_2012,
	title = {{FSL}},
	volume = {62},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811911010603},
	doi = {10.1016/j.neuroimage.2011.09.015},
	language = {en},
	number = {2},
	urldate = {2016-06-29},
	journal = {NeuroImage},
	author = {Jenkinson, Mark and Beckmann, Christian F. and Behrens, Timothy E.J. and Woolrich, Mark W. and Smith, Stephen M.},
	month = aug,
	year = {2012},
	pages = {782--790},
	annote = {HCP Standard Pre-processing Protocol 2},
	file = {[Jenkinson.2012] FSL.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Data Issues/[Jenkinson.2012] FSL.pdf:application/pdf}
}

@book{grimmett_probability_2001,
	address = {Oxford ; New York},
	edition = {3rd ed},
	title = {Probability and random processes},
	isbn = {978-0-19-857223-7 978-0-19-857222-0},
	publisher = {Oxford University Press},
	author = {Grimmett, Geoffrey and Stirzaker, David},
	year = {2001},
	keywords = {Probabilities, Stochastic processes},
	file = {[Grimmett.2001] Probability and random processes.pdf:/home/kisung/Dropbox/VC. Coursework/P1. Math/1. Probability/[Grimmett.2001] Probability and random processes.pdf:application/pdf}
}

@book{cichocki_nonnegative_2009,
	address = {Chichester, U.K},
	title = {Nonnegative matrix and tensor factorizations: applications to exploratory multi-way data analysis and blind source separation},
	isbn = {978-0-470-74666-0},
	shorttitle = {Nonnegative matrix and tensor factorizations},
	publisher = {John Wiley},
	editor = {Cichocki, Andrzej},
	year = {2009},
	note = {OCLC: ocn320432452},
	keywords = {Computer algorithms, Data mining, Data structures (Computer science), machine learning},
	annote = {Problem statements and models -- Similarity measures and generalized divergences -- Multiplicative iterative algorithms for NMF with sparsity constraints -- Alternating least squares and related algorithms for NMF and SCA problems -- Projected gradient algorithms -- Quasi-Newton algorithms for nonnegative matrix factorization -- Multi-way array (tensor) factorizations and decompositions -- Selected applications},
	file = {[Cichocki.2009] Nonnegative matrix and tensor factorizations.pdf:/home/kisung/Dropbox/V3. Statistics/P5. MSL/[Cichocki.2009] Nonnegative matrix and tensor factorizations.pdf:application/pdf}
}

@article{bassett_robust_2013,
	title = {Robust detection of dynamic community structure in networks},
	volume = {23},
	issn = {10541500},
	url = {http://scitation.aip.org/content/aip/journal/chaos/23/1/10.1063/1.4790830},
	doi = {10.1063/1.4790830},
	language = {en},
	number = {1},
	urldate = {2016-10-18},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Bassett, Danielle S. and Porter, Mason A. and Wymbs, Nicholas F. and Grafton, Scott T. and Carlson, Jean M. and Mucha, Peter J.},
	year = {2013},
	pages = {013142},
	file = {[Bassett.2013] Robust detection of dynamic community structure in networks.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P4. Network/S2. Modularity/[Bassett.2013] Robust detection of dynamic community structure in networks.pdf:application/pdf}
}

@article{strehl_cluster_2003,
	title = {Cluster {Ensembles} — a {Knowledge} {Reuse} {Framework} for {Combining} {Multiple} {Partitions}},
	volume = {3},
	issn = {1532-4435},
	url = {http://dx.doi.org/10.1162/153244303321897735},
	doi = {10.1162/153244303321897735},
	journal = {J. Mach. Learn. Res.},
	author = {Strehl, Alexander and Ghosh, Joydeep},
	month = mar,
	year = {2003},
	keywords = {cluster analysis, clustering, consensus functions, ensemble, knowledge reuse, multi-learner systems, mutual information, partitioning, unsupervised learning},
	pages = {583--617},
	file = {[Strehl_Ghosh.2003] Cluster Ensembles — a Knowledge Reuse Framework for Combining Multiple.pdf:/home/kisung/Dropbox/V3. Statistics/P6. ML/S1. Additional Topics/1. Clustering Comparison/[Strehl_Ghosh.2003] Cluster Ensembles — a Knowledge Reuse Framework for Combining Multiple.pdf:application/pdf}
}

@article{diaconis_things_2013,
	title = {Some things we’ve learned (about {Markov} chain {Monte} {Carlo})},
	volume = {19},
	issn = {1350-7265},
	url = {http://projecteuclid.org/euclid.bj/1377612852},
	doi = {10.3150/12-BEJSP09},
	language = {en},
	number = {4},
	urldate = {2016-10-15},
	journal = {Bernoulli},
	author = {Diaconis, Persi},
	month = sep,
	year = {2013},
	pages = {1294--1305},
	file = {[Diaconis.2013] Some things we’ve learned (about Markov chain Monte Carlo).pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/S2. Comp-MCMC/[Diaconis.2013] Some things we’ve learned (about Markov chain Monte Carlo).pdf:application/pdf}
}

@article{zhang_functional_2016,
	title = {Functional {CAR} {Models} for {Large} {Spatially} {Correlated} {Functional} {Datasets}},
	volume = {111},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2015.1042581},
	doi = {10.1080/01621459.2015.1042581},
	language = {en},
	number = {514},
	urldate = {2016-09-03},
	journal = {Journal of the American Statistical Association},
	author = {Zhang, Lin and Baladandayuthapani, Veerabhadran and Zhu, Hongxiao and Baggerly, Keith A. and Majewski, Tadeusz and Czerniak, Bogdan A. and Morris, Jeffrey S.},
	month = apr,
	year = {2016},
	pages = {772--786},
	file = {[Zhang.2016] Functional CAR Models for Large Spatially Correlated Functional Datasets.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/[Zhang.2016] Functional CAR Models for Large Spatially Correlated Functional Datasets.pdf:application/pdf}
}

@article{friston_multivariate_1996,
	title = {A multivariate analysis of {PET} activation studies},
	volume = {4},
	issn = {1065-9471},
	doi = {10.1002/(SICI)1097-0193(1996)4:2<140::AID-HBM5>3.0.CO;2-3},
	abstract = {In this paper we present a general multivariate approach to the analysis of functional imaging studies. This analysis uses standard multivariate techniques to make statistical inferences about activation effects and to describe the important features of these effects. More specifically, the proposed analysis uses multivariate analysis of covariance (ManCova) with Wilk's lambda to test for specific effects of interest (e.g., differences among activation conditions), and canonical variates analysis (CVA) to characterize differential responses in terms of distributed brain systems. The data are subject to ManCova after transformation using their principal components or eigenimages. After significance of the activation effect has been assessed, underlying changes are described in terms of canonical images. Canonical images are like eigenimages but take explicit account of the effects of error or noise. The generality of this approach is assured by the general linear model used in the ManCova. The design and inferences sought are embodied in the design matrix and can, in principle, accommodate most parametric statistical analyses. This multivariate analysis may provide a statistical approach to PET activation studies that 1) complements univariate approaches like statistical parametric mapping, and 2) may facilitate the extension of existing multivariate techniques, like the scaled subprofile model and eigenimage analysis, to include hypothesis testing and statistical inference.},
	language = {eng},
	number = {2},
	journal = {Hum Brain Mapp},
	author = {Friston, K. J. and Poline, J. B. and Holmes, A. P. and Frith, C. D. and Frackowiak, R. S.},
	year = {1996},
	pmid = {20408193},
	pages = {140--151},
	annote = {Apply PCA:PET activitation studies:eigenimages},
	file = {[Friston.1996] A multivariate analysis of PET activation studies.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - SPM/[Friston.1996] A multivariate analysis of PET activation studies.pdf:application/pdf}
}

@article{jeong_mutual_2001,
	title = {Mutual information analysis of the {EEG} in patients with {Alzheimer}'s disease},
	volume = {112},
	issn = {1388-2457},
	abstract = {OBJECTIVE: Mutual information provides a measure of both the linear and nonlinear statistical dependencies between two time series. Cross-mutual information (CMI) is used to quantify the information transmitted from one time series to another, while auto mutual information (AMI) in a time series estimates how much on average the value of the time series can be predicted from values of the time series at preceding points. The aim of this study is to assess information transmission between different cortical areas in Alzheimer's disease (AD) patients by estimating the average CMI between EEG electrodes.
METHODS: We recorded the EEG from 16 scale electrodes in 15 AD patients and 15 age-matched normal controls, and estimated the local, distant, and interhemispheric CMIs of the EEG in both groups. The rate of decrease (with increasing delay) of the AMI of the EEG was also measured to evaluate the complexity of the EEG in AD patients.
RESULTS: The local CMI in AD subjects was lower than that in normal controls, especially over frontal and antero-temporal regions. A prominent decrease in information transmission between distant electrodes in the right hemisphere and between corresponding interhemispheric electrodes was detected in the AD patients. In addition, the AMIs throughout the cerebrums of the AD patients decreased significantly more slowly with delay than did the AMIs of normal controls.
CONCLUSIONS: These results are consistent with previous findings that suggest the association of EEG abnormalities in AD patients with functional impairment of information transmission in long cortico-cortical connections.},
	language = {eng},
	number = {5},
	journal = {Clin Neurophysiol},
	author = {Jeong, J. and Gore, J. C. and Peterson, B. S.},
	month = may,
	year = {2001},
	pmid = {11336898},
	keywords = {Aged, Alzheimer Disease, Brain, Brain Mapping, Electroencephalography, Female, Humans, Male, Nerve Net, Predictive Value of Tests, Probability, Reference Values, Reproducibility of Results},
	pages = {827--835},
	annote = {Functional Connectivity : mutual information for Alzheimer's and control patients},
	file = {[Jeong.2001] Mutual information analysis of the EEG in patients with Alzheimer's disease.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Define FC/[Jeong.2001] Mutual information analysis of the EEG in patients with Alzheimer's disease.pdf:application/pdf}
}

@article{barch_function_2013,
	title = {Function in the human connectome: {Task}-{fMRI} and individual differences in behavior},
	volume = {80},
	issn = {10538119},
	shorttitle = {Function in the human connectome},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811913005272},
	doi = {10.1016/j.neuroimage.2013.05.033},
	language = {en},
	urldate = {2016-07-04},
	journal = {NeuroImage},
	author = {Barch, Deanna M. and Burgess, Gregory C. and Harms, Michael P. and Petersen, Steven E. and Schlaggar, Bradley L. and Corbetta, Maurizio and Glasser, Matthew F. and Curtiss, Sandra and Dixit, Sachin and Feldt, Cindy and Nolan, Dan and Bryant, Edward and Hartley, Tucker and Footer, Owen and Bjork, James M. and Poldrack, Russ and Smith, Steve and Johansen-Berg, Heidi and Snyder, Abraham Z. and Van Essen, David C.},
	month = oct,
	year = {2013},
	pages = {169--189},
	annote = {HCP:Data:Behavioral Scores: Overall Intro},
	file = {[Barch.2013] Function in the human connectome.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Data Issues/[Barch.2013] Function in the human connectome.pdf:application/pdf}
}

@article{newman_community_2013,
	title = {Community detection and graph partitioning},
	volume = {103},
	issn = {0295-5075, 1286-4854},
	url = {http://stacks.iop.org/0295-5075/103/i=2/a=28003?key=crossref.d558b2160418426a76cee0eb5c619a4e},
	doi = {10.1209/0295-5075/103/28003},
	number = {2},
	urldate = {2016-06-15},
	journal = {EPL (Europhysics Letters)},
	author = {Newman, M. E. J.},
	month = jul,
	year = {2013},
	pages = {28003},
	annote = {graph partition / partitioning on community detection
 },
	file = {[Newman.2013] Community detection and graph partitioning.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - Detect Modules/[Newman.2013] Community detection and graph partitioning.pdf:application/pdf}
}

@article{thirion_detection_2006,
	title = {Detection of signal synchronizations in resting-state {fMRI} datasets},
	volume = {29},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811905004878},
	doi = {10.1016/j.neuroimage.2005.06.054},
	language = {en},
	number = {1},
	urldate = {2016-08-08},
	journal = {NeuroImage},
	author = {Thirion, Bertrand and Dodel, Silke and Poline, Jean-Baptiste},
	month = jan,
	year = {2006},
	pages = {321--327},
	annote = {Spectral coherence + Pairwise Average Coherences + PCA, ISOMAP, LAPLACIAN EMBEDDING are used just for single subject.},
	file = {[Thirion.2006] Detection of signal synchronizations in resting-state fMRI datasets.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - FC Dimension Reduction/[Thirion.2006] Detection of signal synchronizations in resting-state fMRI datasets.pdf:application/pdf}
}

@article{roweis_nonlinear_2000,
	title = {Nonlinear {Dimensionality} {Reduction} by {Locally} {Linear} {Embedding}},
	volume = {290},
	issn = {00368075, 10959203},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.290.5500.2323},
	doi = {10.1126/science.290.5500.2323},
	number = {5500},
	urldate = {2016-06-19},
	journal = {Science},
	author = {Roweis, S. T.},
	month = dec,
	year = {2000},
	pages = {2323--2326},
	annote = {LLE : start},
	file = {[Roweis.2000] Nonlinear Dimensionality Reduction by Locally Linear Embedding.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/[Roweis.2000] Nonlinear Dimensionality Reduction by Locally Linear Embedding.pdf:application/pdf}
}

@article{handcock_model-based_2007,
	title = {Model-based clustering for social networks},
	volume = {170},
	issn = {0964-1998, 1467-985X},
	url = {http://doi.wiley.com/10.1111/j.1467-985X.2007.00471.x},
	doi = {10.1111/j.1467-985X.2007.00471.x},
	language = {en},
	number = {2},
	urldate = {2016-10-09},
	journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
	author = {Handcock, Mark S. and Raftery, Adrian E. and Tantrum, Jeremy M.},
	month = mar,
	year = {2007},
	pages = {301--354},
	annote = {LSM03},
	file = {[Handcock.2007] Model-based clustering for social networks.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/LSM/[Handcock.2007] Model-based clustering for social networks.pdf:application/pdf}
}

@article{qiu_manifold_2015,
	title = {Manifold learning on brain functional networks in aging},
	volume = {20},
	issn = {13618415},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1361841514001522},
	doi = {10.1016/j.media.2014.10.006},
	language = {en},
	number = {1},
	urldate = {2016-08-08},
	journal = {Medical Image Analysis},
	author = {Qiu, Anqi and Lee, Annie and Tan, Mingzhen and Chung, Moo K.},
	month = feb,
	year = {2015},
	pages = {52--60},
	annote = {LLE applied to space of subjects' networks : limitation : GLASSO},
	file = {[Qiu.2015] Manifold learning on brain functional networks in aging.pdf:/home/kisung/Dropbox/V5. Neuroscience/Topic - FC Dimension Reduction/[Qiu.2015] Manifold learning on brain functional networks in aging.pdf:application/pdf}
}

@misc{penny_variational_2001,
	title = {Variational {Bayes} for d-d {Mixture} {Models}},
	author = {Penny, Will},
	year = {2001},
	file = {[Penny.2001] Variational Bayes for d-d Mixture Models.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/Topics/[Penny.2001] Variational Bayes for d-d Mixture Models.pdf:application/pdf}
}

@article{meila_comparing_2007,
	title = {Comparing clusterings—an information based distance},
	volume = {98},
	issn = {0047259X},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0047259X06002016},
	doi = {10.1016/j.jmva.2006.11.013},
	language = {en},
	number = {5},
	urldate = {2016-06-19},
	journal = {Journal of Multivariate Analysis},
	author = {Meilă, Marina},
	month = may,
	year = {2007},
	pages = {873--895},
	annote = {normalized variation of information ; variant of variation of information},
	file = {[Meilă.2007] Comparing clusterings—an information based distance.pdf:/home/kisung/Dropbox/V3. Statistics/P6. ML/S1. Additional Topics/1. Clustering Comparison/[Meilă.2007] Comparing clusterings—an information based distance.pdf:application/pdf}
}

@article{van_borkulo_new_2014,
	title = {A new method for constructing networks from binary data},
	volume = {4},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/srep05918},
	doi = {10.1038/srep05918},
	urldate = {2016-12-19},
	journal = {Scientific Reports},
	author = {van Borkulo, Claudia D. and Borsboom, Denny and Epskamp, Sacha and Blanken, Tessa F. and Boschloo, Lynn and Schoevers, Robert A. and Waldorp, Lourens J.},
	month = aug,
	year = {2014},
	file = {[van Borkulo.2014] A new method for constructing networks from binary data.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/Jin01/[van Borkulo.2014] A new method for constructing networks from binary data.pdf:application/pdf}
}

@inproceedings{cawley_sparse_2006,
	address = {Cambridge, MA, USA},
	series = {{NIPS}'06},
	title = {Sparse {Multinomial} {Logistic} {Regression} via {Bayesian} {L}1 {Regularisation}},
	url = {http://dl.acm.org/citation.cfm?id=2976456.2976483},
	booktitle = {Proceedings of the 19th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Cawley, Gavin C. and Talbot, Nicola L. C. and Girolami, Mark},
	year = {2006},
	pages = {209--216},
	file = {[Cawley.2006] Sparse Multinomial Logistic Regression via Bayesian L1 Regularisation.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/Jin01/[Cawley.2006] Sparse Multinomial Logistic Regression via Bayesian L1 Regularisation.pdf:application/pdf}
}

@article{jin_fitting_2013,
	title = {Fitting {Social} {Network} {Models} {Using} {Varying} {Truncation} {Stochastic} {Approximation} {MCMC} {Algorithm}},
	volume = {22},
	issn = {1061-8600, 1537-2715},
	url = {http://www.tandfonline.com/doi/abs/10.1080/10618600.2012.680851},
	doi = {10.1080/10618600.2012.680851},
	language = {en},
	number = {4},
	urldate = {2016-12-19},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Jin, Ick Hoon and Liang, Faming},
	month = oct,
	year = {2013},
	pages = {927--952},
	file = {[Jin.2013] Fitting Social Network Models Using Varying Truncation Stochastic Approximation.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/Jin01/[Jin.2013] Fitting Social Network Models Using Varying Truncation Stochastic Approximation.pdf:application/pdf}
}

@article{liang_simulated_2014,
	title = {Simulated {Stochastic} {Approximation} {Annealing} for {Global} {Optimization} {With} a {Square}-{Root} {Cooling} {Schedule}},
	volume = {109},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2013.872993},
	doi = {10.1080/01621459.2013.872993},
	language = {en},
	number = {506},
	urldate = {2016-12-21},
	journal = {Journal of the American Statistical Association},
	author = {Liang, Faming and Cheng, Yichen and Lin, Guang},
	month = apr,
	year = {2014},
	pages = {847--863},
	file = {[Liang.2014] Simulated Stochastic Approximation Annealing for Global Optimization With a.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/Jin01/[Liang.2014] Simulated Stochastic Approximation Annealing for Global Optimization With a.pdf:application/pdf}
}

@book{hjort_bayesian_2010,
	address = {Cambridge, UK ; New York},
	series = {Cambridge series in statistical and probabilistic mathematics},
	title = {Bayesian nonparametrics},
	isbn = {978-0-521-51346-3},
	abstract = {"Bayesian nonparametrics works - theoretically, computationally. The theory provides highly flexible models whose complexity grows appropriately with the amount of data. Computational issues, though challenging, are no longer intractable. All that is needed is an entry point: this intelligent book is the perfect guide to what can seem a forbidding landscape. Tutorial chapters by Ghosal, Lijoi and Prünster, Teh and Jordan, and Dunson advance from theory, to basic models and hierarchical modeling, to applications and implementation, particularly in computer science and biostatistics. These are complemented by companion chapters by the editors and Griffin and Quintana, providing additional models, examining computational issues, identifying future growth areas, and giving links to related topics. This coherent text gives ready access both to underlying principles and to state-of-the-art practice. Specific examples are drawn from information retrieval, NLP, machine vision, computational biology, biostatistics, and bioinformatics"--Provided by publisher},
	number = {28},
	publisher = {Cambridge University Press},
	editor = {Hjort, Nils Lid},
	year = {2010},
	note = {OCLC: ocn441945339},
	keywords = {Bayesian statistical decision theory, Nonparametric statistics},
	annote = {An invitation to Bayesian nonparametrics / Nils Lid Hjort, Chris Holmes, Peter Müller and Stephen G. Walker -- 1. Bayesian nonparametric methods: motivation and ideas / Stephen G. Walker -- 2. The Dirichlet process, related priors, and posterior asymptotics / Subhashis Ghosal -- 3. Models beyond the Dirichlet process / Antonio Lijoi and Igor Prünster -- 4. Further models and applications / Nils Lid Hjort -- 5. Hierarchical Bayesian nonparametric models with applications / Yee Whye Teh and Michael I. Jordan -- 6. Computational issues arising in Bayesian nonparametric hierarchical models / Jim Griffin and Chris Holmes -- 7. Nonparametric Bayes applications to biostatistics / David B. Dunson -- 8. More nonparametric Bayesian models for biostatistics / Peter Müller and Fernando Quintana -- Author index -- Subject index},
	file = {[Hjort.2010] Bayesian nonparametrics.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/S6. Theory-Nonparametrics/[Hjort.2010] Bayesian nonparametrics.pdf:application/pdf}
}

@article{loh_structure_2013,
	title = {Structure estimation for discrete graphical models: {Generalized} covariance matrices and their inverses},
	volume = {41},
	issn = {0090-5364},
	shorttitle = {Structure estimation for discrete graphical models},
	url = {http://projecteuclid.org/euclid.aos/1388545677},
	doi = {10.1214/13-AOS1162},
	language = {en},
	number = {6},
	urldate = {2017-01-05},
	journal = {The Annals of Statistics},
	author = {Loh, Po-Ling and Wainwright, Martin J.},
	month = dec,
	year = {2013},
	pages = {3022--3049},
	file = {[Loh.2013] Structure estimation for discrete graphical models.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/Jin01/[Loh.2013] Structure estimation for discrete graphical models.pdf:application/pdf}
}

@article{ravikumar_high-dimensional_2010,
	title = {High-dimensional {Ising} model selection using ℓ 1 -regularized logistic regression},
	volume = {38},
	issn = {0090-5364},
	url = {http://projecteuclid.org/euclid.aos/1268056617},
	doi = {10.1214/09-AOS691},
	language = {en},
	number = {3},
	urldate = {2017-01-05},
	journal = {The Annals of Statistics},
	author = {Ravikumar, Pradeep and Wainwright, Martin J. and Lafferty, John D.},
	month = jun,
	year = {2010},
	pages = {1287--1319},
	file = {[Ravikumar.2010] High-dimensional Ising model selection using ℓ 1 -regularized logistic.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/Jin01/[Ravikumar.2010] High-dimensional Ising model selection using ℓ 1 -regularized logistic.pdf:application/pdf}
}

@article{liang_trajectory_2010,
	title = {Trajectory averaging for stochastic approximation {MCMC} algorithms},
	volume = {38},
	issn = {0090-5364},
	url = {http://projecteuclid.org/euclid.aos/1279638541},
	doi = {10.1214/10-AOS807},
	language = {en},
	number = {5},
	urldate = {2017-01-06},
	journal = {The Annals of Statistics},
	author = {Liang, Faming},
	month = oct,
	year = {2010},
	pages = {2823--2856},
	file = {[Liang.2010] Trajectory averaging for stochastic approximation MCMC algorithms.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/Jin01/[Liang.2010] Trajectory averaging for stochastic approximation MCMC algorithms.pdf:application/pdf}
}

@article{liang_resampling-based_2013,
	title = {A {Resampling}-{Based} {Stochastic} {Approximation} {Method} for {Analysis} of {Large} {Geostatistical} {Data}},
	volume = {108},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2012.746061},
	doi = {10.1080/01621459.2012.746061},
	language = {en},
	number = {501},
	urldate = {2017-01-06},
	journal = {Journal of the American Statistical Association},
	author = {Liang, Faming and Cheng, Yichen and Song, Qifan and Park, Jincheol and Yang, Ping},
	month = mar,
	year = {2013},
	pages = {325--339},
	file = {[Liang.2013] A Resampling-Based Stochastic Approximation Method for Analysis of Large.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/Jin01/[Liang.2013] A Resampling-Based Stochastic Approximation Method for Analysis of Large.pdf:application/pdf}
}

@article{barnett_change_2016,
	title = {Change {Point} {Detection} in {Correlation} {Networks}},
	volume = {6},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/srep18893},
	doi = {10.1038/srep18893},
	urldate = {2017-01-12},
	journal = {Scientific Reports},
	author = {Barnett, Ian and Onnela, Jukka-Pekka},
	month = jan,
	year = {2016},
	pages = {18893},
	file = {[Barnett.2016] Change Point Detection in Correlation Networks.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/KY02/[Barnett.2016] Change Point Detection in Correlation Networks.pdf:application/pdf}
}

@article{jo_bayesian_2016,
	title = {Bayesian analysis to detect abrupt changes in extreme hydrological processes},
	volume = {538},
	issn = {00221694},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0022169416301792},
	doi = {10.1016/j.jhydrol.2016.03.065},
	language = {en},
	urldate = {2017-01-13},
	journal = {Journal of Hydrology},
	author = {Jo, Seongil and Kim, Gwangsu and Jeon, Jong-June},
	month = jul,
	year = {2016},
	pages = {63--70},
	file = {[Jo.2016] Bayesian analysis to detect abrupt changes in extreme hydrological processes.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/KY02/[Jo.2016] Bayesian analysis to detect abrupt changes in extreme hydrological processes.pdf:application/pdf}
}

@article{yu_useful_2015,
	title = {A useful variant of the {Davis}–{Kahan} theorem for statisticians},
	volume = {102},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/asv008},
	doi = {10.1093/biomet/asv008},
	language = {en},
	number = {2},
	urldate = {2017-01-13},
	journal = {Biometrika},
	author = {Yu, Y. and Wang, T. and Samworth, R. J.},
	month = jun,
	year = {2015},
	pages = {315--323},
	file = {[Yu.2015] A useful variant of the Davis–Kahan theorem for statisticians.pdf:/home/kisung/Dropbox/V1. Pure Mathematics/P2. Linear Algebra/S1. Davis-Kahan/[Yu.2015] A useful variant of the Davis–Kahan theorem for statisticians.pdf:application/pdf}
}

@book{givens_computational_2013,
	address = {Hoboken, N.J},
	edition = {2nd ed},
	series = {Wiley series in computational statistics},
	title = {Computational statistics},
	isbn = {978-0-470-53331-4},
	publisher = {Wiley},
	author = {Givens, Geof H. and Hoeting, Jennifer A.},
	year = {2013},
	keywords = {Data processing, Mathematical statistics},
	file = {[Givens.2013] Computational statistics.pdf:/home/kisung/Dropbox/VC. Coursework/P3. Statistics/5. MCMC/[Givens.2013] Computational statistics.pdf:application/pdf}
}

@book{liang_advanced_2010,
	address = {Chichester, West Sussex, U.K},
	series = {Wiley series in computational statistics},
	title = {Advanced {Markov} chain {Monte} {Carlo} methods: learning from past samples},
	isbn = {978-0-470-74826-8},
	shorttitle = {Advanced {Markov} chain {Monte} {Carlo} methods},
	publisher = {Wiley},
	author = {Liang, F. and Liu, Chuanhai and Carroll, Raymond J.},
	year = {2010},
	note = {OCLC: ocn555629616},
	keywords = {Monte Carlo method, Markov processes},
	file = {[Liang.2010] Advanced Markov chain Monte Carlo methods.pdf:/home/kisung/Dropbox/VC. Coursework/P3. Statistics/5. MCMC/[Liang.2010] Advanced Markov chain Monte Carlo methods.pdf:application/pdf;[Liang.2010] Advanced Markov chain Monte Carlo methods.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/S7. Theory-MCMC/[Liang.2010] Advanced Markov chain Monte Carlo methods.pdf:application/pdf}
}

@book{vaart_asymptotic_2007,
	address = {Cambridge},
	edition = {1. paperback ed., 8. printing},
	series = {Cambridge series in statistical and probabilistic mathematics},
	title = {Asymptotic statistics},
	isbn = {978-0-521-78450-4 978-0-521-49603-2},
	language = {eng},
	publisher = {Cambridge Univ. Press},
	author = {Vaart, A. W. van der},
	year = {2007},
	note = {OCLC: 838749444},
	keywords = {Asymptotic efficiencies (Statistics), Asymptotische Statistik, Mathematical statistics Asymptotic theory},
	file = {[Vaart.2007] Asymptotic statistics.pdf:/home/kisung/Dropbox/V3. Statistics/P9. Asymptotics/[Vaart.2007] Asymptotic statistics.pdf:application/pdf}
}

@article{papyan_multimodal_2016,
	title = {Multimodal {Latent} {Variable} {Analysis}},
	volume = {abs/1611.08472},
	url = {http://arxiv.org/abs/1611.08472},
	journal = {CoRR},
	author = {Papyan, Vardan and Talmon, Ronen},
	year = {2016},
	file = {[Papyan.2016] Multimodal Latent Variable Analysis.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/KY03-Fusion/[Papyan.2016] Multimodal Latent Variable Analysis.pdf:application/pdf}
}

@book{casella_statistical_2002,
	address = {Pacific Grove, CA},
	title = {Statistical inference},
	isbn = {978-81-315-0394-2},
	language = {English},
	publisher = {Cengage Learning \& Wadsworth},
	author = {Casella, George and Berger, Roger L},
	year = {2002},
	note = {OCLC: 905616056},
	file = {[Casella.2002] Statistical inference.pdf:/home/kisung/Dropbox/VC. Coursework/P3. Statistics/6. Inference/[Casella.2002] Statistical inference.pdf:application/pdf}
}

@book{agresti_categorical_2013,
	address = {Hoboken, NJ},
	edition = {3rd ed},
	series = {Wiley series in probability and statistics},
	title = {Categorical data analysis},
	isbn = {978-0-470-46363-5},
	abstract = {"A classic in its own right, this book continues to provide an introduction to modern generalized linear models for categorical variables. The text emphasizes methods that are most commonly used in practical application, such as classical inferences for two- and three-way contingency tables, logistic regression, loglinear models, models for multinomial (nominal and ordinal) responses, and methods for repeated measurement and other forms of clustered, correlated response data. Chapter headings remain essentially with the exception of a new one on Bayesian inference for parametric models. Other major changes include an expansion of clustered data, new research on analysis of data sets with robust variables, extensive discussions of ordinal data, more on interpretation, and additional exercises throughout the book. R and SAS are now showcased as the software of choice. An author web site with solutions, commentaries, software programs, and data sets is available"--},
	number = {792},
	publisher = {Wiley},
	author = {Agresti, Alan},
	year = {2013},
	keywords = {MATHEMATICS / Probability \& Statistics / General, Multivariate analysis},
	annote = {Machine generated contents note: Preface 1. Introduction: Distributions and Inference for Categorical Data 1 1.1 Categorical Response Data, 1 1.2 Distributions for Categorical Data 1.3 Statistical Inference for Categorical Data 1.4 Statistical Inference for Binomial Parameters 1.5 Statistical Inference for Multinomial Parameters 1.6 Bayesian Inference for Binomial and Multinomial Parameters Notes Exercises 2. Describing Contingency Tables 2.1 Probability Structure for Contingency Tables 2.2 Comparing Two Proportions 2.3 Conditional Association in Stratified 2x2 Tables 2.4 Measuring Association in I x J Tables Notes Exercises 3. Inference for Two-Way Contingency Tables 3.1 Confidence Intervals for Association Parameters 3.2 Testing Independence in Two-Way Contingency Tables 3.3 Following-Up Chi-Squared Tests 3.4 Two-Way Tables with Ordered Classifications 3.5 Small-Sample Inference for Contingency Tables 3.6 Bayesian Inference for Two-Way Contingency Tables 3.7 Extensions for Multiway Tables and Nontabulated Responses Notes Exercises 4. Introduction to Generalized Linear Models 4.1 The Generalized Linear Model 4.2 Generalized Linear Models for Binary Data 4.3 Generalized Linear Models for Counts and Rates 4.4 Moments and Likelihood for Generalized Linear Models 4.5 Inference and Model Checking for Generalized Linear Models 4.6 Fitting Generalized Linear Models 4.7 Quasi-Likelihood and Generalized Linear Models Notes Exercises 5. Logistic Regression 5.1 Interpreting Parameters in Logistic Regression 5.2 Inference for Logistic Regression 5.3 Logistic Models with Categorical Predictors 5.4 Multiple Logistic Regression 5.5 Fitting Logistic Regression Models Notes Exercises 6. Building, Checking, and Applying Logistic Regression Models 6.1 Strategies in Model Selection 6.2 Logistic Regression Diagnostics 6.3 Summarizing the Predictive Power of a Model 6.3 Mantel-Haenszel and Related Methods for Multiple 2x2 Tables 6.4 Detecting and Dealing with Infinite Estimates 6.5 Sample Size and Power Considerations Notes Exercises 7. Alternative Modeling of Binary Response Data 7.1 Probit and Complementary Log-Log Models 7.2 Bayesian Inference for Binary Regression 7.3 Conditional Logistic Regression 7.4 Smoothing: Kernels, Penalized Likelihood, Generalized Additive Models 7.5 Issues in Analyzing High-Dimensional Categorical Data Notes Exercises 8. Models for Multinomial Responses 8.1 Nominal Responses: Baseline-Category Logit Models 8.2 Ordinal Responses: Cumulative Logit Models 8.3 Ordinal Responses: Alternative Models 8.4 Testing Conditional Independence in I ? J ? K Tables 8.5 Discrete-Choice Models 8.6 Bayesian Modeling of Multinomial Responses Notes Exercises 9. Loglinear Models for Contingency Tables 9.1 Loglinear Models for Two-Way Tables 9.2 Loglinear Models for Independence and Interaction in Three-Way Tables 9.3 Inference for Loglinear Models 9.4 Loglinear Models for Higher Dimensions 9.5 The Loglinear?Logistic Model Connection 9.6 Loglinear Model Fitting: Likelihood Equations and Asymptotic Distributions 9.7 Loglinear Model Fitting: Iterative Methods and their Application Notes Exercises 10. Building and Extending Loglinear Models 10.1 Conditional Independence Graphs and Collapsibility 10.2 Model Selection and Comparison 10.3 Residuals for Detecting Cell-Specific Lack of Fit 10.4 Modeling Ordinal Associations 10.5 Generalized Loglinear and Association Models, Correlation Models, and Correspondence Analysis 10.6 Empty Cells and Sparseness in Modeling Contingency Tables 10.7 Bayesian Loglinear Modeling Notes Exercises 11. Models for Matched Pairs 11.1 Comparing Dependent Proportions 11.2 Conditional Logistic Regression for Binary Matched Pairs 11.3 Marginal Models for Square Contingency Tables 11.4 Symmetry, Quasi-symmetry, and Quasi-independence 11.5 Measuring Agreement Between Observers 11.6 Bradley-Terry Model for Paired Preferences 11.7 Marginal Models and Quasi-symmetry Models for Matched Sets Notes Exercises 12. Clustered Categorical Data: Marginal and Transitional Models 12.1 Marginal Modeling: Maximum Likelihood Approach 12.2 Marginal Modeling: Generalized Estimating Equations Approach 12.3 Quasi-likelihood and Its GEE Multivariate Extension: Details 12.4 Transitional Models: Markov Chain and Time Series Models Notes Exercises 13. Clustered Categorical Data: Random Effects Models 13.1 Random Effects Modeling of Clustered Categorical Data 13.2 Binary Responses: The Logistic-Normal Model 13.3 Examples of Random Effects Models for Binary Data 13.4 Random Effects Models for Multinomial Data 13.5 Multilevel Models 13.6 GLMM Fitting, Inference, and Prediction 13.7 Bayesian Multivariate Categorical Modeling Notes Exercises 14. Other Mixture Models for Discrete Data 14.1 Latent Class Models 14.2 Nonparametric Random Effects Models 14.3 Beta-Binomial Models 14.4 Negative Binomial Regression 14.5 Poisson Regression with Random Effects Notes Exercises 15. Non-Model-Based Classification and Clustering 15.2 Classification: Linear Discriminant Analysis 15.3 Classification: Tree-Structured Prediction 15.4 Cluster Analysis for Categorical Data Notes Exercises 16. Large- and Small-Sample Theory for Parametric Models 16.1 Delta Method 16.2 Asymptotic Distributions of Estimators of Model Parameters and Cell Probabilities 16.3 Asymptotic Distributions of Residuals and Goodness-of-Fit Statistics 16.4 Asymptotic Distributions for Logit/Loglinear Models 16.5 Small-Sample Significance Tests for Contingency Tables 16.6 Small-Sample Confidence Intervals for Categorical Data 16.7 Alternative Estimation Theory for Parametric Models Notes Exercises 17. Historical Tour of Categorical Data Analysis 17.1 Pearson-Yule Association Controversy 17.2 R. A. Fisher's Contributions 17.3 Logistic Regression 17.4 Multiway Contingency Tables and Loglinear Models 17.5 Bayesian Methods for Categorical Data 17.6 A Look Forward, and Backward Appendix A. Statistical Software for Categorical Data Analysis Appendix B. Chi-Squared Distribution Values References Author Index Example Index Subject Index},
	file = {[Agresti.2013] Categorical data analysis.pdf:/home/kisung/Dropbox/VC. Coursework/P3. Statistics/4. GLM/[Agresti.2013] Categorical data analysis.pdf:application/pdf}
}

@article{morup_bayesian_2012,
	title = {Bayesian {Community} {Detection}},
	volume = {24},
	issn = {0899-7667, 1530-888X},
	url = {http://www.mitpressjournals.org/doi/10.1162/NECO_a_00314},
	doi = {10.1162/NECO_a_00314},
	language = {en},
	number = {9},
	urldate = {2017-02-10},
	journal = {Neural Computation},
	author = {Mørup, Morten and Schmidt, Mikkel N.},
	month = sep,
	year = {2012},
	pages = {2434--2456},
	file = {[Mørup.2012] Bayesian Community Detection.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/JAL01/[Mørup.2012] Bayesian Community Detection.pdf:application/pdf}
}

@article{george_variable_1993,
	title = {Variable {Selection} via {Gibbs} {Sampling}},
	volume = {88},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1993.10476353},
	doi = {10.1080/01621459.1993.10476353},
	language = {en},
	number = {423},
	urldate = {2017-02-13},
	journal = {Journal of the American Statistical Association},
	author = {George, Edward I. and McCulloch, Robert E.},
	month = sep,
	year = {1993},
	pages = {881--889},
	file = {[George.1993] Variable Selection via Gibbs Sampling.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/JAL01/[George.1993] Variable Selection via Gibbs Sampling.pdf:application/pdf}
}

@article{schmidt_nonparametric_2013,
	title = {Nonparametric {Bayesian} modeling of complex networks: an introduction},
	volume = {30},
	issn = {1053-5888},
	shorttitle = {Nonparametric {Bayesian} modeling of complex networks},
	url = {http://ieeexplore.ieee.org/document/6494690/},
	doi = {10.1109/MSP.2012.2235191},
	number = {3},
	urldate = {2017-02-13},
	journal = {IEEE Signal Processing Magazine},
	author = {Schmidt, Mikkel N. and Morup, Morten},
	month = may,
	year = {2013},
	pages = {110--128},
	file = {[Schmidt.2013] Nonparametric Bayesian modeling of complex networks.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/SBM/[Schmidt.2013] Nonparametric Bayesian modeling of complex networks.pdf:application/pdf}
}

@book{murray_differential_1993,
	address = {London ; New York},
	edition = {1st ed},
	series = {Monographs on statistics and applied probability},
	title = {Differential geometry and statistics},
	isbn = {978-0-412-39860-5},
	number = {48},
	publisher = {Chapman \& Hall},
	author = {Murray, M. K. and Rice, John W.},
	year = {1993},
	keywords = {Mathematical statistics, Geometry, Differential},
	file = {[Murray.1993] Differential geometry and statistics.pdf:/home/kisung/Dropbox/V1. Pure Mathematics/P3. Geometry/S1. Statistics/[Murray.1993] Differential geometry and statistics.pdf:application/pdf}
}

@article{blei_variational_2016,
	title = {Variational {Inference}: {A} {Review} for {Statisticians}},
	journal = {ArXiv e-prints},
	author = {Blei, D. M. and Kucukelbir, A. and McAuliffe, J. D.},
	month = jan,
	year = {2016},
	keywords = {Computer Science - Learning, Statistics - Machine Learning, Statistics - Computation},
	file = {[Blei.2016] Variational Inference.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/S1. Comp-Approximate/[Blei.2016] Variational Inference.pdf:application/pdf}
}

@article{epskamp_network_2016,
	title = {Network {Psychometrics}},
	journal = {ArXiv e-prints},
	author = {Epskamp, S. and Maris, G. K. J. and Waldorp, L. J. and Borsboom, D.},
	month = sep,
	year = {2016},
	keywords = {Statistics - Methodology},
	file = {[Epskamp.2016] Network Psychometrics.pdf:/home/kisung/Dropbox/netpsy 2017. 3. 19. 오후 21649/[Epskamp.2016] Network Psychometrics.pdf:application/pdf;[Epskamp.2016] Network Psychometrics.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/Jin01/[Epskamp.2016] Network Psychometrics.pdf:application/pdf}
}

@article{kruis_three_2016,
	title = {Three representations of the {Ising} model},
	volume = {6},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/srep34175},
	doi = {10.1038/srep34175},
	language = {en},
	number = {1},
	urldate = {2017-03-19},
	journal = {Scientific Reports},
	author = {Kruis, Joost and Maris, Gunter},
	month = dec,
	year = {2016},
	file = {[Kruis.2016] Three representations of the Ising model.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/Jin01/[Kruis.2016] Three representations of the Ising model.pdf:application/pdf}
}

@article{marsman_bayesian_2015,
	title = {Bayesian inference for low-rank {Ising} networks},
	volume = {5},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/srep09050},
	doi = {10.1038/srep09050},
	urldate = {2017-03-19},
	journal = {Scientific Reports},
	author = {Marsman, Maarten and Maris, Gunter and Bechger, Timo and Glas, Cees},
	month = mar,
	year = {2015},
	pages = {9050},
	file = {[Marsman.2015] Bayesian inference for low-rank Ising networks.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/Jin01/[Marsman.2015] Bayesian inference for low-rank Ising networks.pdf:application/pdf}
}

@article{hughes_autologistic_2011,
	title = {Autologistic models for binary data on a lattice},
	volume = {22},
	issn = {11804009},
	url = {http://doi.wiley.com/10.1002/env.1102},
	doi = {10.1002/env.1102},
	language = {en},
	number = {7},
	urldate = {2017-03-19},
	journal = {Environmetrics},
	author = {Hughes, John and Haran, Murali and Caragea, Petruţa C.},
	month = nov,
	year = {2011},
	pages = {857--871},
	file = {[Hughes.2011] Autologistic models for binary data on a lattice.pdf:/home/kisung/Dropbox/VC. Coursework/Readings/Jin01/[Hughes.2011] Autologistic models for binary data on a lattice.pdf:application/pdf}
}

@book{lu_multilinear_2014,
	address = {Boca Raton, Florida},
	series = {Chapman \& {Hall}/{CRC} machine learning \& pattern recognition series},
	title = {Multilinear subspace learning: dimensionality reduction of multidimensional data},
	isbn = {978-1-4398-5724-3},
	shorttitle = {Multilinear subspace learning},
	abstract = {"Due to advances in sensor, storage, and networking technologies, data is being generated on a daily basis at an ever-increasing pace in a wide range of applications, including cloud computing, mobile Internet, and medical imaging. This large multidimensional data requires more efficient dimensionality reduction schemes than the traditional techniques. Addressing this need, multilinear subspace learning (MSL) reduces the dimensionality of big data directly from its natural multidimensional representation, a tensor. Multilinear Subspace Learning: Dimensionality Reduction of Multidimensional Data gives a comprehensive introduction to both theoretical and practical aspects of MSL for the dimensionality reduction of multidimensional data based on tensors. It covers the fundamentals, algorithms, and applications of MSL. Emphasizing essential concepts and system-level perspectives, the authors provide a foundation for solving many of today's most interesting and challenging problems in big multidimensional data processing. They trace the history of MSL, detail recent advances, and explore future developments and emerging applications.The book follows a unifying MSL framework formulation to systematically derive representative MSL algorithms. It describes various applications of the algorithms, along with their pseudocode. Implementation tips help practitioners in further development, evaluation, and application. The book also provides researchers with useful theoretical information on big multidimensional data in machine learning and pattern recognition. MATLAB source code, data, and other materials are available at www.comp.hkbu.edu.hk/haiping/MSL.html"--},
	publisher = {CRC Press/Taylor \& Francis Group},
	author = {Lu, Haiping and Plataniotis, Konstantinos N. and Venetsanopoulos, A. N.},
	year = {2014},
	keywords = {Data compression (Computer science), Big data, Multilinear algebra, COMPUTERS / Database Management / Data Mining, COMPUTERS / Machine Theory, TECHNOLOGY \& ENGINEERING / Electrical},
	annote = {"A Chapman \& Hall Book"},
	file = {[Lu.2014] Multilinear subspace learning.pdf:/home/kisung/Dropbox/V3. Statistics/P5. MSL/[Lu.2014] Multilinear subspace learning.pdf:application/pdf}
}

@book{bhattacharya_nonparametric_2012,
	address = {Cambridge, UK ; New York},
	series = {Institute of mathematical statistics monographs},
	title = {Nonparametric inference on manifolds: with applications to shape spaces},
	isbn = {978-1-107-01958-4},
	shorttitle = {Nonparametric inference on manifolds},
	number = {2},
	publisher = {Cambridge University Press},
	author = {Bhattacharya, Abhishek and Bhattacharya, R. N.},
	year = {2012},
	note = {OCLC: ocn757931398},
	keywords = {Nonparametric statistics, Manifolds (Mathematics)},
	file = {[Bhattacharya.2012] Nonparametric inference on manifolds.pdf:/home/kisung/Dropbox/V1. Pure Mathematics/P3. Geometry/S1. Statistics/[Bhattacharya.2012] Nonparametric inference on manifolds.pdf:application/pdf}
}

@book{robert_introducing_2010,
	address = {New York},
	series = {Use {R}!},
	title = {Introducing {Monte} {Carlo} methods with {R}},
	isbn = {978-1-4419-1575-7 978-1-4419-1576-4},
	publisher = {Springer},
	author = {Robert, Christian P. and Casella, George},
	year = {2010},
	note = {OCLC: ocn462920377},
	keywords = {Data processing, Mathematical Computing, Mathematical statistics, R (Computer program language), Monte Carlo method, Markov processes, Computer programs, Monte Carlo-methode, R (computerprogramma), Monte-Carlo-Simulation, R (Programm)},
	file = {[Robert.2010] Introducing Monte Carlo methods with R.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/S7. Theory-MCMC/[Robert.2010] Introducing Monte Carlo methods with R.pdf:application/pdf}
}

@article{wainwright_graphical_2007,
	title = {Graphical {Models}, {Exponential} {Families}, and {Variational} {Inference}},
	volume = {1},
	issn = {1935-8237, 1935-8245},
	url = {http://www.nowpublishers.com/article/Details/MAL-001},
	doi = {10.1561/2200000001},
	language = {en},
	number = {1–2},
	urldate = {2017-05-10},
	journal = {Foundations and Trends® in Machine Learning},
	author = {Wainwright, Martin J. and Jordan, Michael I.},
	year = {2007},
	pages = {1--305},
	file = {[Wainwright.2007] Graphical Models, Exponential Families, and Variational Inference.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/S1. Comp-Approximate/[Wainwright.2007] Graphical Models, Exponential Families, and Variational Inference.pdf:application/pdf}
}

@article{lee_landmark_2009,
	title = {Landmark {MDS} ensemble},
	volume = {42},
	issn = {00313203},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320308005049},
	doi = {10.1016/j.patcog.2008.11.039},
	language = {en},
	number = {9},
	urldate = {2017-05-15},
	journal = {Pattern Recognition},
	author = {Lee, Seunghak and Choi, Seungjin},
	month = sep,
	year = {2009},
	pages = {2045--2053},
	file = {[Lee_Choi.2009] Landmark MDS ensemble.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/13. LMDS/[Lee_Choi.2009] Landmark MDS ensemble.pdf:application/pdf}
}

@incollection{silva_global_2002,
	address = {Cambridge, MA},
	title = {Global {Versus} {Local} {Methods} in {Nonlinear} {Dimensionality} {Reduction}},
	url = {http://books.nips.cc/papers/files/nips15/AA28.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 15},
	publisher = {MIT Press},
	author = {Silva, Vin D. and Tenenbaum, Joshua B.},
	editor = {Thrun, S. and Obermayer, K.},
	year = {2002},
	pages = {705--712},
	file = {[Silva_Tenenbaum.2002] Global Versus Local Methods in Nonlinear Dimensionality Reduction.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/13. LMDS/[Silva_Tenenbaum.2002] Global Versus Local Methods in Nonlinear Dimensionality Reduction.pdf:application/pdf}
}

@incollection{goos_kernel_1997,
	address = {Berlin, Heidelberg},
	title = {Kernel principal component analysis},
	volume = {1327},
	isbn = {978-3-540-63631-1 978-3-540-69620-9},
	url = {http://link.springer.com/10.1007/BFb0020217},
	urldate = {2017-05-16},
	booktitle = {Artificial {Neural} {Networks} — {ICANN}'97},
	publisher = {Springer Berlin Heidelberg},
	author = {Schölkopf, Bernhard and Smola, Alexander and Müller, Klaus-Robert},
	editor = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Gerstner, Wulfram and Germond, Alain and Hasler, Martin and Nicoud, Jean-Daniel},
	year = {1997},
	note = {DOI: 10.1007/BFb0020217},
	pages = {583--588},
	file = {[Schölkopf.1997] Kernel principal component analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/10. KPCA/[Schölkopf.1997] Kernel principal component analysis.pdf:application/pdf}
}

@article{sammon_nonlinear_1969,
	title = {A {Nonlinear} {Mapping} for {Data} {Structure} {Analysis}},
	volume = {C-18},
	issn = {0018-9340},
	url = {http://ieeexplore.ieee.org/document/1671271/},
	doi = {10.1109/T-C.1969.222678},
	number = {5},
	urldate = {2017-05-19},
	journal = {IEEE Transactions on Computers},
	author = {Sammon, J.W.},
	month = may,
	year = {1969},
	pages = {401--409},
	file = {[Sammon.1969] A Nonlinear Mapping for Data Structure Analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/11. Sammon/[Sammon.1969] A Nonlinear Mapping for Data Structure Analysis.pdf:application/pdf}
}

@article{weinberger_unsupervised_2006,
	title = {Unsupervised {Learning} of {Image} {Manifolds} by {Semidefinite} {Programming}},
	volume = {70},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/10.1007/s11263-005-4939-z},
	doi = {10.1007/s11263-005-4939-z},
	language = {en},
	number = {1},
	urldate = {2017-05-19},
	journal = {International Journal of Computer Vision},
	author = {Weinberger, Kilian Q. and Saul, Lawrence K.},
	month = oct,
	year = {2006},
	pages = {77--90},
	file = {[Weinberger.2006] Unsupervised Learning of Image Manifolds by Semidefinite Programming.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/07. MVU/[Weinberger.2006] Unsupervised Learning of Image Manifolds by Semidefinite Programming.pdf:application/pdf}
}

@article{camastra_data_2003,
	title = {Data dimensionality estimation methods: a survey},
	volume = {36},
	issn = {00313203},
	shorttitle = {Data dimensionality estimation methods},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320303001766},
	doi = {10.1016/S0031-3203(03)00176-6},
	language = {en},
	number = {12},
	urldate = {2017-05-19},
	journal = {Pattern Recognition},
	author = {Camastra, Francesco},
	month = dec,
	year = {2003},
	pages = {2945--2954},
	file = {[Camastra.2003] Data dimensionality estimation methods.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S4. Estimation/[Camastra.2003] Data dimensionality estimation methods.pdf:application/pdf}
}

@article{pestov_axiomatic_2008,
	title = {An axiomatic approach to intrinsic dimension of a dataset},
	volume = {21},
	issn = {08936080},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0893608007002511},
	doi = {10.1016/j.neunet.2007.12.030},
	language = {en},
	number = {2-3},
	urldate = {2017-05-19},
	journal = {Neural Networks},
	author = {Pestov, Vladimir},
	month = mar,
	year = {2008},
	pages = {204--213},
	file = {[Pestov.2008] An axiomatic approach to intrinsic dimension of a dataset.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S4. Estimation/[Pestov.2008] An axiomatic approach to intrinsic dimension of a dataset.pdf:application/pdf}
}

@article{grassberger_measuring_1983,
	title = {Measuring the strangeness of strange attractors},
	volume = {9},
	issn = {01672789},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0167278983902981},
	doi = {10.1016/0167-2789(83)90298-1},
	language = {en},
	number = {1-2},
	urldate = {2017-05-21},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Grassberger, Peter and Procaccia, Itamar},
	month = oct,
	year = {1983},
	pages = {189--208},
	annote = {definition : correlation dimension},
	file = {[Grassberger.1983] Measuring the strangeness of strange attractors.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S4. Estimation/2. correlation/[Grassberger.1983] Measuring the strangeness of strange attractors.pdf:application/pdf}
}

@article{granata_accurate_2016,
	title = {Accurate {Estimation} of the {Intrinsic} {Dimension} {Using} {Graph} {Distances}: {Unraveling} the {Geometric} {Complexity} of {Datasets}},
	volume = {6},
	issn = {2045-2322},
	shorttitle = {Accurate {Estimation} of the {Intrinsic} {Dimension} {Using} {Graph} {Distances}},
	url = {http://www.nature.com/articles/srep31377},
	doi = {10.1038/srep31377},
	language = {en},
	number = {1},
	urldate = {2017-05-20},
	journal = {Scientific Reports},
	author = {Granata, Daniele and Carnevale, Vincenzo},
	month = nov,
	year = {2016},
	file = {[Granata.2016] Accurate Estimation of the Intrinsic Dimension Using Graph Distances.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S4. Estimation/3. graph distance/[Granata.2016] Accurate Estimation of the Intrinsic Dimension Using Graph Distances.pdf:application/pdf}
}

@article{camastra_intrinsic_2016,
	title = {Intrinsic dimension estimation: {Advances} and open problems},
	volume = {328},
	issn = {00200255},
	shorttitle = {Intrinsic dimension estimation},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0020025515006179},
	doi = {10.1016/j.ins.2015.08.029},
	language = {en},
	urldate = {2017-05-21},
	journal = {Information Sciences},
	author = {Camastra, Francesco and Staiano, Antonino},
	month = jan,
	year = {2016},
	pages = {26--41},
	file = {[Camastra.2016] Intrinsic dimension estimation.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S4. Estimation/[Camastra.2016] Intrinsic dimension estimation.pdf:application/pdf}
}

@book{ott_chaos_2002,
	address = {Cambridge, U.K. ; New York},
	edition = {2nd ed},
	title = {Chaos in dynamical systems},
	isbn = {978-0-521-81196-5 978-0-521-01084-9},
	publisher = {Cambridge University Press},
	author = {Ott, Edward},
	year = {2002},
	keywords = {Chaotic behavior in systems},
	annote = {Definition : Boxcounting / Kolmogorov capacity}
}

@book{ma_manifold_2012,
	address = {Boca Raton, Fla. : London},
	title = {Manifold learning theory and applications},
	isbn = {978-1-4398-7109-6},
	publisher = {CRC ; Taylor \& Francis [distributor]},
	editor = {Ma, Yunqian and Fu, Yun},
	year = {2012},
	note = {OCLC: ocn751753027},
	keywords = {Manifolds (Mathematics)},
	annote = {Alan Julian Izenman -- Shounak Roychowdhury and Joydeep Ghosh -- Arkadas Ozakin, Nikolaos Vasiloglou II, Alexander Gray -- Hariharan Narayanan -- Chang Wang, Peter Krafft, and Sridhar Mahadevan -- Ameet Talwalkar, Sanjiv Kumar, Mehryar Mohri, Henry Rowley -- Wei Zeng, Jian Sun, Ren Guo, Feng Luo, and Xianfeng Gu -- Xianfeng Gu, Wei Zeng, Feng Luo, and Shing-Tung Yau -- Chafik Samir, Pierre-Antoine Absil, and Paul Van Dooren -- Ahmed Elgammal and Marwan Torki -- Ahmed Elgammal and Chan Su Lee Spectral embedding methods for manifold learning / Robust Laplacian eigenmaps using global information / Density preserving maps / Sample complexity in manifold learning / Manifold alignment / Large-scale manifold learning / Metric and heat kernel / Discreet Ricci flow for surface and 3-manifold / 2D and 3D objects morphing using manifold techniques / Learning image manifolds from local features / Human motion analysis applications of manifold learning},
	file = {[Ma.2012] Manifold learning theory and applications.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/[Ma.2012] Manifold learning theory and applications.pdf:application/pdf}
}

@book{gentle_matrix_2007,
	address = {New York, NY},
	series = {Springer texts in statistics},
	title = {Matrix algebra: theory, computations, and applications in statistics},
	isbn = {978-0-387-70873-7 978-0-387-70872-0},
	shorttitle = {Matrix algebra},
	language = {eng},
	publisher = {Springer},
	author = {Gentle, James E.},
	year = {2007},
	note = {OCLC: 255826556},
	keywords = {Statistik, Matrices, Matrizenalgebra, Numerische Mathematik, Vektorraum, Matrices Problems, exercises, etc, Lehrbuch},
	file = {[Gentle.2007] Matrix algebra.pdf:/home/kisung/Dropbox/V1. Pure Mathematics/P2. Linear Algebra/[Gentle.2007] Matrix algebra.pdf:application/pdf}
}

@article{spearman_general_1904,
	title = {"{General} {Intelligence}," {Objectively} {Determined} and {Measured}},
	volume = {15},
	issn = {00029556},
	url = {http://www.jstor.org/stable/1412107?origin=crossref},
	doi = {10.2307/1412107},
	number = {2},
	urldate = {2017-05-22},
	journal = {The American Journal of Psychology},
	author = {Spearman, C.},
	month = apr,
	year = {1904},
	pages = {201},
	file = {[Spearman.1904] General Intelligence, Objectively Determined and Measured.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/05. FA/[Spearman.1904] General Intelligence, Objectively Determined and Measured.pdf:application/pdf}
}

@article{sorzano_survey_2014,
	title = {A survey of dimensionality reduction techniques},
	journal = {ArXiv e-prints},
	author = {Sorzano, C. O. S. and Vargas, J. and Montano, A. P.},
	month = mar,
	year = {2014},
	keywords = {Computer Science - Learning, Statistics - Machine Learning, Quantitative Biology - Quantitative Methods},
	file = {[Sorzano.2014] A survey of dimensionality reduction techniques.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/[Sorzano.2014] A survey of dimensionality reduction techniques.pdf:application/pdf}
}

@inproceedings{he_neighborhood_2005,
	address = {Washington, DC, USA},
	series = {{ICCV} '05},
	title = {Neighborhood {Preserving} {Embedding}},
	isbn = {0-7695-2334-X-02},
	url = {http://dx.doi.org/10.1109/ICCV.2005.167},
	doi = {10.1109/ICCV.2005.167},
	booktitle = {Proceedings of the {Tenth} {IEEE} {International} {Conference} on {Computer} {Vision} - {Volume} 2},
	publisher = {IEEE Computer Society},
	author = {He, Xiaofei and Cai, Deng and Yan, Shuicheng and Zhang, Hong-Jiang},
	year = {2005},
	pages = {1208--1213},
	file = {[He.2005] Neighborhood Preserving Embedding.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/08. NPE/[He.2005] Neighborhood Preserving Embedding.pdf:application/pdf}
}

@phdthesis{he_locality_2005,
	address = {Chicago, IL, USA},
	title = {Locality {Preserving} {Projections}},
	school = {University of Chicago},
	author = {He, Xiaofei},
	year = {2005},
	annote = {AAI3195015},
	file = {[He.2005] Locality Preserving Projections.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/07. LPP/[He.2005] Locality Preserving Projections.pdf:application/pdf}
}

@article{hotelling_analysis_1933,
	title = {Analysis of a complex of statistical variables into principal components.},
	volume = {24},
	issn = {0022-0663},
	url = {http://content.apa.org/journals/edu/24/6/417},
	doi = {10.1037/h0071325},
	language = {en},
	number = {6},
	urldate = {2017-05-25},
	journal = {Journal of Educational Psychology},
	author = {Hotelling, H.},
	year = {1933},
	pages = {417--441}
}

@article{kruskal_multidimensional_1964,
	title = {Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis},
	volume = {29},
	issn = {0033-3123, 1860-0980},
	url = {http://link.springer.com/10.1007/BF02289565},
	doi = {10.1007/BF02289565},
	language = {en},
	number = {1},
	urldate = {2017-05-25},
	journal = {Psychometrika},
	author = {Kruskal, J. B.},
	month = mar,
	year = {1964},
	pages = {1--27},
	file = {[Kruskal.1964] Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/02. MDS/[Kruskal.1964] Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis.pdf:application/pdf}
}

@incollection{beals_extensions_1984,
	address = {Providence, Rhode Island},
	title = {Extensions of {Lipschitz} mappings into a {Hilbert} space},
	volume = {26},
	isbn = {978-0-8218-5030-5 978-0-8218-7611-4},
	url = {http://www.ams.org/conm/026/},
	language = {en},
	urldate = {2017-05-25},
	booktitle = {Contemporary {Mathematics}},
	publisher = {American Mathematical Society},
	author = {Johnson, William B. and Lindenstrauss, Joram},
	editor = {Beals, Richard and Beck, Anatole and Bellow, Alexandra and Hajian, Arshag},
	year = {1984},
	note = {DOI: 10.1090/conm/026/737400},
	pages = {189--206},
	annote = {JL lemma
 },
	file = {[Johnson_Lindenstrauss.1984] Extensions of Lipschitz mappings into a Hilbert space.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/04. RNDPROJ/[Johnson_Lindenstrauss.1984] Extensions of Lipschitz mappings into a Hilbert space.pdf:application/pdf}
}

@article{zhang_principal_2004,
	title = {Principal {Manifolds} and {Nonlinear} {Dimensionality} {Reduction} via {Tangent} {Space} {Alignment}},
	volume = {26},
	issn = {1064-8275, 1095-7197},
	url = {http://epubs.siam.org/doi/10.1137/S1064827502419154},
	doi = {10.1137/S1064827502419154},
	language = {en},
	number = {1},
	urldate = {2017-05-27},
	journal = {SIAM Journal on Scientific Computing},
	author = {Zhang, Zhenyue and Zha, Hongyuan},
	month = jan,
	year = {2004},
	pages = {313--338},
	file = {[Zhang.2004] Principal Manifolds and Nonlinear Dimensionality Reduction via Tangent Space.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/14. LTSA/[Zhang.2004] Principal Manifolds and Nonlinear Dimensionality Reduction via Tangent Space.pdf:application/pdf}
}

@article{zhang_linear_2007,
	title = {Linear local tangent space alignment and application to face recognition},
	volume = {70},
	issn = {09252312},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231206004577},
	doi = {10.1016/j.neucom.2006.11.007},
	language = {en},
	number = {7-9},
	urldate = {2017-05-27},
	journal = {Neurocomputing},
	author = {Zhang, Tianhao and Yang, Jie and Zhao, Deli and Ge, Xinliang},
	month = mar,
	year = {2007},
	pages = {1547--1553},
	file = {[Zhang.2007] Linear local tangent space alignment and application to face recognition.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/09. LLTSA/[Zhang.2007] Linear local tangent space alignment and application to face recognition.pdf:application/pdf}
}

@article{achlioptas_database-friendly_2003,
	title = {Database-friendly random projections: {Johnson}-{Lindenstrauss} with binary coins},
	volume = {66},
	issn = {00220000},
	shorttitle = {Database-friendly random projections},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0022000003000254},
	doi = {10.1016/S0022-0000(03)00025-4},
	language = {en},
	number = {4},
	urldate = {2017-06-06},
	journal = {Journal of Computer and System Sciences},
	author = {Achlioptas, Dimitris},
	month = jun,
	year = {2003},
	pages = {671--687},
	file = {[Achlioptas.2003] Database-friendly random projections.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/04. RNDPROJ/[Achlioptas.2003] Database-friendly random projections.pdf:application/pdf}
}

@inproceedings{porte_introduction_2008,
	title = {An introduction to diffusion maps},
	booktitle = {In {The} 19th {Symposium} of the {Pattern} {Recognition} {Association} of {South} {Africa}},
	author = {Porte, J. De La and Herbst, B. M. and Hereman, W. and Walt, S. J. Van Der},
	year = {2008},
	file = {[Porte.2008] An introduction to diffusion maps.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/01. DM/[Porte.2008] An introduction to diffusion maps.pdf:application/pdf}
}

@inproceedings{nadler_diffusion_2005,
	address = {Cambridge, MA, USA},
	series = {{NIPS}'05},
	title = {Diffusion {Maps}, {Spectral} {Clustering} and {Eigenfunctions} of {Fokker}-{Planck} {Operators}},
	url = {http://dl.acm.org/citation.cfm?id=2976248.2976368},
	booktitle = {Proceedings of the 18th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Nadler, Boaz and Lafon, Stéphane and Coifman, Ronald R. and Kevrekidis, Ioannis G.},
	year = {2005},
	keywords = {algorithms and architectures, learning theory},
	pages = {955--962},
	file = {[Nadler.2005] Diffusion Maps, Spectral Clustering and Eigenfunctions of Fokker-Planck.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/01. DM/[Nadler.2005] Diffusion Maps, Spectral Clustering and Eigenfunctions of Fokker-Planck.pdf:application/pdf}
}

@article{paulovich_piece_2011,
	title = {Piece wise {Laplacian}-based {Projection} for {Interactive} {Data} {Exploration} and {Organization}},
	volume = {30},
	issn = {01677055},
	url = {http://doi.wiley.com/10.1111/j.1467-8659.2011.01958.x},
	doi = {10.1111/j.1467-8659.2011.01958.x},
	language = {en},
	number = {3},
	urldate = {2017-06-17},
	journal = {Computer Graphics Forum},
	author = {Paulovich, F.V. and Eler, D.M. and Poco, J. and Botha, C.P. and Minghim, R. and Nonato, L.G.},
	month = jun,
	year = {2011},
	pages = {1091--1100},
	file = {[Paulovich.2011] Piece wise Laplacian-based Projection for Interactive Data Exploration and.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/39. PLP/[Paulovich.2011] Piece wise Laplacian-based Projection for Interactive Data Exploration and.pdf:application/pdf}
}

@book{absil_optimization_2008,
	address = {Princeton, N.J. ; Woodstock},
	title = {Optimization algorithms on matrix manifolds},
	isbn = {978-0-691-13298-3},
	publisher = {Princeton University Press},
	author = {Absil, P.-A. and Mahony, R. and Sepulchre, R.},
	year = {2008},
	note = {OCLC: ocn174129993},
	keywords = {Algorithms, Matrices, Mathematical optimization},
	file = {[Absil.2008] Optimization algorithms on matrix manifolds.pdf:/home/kisung/Dropbox/V1. Pure Mathematics/P3. Geometry/S3. Matrix Manifolds/[Absil.2008] Optimization algorithms on matrix manifolds.pdf:application/pdf}
}

@article{chen_atomic_1998,
	title = {Atomic {Decomposition} by {Basis} {Pursuit}},
	volume = {20},
	issn = {1064-8275, 1095-7197},
	url = {http://epubs.siam.org/doi/10.1137/S1064827596304010},
	doi = {10.1137/S1064827596304010},
	language = {en},
	number = {1},
	urldate = {2017-07-01},
	journal = {SIAM Journal on Scientific Computing},
	author = {Chen, Scott Shaobing and Donoho, David L. and Saunders, Michael A.},
	month = jan,
	year = {1998},
	pages = {33--61},
	file = {[Chen.1998] Atomic Decomposition by Basis Pursuit.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P2. Numerical/S2. Sparsity/01. BP/[Chen.1998] Atomic Decomposition by Basis Pursuit.pdf:application/pdf}
}

@book{wright_primal-dual_1997,
	address = {Philadelphia},
	title = {Primal-dual interior-point methods},
	isbn = {978-0-89871-382-4},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Wright, Stephen J.},
	year = {1997},
	keywords = {Mathematical optimization, Interior-point methods, Linear programming},
	file = {[Wright.1997] Primal-dual interior-point methods.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P2. Numerical/S2. Sparsity/02. PD-IPM/[Wright.1997] Primal-dual interior-point methods.pdf:application/pdf}
}

@article{tillmann_equivalence_2015,
	title = {Equivalence of {Linear} {Programming} and {Basis} {Pursuit}: {Equivalence} of {LP} and {BP}},
	volume = {15},
	issn = {16177061},
	shorttitle = {Equivalence of {Linear} {Programming} and {Basis} {Pursuit}},
	url = {http://doi.wiley.com/10.1002/pamm.201510351},
	doi = {10.1002/pamm.201510351},
	language = {en},
	number = {1},
	urldate = {2017-07-01},
	journal = {PAMM},
	author = {Tillmann, Andreas M.},
	month = oct,
	year = {2015},
	pages = {735--738},
	file = {[Tillmann.2015] Equivalence of Linear Programming and Basis Pursuit.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P2. Numerical/S2. Sparsity/01. BP/[Tillmann.2015] Equivalence of Linear Programming and Basis Pursuit.pdf:application/pdf}
}

@article{jenssen_kernel_2010,
	title = {Kernel {Entropy} {Component} {Analysis}},
	volume = {32},
	issn = {0162-8828},
	url = {http://ieeexplore.ieee.org/document/4912217/},
	doi = {10.1109/TPAMI.2009.100},
	number = {5},
	urldate = {2017-11-11},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Jenssen, R.},
	month = may,
	year = {2010},
	pages = {847--860},
	file = {[Jenssen.2010] Kernel Entropy Component Analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/43. KECA/[Jenssen.2010] Kernel Entropy Component Analysis.pdf:application/pdf}
}

@book{hyvarinen_independent_2001,
	address = {New York},
	title = {Independent component analysis},
	isbn = {978-0-471-40540-5},
	publisher = {J. Wiley},
	author = {Hyvarinen, Aapo and Karhunen, Juha and Oja, Erkki},
	year = {2001},
	keywords = {Independent component analysis},
	file = {[Hyvarinen.2001] Independent component analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/01. ICA/[Hyvarinen.2001] Independent component analysis.pdf:application/pdf}
}

@article{fisher_use_1936,
	title = {{THE} {USE} {OF} {MULTIPLE} {MEASUREMENTS} {IN} {TAXONOMIC} {PROBLEMS}},
	volume = {7},
	issn = {20501420},
	url = {http://doi.wiley.com/10.1111/j.1469-1809.1936.tb02137.x},
	doi = {10.1111/j.1469-1809.1936.tb02137.x},
	language = {en},
	number = {2},
	urldate = {2017-11-11},
	journal = {Annals of Eugenics},
	author = {Fisher, R. A.},
	month = sep,
	year = {1936},
	pages = {179--188},
	file = {[Fisher.1936] THE USE OF MULTIPLE MEASUREMENTS IN TAXONOMIC PROBLEMS.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/06. LDA/[Fisher.1936] THE USE OF MULTIPLE MEASUREMENTS IN TAXONOMIC PROBLEMS.pdf:application/pdf}
}

@book{fukunaga_introduction_1990,
	address = {Boston},
	edition = {2nd ed},
	series = {Computer science and scientific computing},
	title = {Introduction to statistical pattern recognition},
	isbn = {978-0-12-269851-4},
	publisher = {Academic Press},
	author = {Fukunaga, Keinosuke},
	year = {1990},
	keywords = {Mathematical models, Mathematical statistics, Pattern perception, Decision making, Statistical methods},
	file = {[Fukunaga.1990] Introduction to statistical pattern recognition.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/06. LDA/[Fukunaga.1990] Introduction to statistical pattern recognition.pdf:application/pdf}
}

@inproceedings{li_very_2006,
	address = {New York, NY, USA},
	series = {{KDD} '06},
	title = {Very {Sparse} {Random} {Projections}},
	isbn = {1-59593-339-5},
	url = {http://doi.acm.org/10.1145/1150402.1150436},
	doi = {10.1145/1150402.1150436},
	booktitle = {Proceedings of the 12th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Li, Ping and Hastie, Trevor J. and Church, Kenneth W.},
	year = {2006},
	keywords = {random projections, rates of convergence, sampling},
	pages = {287--296},
	file = {[Li.2006] Very Sparse Random Projections.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/04. RNDPROJ/[Li.2006] Very Sparse Random Projections.pdf:application/pdf}
}

@incollection{silva_global_2003,
	title = {Global {Versus} {Local} {Methods} in {Nonlinear} {Dimensionality} {Reduction}},
	url = {http://papers.nips.cc/paper/2141-global-versus-local-methods-in-nonlinear-dimensionality-reduction.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 15},
	publisher = {MIT Press},
	author = {Silva, Vin D. and Tenenbaum, Joshua B.},
	editor = {Becker, S. and Thrun, S. and Obermayer, K.},
	year = {2003},
	pages = {721--728},
	file = {[Silva_Tenenbaum.2003] Global Versus Local Methods in Nonlinear Dimensionality Reduction.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/05. LLE/[Silva_Tenenbaum.2003] Global Versus Local Methods in Nonlinear Dimensionality Reduction.pdf:application/pdf}
}

@techreport{wagner_comparing_2007,
	title = {Comparing {Clusterings} – {An} {Overview}},
	url = {http://digbib.ubka.uni-karlsruhe.de/volltexte/1000011477},
	number = {2006-04},
	institution = {Department of Informatics},
	author = {Wagner, Silke and Wagner, Dorothea},
	year = {2007},
	file = {[Wagner_Wagner.2007] Comparing Clusterings – An Overview.pdf:/home/kisung/Dropbox/V3. Statistics/P6. ML/S1. Additional Topics/1. Clustering Comparison/[Wagner_Wagner.2007] Comparing Clusterings – An Overview.pdf:application/pdf}
}

@inproceedings{cayton_robust_2006,
	address = {New York, NY, USA},
	series = {{ICML} '06},
	title = {Robust {Euclidean} {Embedding}},
	isbn = {1-59593-383-2},
	url = {http://doi.acm.org/10.1145/1143844.1143866},
	doi = {10.1145/1143844.1143866},
	booktitle = {Proceedings of the 23rd {International} {Conference} on {Machine} {Learning}},
	publisher = {ACM},
	author = {Cayton, Lawrence and Dasgupta, Sanjoy},
	year = {2006},
	pages = {169--176},
	file = {[Cayton_Dasgupta.2006] Robust Euclidean Embedding.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/27. REE/[Cayton_Dasgupta.2006] Robust Euclidean Embedding.pdf:application/pdf}
}

@inproceedings{walder_diffeomorphic_2009,
	address = {Red Hook, NY, USA},
	title = {Diffeomorphic {Dimensionality} {Reduction}},
	booktitle = {Advances in neural information processing systems 21},
	publisher = {Biologische Kybernetik},
	author = {Walder, C. and Schölkopf, B.},
	month = jun,
	year = {2009},
	pages = {1713--1720},
	file = {[Walder_Schölkopf.2009] Diffeomorphic Dimensionality Reduction.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/04. DDR/[Walder_Schölkopf.2009] Diffeomorphic Dimensionality Reduction.pdf:application/pdf}
}

@inproceedings{hammond_graph_2013,
	address = {Austin, Texas},
	title = {Graph {Diffusion} {Distance}: {A} {Difference} {Measure} for {Weighted} {Graphs} {Based} on the {Graph} {Laplacian} {Exponential} {Kernel}},
	url = {http://www.sci.utah.edu/publications/hammond13/Hammond_GlobalSIP2013.pdf},
	doi = {10.1109/GlobalSIP.2013.6736904},
	booktitle = {Proceedings of the {IEEE} global conference on information and signal processing ({GlobalSIP}'13)},
	author = {Hammond, D. K. and Gur, Y. and Johnson, C. R.},
	year = {2013},
	pages = {419--422},
	file = {[Hammond.2013] Graph Diffusion Distance.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P3. SGT/Topics/[Hammond.2013] Graph Diffusion Distance.pdf:application/pdf}
}

@inproceedings{boser_training_1992,
	address = {New York, NY, USA},
	series = {{COLT} '92},
	title = {A {Training} {Algorithm} for {Optimal} {Margin} {Classifiers}},
	isbn = {0-89791-497-X},
	url = {http://doi.acm.org/10.1145/130385.130401},
	doi = {10.1145/130385.130401},
	booktitle = {Proceedings of the {Fifth} {Annual} {Workshop} on {Computational} {Learning} {Theory}},
	publisher = {ACM},
	author = {Boser, Bernhard E. and Guyon, Isabelle M. and Vapnik, Vladimir N.},
	year = {1992},
	pages = {144--152},
	file = {[Boser.1992] A Training Algorithm for Optimal Margin Classifiers.pdf:/home/kisung/Dropbox/V3. Statistics/P6. ML/S2. Tools_Supervised/[Boser.1992] A Training Algorithm for Optimal Margin Classifiers.pdf:application/pdf}
}

@article{cha_vision-based_2016,
	title = {Vision-based detection of loosened bolts using the {Hough} transform and support vector machines},
	volume = {71},
	issn = {09265805},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0926580516301297},
	doi = {10.1016/j.autcon.2016.06.008},
	language = {en},
	urldate = {2017-11-20},
	journal = {Automation in Construction},
	author = {Cha, Young-Jin and You, Kisung and Choi, Wooram},
	month = nov,
	year = {2016},
	pages = {181--188},
	file = {[Cha.2016] Vision-based detection of loosened bolts using the Hough transform and support.pdf:/home/kisung/Dropbox/VR. Research/01. Bolts/[Cha.2016] Vision-based detection of loosened bolts using the Hough transform and support.pdf:application/pdf}
}

@article{vershynin_four_2016,
	title = {Four lectures on probabilistic methods for data science},
	journal = {ArXiv e-prints},
	author = {Vershynin, R.},
	month = dec,
	year = {2016},
	keywords = {Mathematics - Statistics Theory, 60-01, 60B20, 60E15, 62-01, 62Fxx, 65-01, 65Cxx, Computer Science - Data Structures and Algorithms, Computer Science - Information Theory, Mathematics - Probability},
	file = {[Vershynin.2016] Four lectures on probabilistic methods for data science.pdf:/home/kisung/Dropbox/V3. Statistics/P9. Asymptotics/[Vershynin.2016] Four lectures on probabilistic methods for data science.pdf:application/pdf}
}

@incollection{choi_remarks_2008,
	address = {Beachwood, Ohio, USA},
	title = {Remarks on consistency of posterior distributions},
	isbn = {978-0-940600-75-1},
	url = {http://projecteuclid.org/euclid.imsc/1209398468},
	language = {en},
	urldate = {2017-11-20},
	booktitle = {Institute of {Mathematical} {Statistics} {Collections}},
	publisher = {Institute of Mathematical Statistics},
	author = {Choi, Taeryon and Ramamoorthi, R. V.},
	year = {2008},
	note = {DOI: 10.1214/074921708000000138},
	pages = {170--186},
	file = {[Choi_Ramamoorthi.2008] Remarks on consistency of posterior distributions.pdf:/home/kisung/Dropbox/V3. Statistics/P1. Bayesian/S6. Theory-Nonparametrics/[Choi_Ramamoorthi.2008] Remarks on consistency of posterior distributions.pdf:application/pdf}
}

@article{tropp_introduction_2015,
	title = {An {Introduction} to {Matrix} {Concentration} {Inequalities}},
	volume = {8},
	issn = {1935-8237, 1935-8245},
	url = {http://www.nowpublishers.com/article/Details/MAL-048},
	doi = {10.1561/2200000048},
	language = {en},
	number = {1-2},
	urldate = {2017-11-20},
	journal = {Foundations and Trends® in Machine Learning},
	author = {Tropp, Joel A.},
	year = {2015},
	pages = {1--230},
	file = {[Tropp.2015] An Introduction to Matrix Concentration Inequalities.pdf:/home/kisung/Dropbox/V1. Pure Mathematics/P2. Linear Algebra/S2. Matrix Inequalities/[Tropp.2015] An Introduction to Matrix Concentration Inequalities.pdf:application/pdf}
}

@article{edelman_random_2005,
	title = {Random matrix theory},
	volume = {14},
	issn = {0962-4929, 1474-0508},
	url = {http://www.journals.cambridge.org/abstract_S0962492904000236},
	doi = {10.1017/S0962492904000236},
	language = {en},
	urldate = {2017-11-20},
	journal = {Acta Numerica},
	author = {Edelman, Alan and Rao, N. Raj},
	month = may,
	year = {2005},
	pages = {233--297},
	file = {[Edelman_Rao.2005] Random matrix theory.pdf:/home/kisung/Dropbox/V1. Pure Mathematics/P2. Linear Algebra/S3. RMT/[Edelman_Rao.2005] Random matrix theory.pdf:application/pdf}
}

@article{mackey_matrix_2014,
	title = {Matrix concentration inequalities via the method of exchangeable pairs},
	volume = {42},
	issn = {0091-1798},
	url = {http://projecteuclid.org/euclid.aop/1395838119},
	doi = {10.1214/13-AOP892},
	language = {en},
	number = {3},
	urldate = {2017-11-20},
	journal = {The Annals of Probability},
	author = {Mackey, Lester and Jordan, Michael I. and Chen, Richard Y. and Farrell, Brendan and Tropp, Joel A.},
	month = may,
	year = {2014},
	pages = {906--945},
	file = {[Mackey.2014] Matrix concentration inequalities via the method of exchangeable pairs.pdf:/home/kisung/Dropbox/V1. Pure Mathematics/P2. Linear Algebra/S2. Matrix Inequalities/[Mackey.2014] Matrix concentration inequalities via the method of exchangeable pairs.pdf:application/pdf}
}

@article{borchers_sdplib_1999,
	title = {{SDPLIB} 1.2, a library of semidefinite programming test problems},
	volume = {11},
	issn = {1055-6788, 1029-4937},
	url = {http://www.tandfonline.com/doi/abs/10.1080/10556789908805769},
	doi = {10.1080/10556789908805769},
	language = {en},
	number = {1-4},
	urldate = {2017-11-20},
	journal = {Optimization Methods and Software},
	author = {Borchers, Brian},
	month = jan,
	year = {1999},
	pages = {683--690},
	file = {[Borchers.1999] SDPLIB 1.pdf:/home/kisung/Dropbox/V2. Applied Mathematics/P5. Optimization/S1. SDP/[Borchers.1999] SDPLIB 1.pdf:application/pdf}
}

@article{noonan_nipals_1977,
	title = {{NIPALS} {Path} {Modelling} with {Latent} {Variables}: {Analysing} {School} {Survey} {Data} {Using} {Nonlinear} {Iterative} {Partial} {Least} {Squares} $^{\textrm{1}}$},
	volume = {21},
	issn = {0031-3831, 1470-1170},
	shorttitle = {{NIPALS} {Path} {Modelling} with {Latent} {Variables}},
	url = {http://www.tandfonline.com/doi/full/10.1080/0031383770210103},
	doi = {10.1080/0031383770210103},
	language = {en},
	number = {1},
	urldate = {2017-11-21},
	journal = {Scandinavian Journal of Educational Research},
	author = {Noonan, Richard and Wold, Herman},
	month = jan,
	year = {1977},
	pages = {33--61}
}

@incollection{wold_path_1975,
	title = {Path {Models} with {Latent} {Variables}: {The} {NIPALS} {Approach}},
	isbn = {978-0-12-103950-9},
	shorttitle = {Path {Models} with {Latent} {Variables}},
	url = {http://linkinghub.elsevier.com/retrieve/pii/B9780121039509500174},
	language = {en},
	urldate = {2017-11-21},
	booktitle = {Quantitative {Sociology}},
	publisher = {Elsevier},
	author = {Wold, Herman},
	year = {1975},
	note = {DOI: 10.1016/B978-0-12-103950-9.50017-4},
	pages = {307--357},
	annote = {PLS Initialization}
}

@incollection{rosipal_overview_2006,
	address = {Berlin, Heidelberg},
	title = {Overview and {Recent} {Advances} in {Partial} {Least} {Squares}},
	isbn = {978-3-540-34138-3},
	url = {https://doi.org/10.1007/11752790_2},
	abstract = {Partial Least Squares (PLS) is a wide class of methods for modeling relations between sets of observed variables by means of latent variables. It comprises of regression and classification tasks as well as dimension reduction techniques and modeling tools. The underlying assumption of all PLS methods is that the observed data is generated by a system or process which is driven by a small number of latent (not directly observed or measured) variables. Projections of the observed data to its latent structure by means of PLS was developed by Herman Wold and coworkers [48,49,52].},
	booktitle = {Subspace, {Latent} {Structure} and {Feature} {Selection}: {Statistical} and {Optimization} {Perspectives} {Workshop}, {SLSFS} 2005, {Bohinj}, {Slovenia}, {February} 23-25, 2005, {Revised} {Selected} {Papers}},
	publisher = {Springer Berlin Heidelberg},
	author = {Rosipal, Roman and Krämer, Nicole},
	editor = {Saunders, Craig and Grobelnik, Marko and Gunn, Steve and Shawe-Taylor, John},
	year = {2006},
	note = {DOI: 10.1007/11752790\_2},
	pages = {34--51},
	file = {[Rosipal_Krämer.2006] Overview and Recent Advances in Partial Least Squares.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/13. PLS/[Rosipal_Krämer.2006] Overview and Recent Advances in Partial Least Squares.pdf:application/pdf}
}

@book{borga_unified_1997,
	address = {Linköping, Sweden},
	title = {A {Unified} {Approach} to {PCA}, {PLS}, {MLR} and {CCA}},
	isbn = {9925-7521-8-3},
	publisher = {Linköping University, Department of Electrical Engineering},
	author = {Borga, Magnus and Landelius, Tomas and Knutsson, Hans},
	year = {1997},
	annote = {Cunnigham's survey paper should have referred to this one.
 },
	file = {[Borga.1997] A Unified Approach to PCA, PLS, MLR and CCA.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/[Borga.1997] A Unified Approach to PCA, PLS, MLR and CCA.pdf:application/pdf}
}

@article{hotelling_relations_1936,
	title = {{RELATIONS} {BETWEEN} {TWO} {SETS} {OF} {VARIATES}},
	volume = {28},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/28.3-4.321},
	doi = {10.1093/biomet/28.3-4.321},
	language = {en},
	number = {3-4},
	urldate = {2017-11-21},
	journal = {Biometrika},
	author = {Hotelling, H.},
	month = dec,
	year = {1936},
	pages = {321--377},
	annote = {Introducing CCA},
	file = {[Hotelling.1936] RELATIONS BETWEEN TWO SETS OF VARIATES.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/13. PLS/[Hotelling.1936] RELATIONS BETWEEN TWO SETS OF VARIATES.pdf:application/pdf}
}

@article{barker_partial_2003,
	title = {Partial least squares for discrimination},
	volume = {17},
	issn = {0886-9383, 1099-128X},
	url = {http://doi.wiley.com/10.1002/cem.785},
	doi = {10.1002/cem.785},
	language = {en},
	number = {3},
	urldate = {2017-11-21},
	journal = {Journal of Chemometrics},
	author = {Barker, Matthew and Rayens, William},
	month = mar,
	year = {2003},
	pages = {166--173},
	annote = {Orthogonal PLS (OPLS)
This paper is known as its alias; Semipenalized CCA},
	file = {[Barker_Rayens.2003] Partial least squares for discrimination.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/13. PLS/[Barker_Rayens.2003] Partial least squares for discrimination.pdf:application/pdf}
}

@article{cai_orthogonal_2006,
	title = {Orthogonal {Laplacianfaces} for {Face} {Recognition}},
	volume = {15},
	issn = {1057-7149},
	url = {http://ieeexplore.ieee.org/document/1710004/},
	doi = {10.1109/TIP.2006.881945},
	number = {11},
	urldate = {2017-11-21},
	journal = {IEEE Transactions on Image Processing},
	author = {Cai, D. and He, X. and Han, J. and Zhang, H.-J.},
	month = nov,
	year = {2006},
	pages = {3608--3614},
	file = {[Cai.2006] Orthogonal Laplacianfaces for Face Recognition.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/14. OLPP/[Cai.2006] Orthogonal Laplacianfaces for Face Recognition.pdf:application/pdf}
}

@inproceedings{cai_isometric_2007,
	address = {Vancouver, British Columbia, Canada},
	series = {{AAAI}'07},
	title = {Isometric {Projection}},
	isbn = {978-1-57735-323-2},
	url = {http://dl.acm.org/citation.cfm?id=1619645.1619730},
	booktitle = {Proceedings of the 22Nd {National} {Conference} on {Artificial} {Intelligence} - {Volume} 1},
	publisher = {AAAI Press},
	author = {Cai, Deng and He, Xiaofei and Han, Jiawei},
	year = {2007},
	pages = {528--533},
	file = {[Cai.2007] Isometric Projection.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/15. ISOPROJ/[Cai.2007] Isometric Projection.pdf:application/pdf}
}

@article{xiaofei_he_learning_2008,
	title = {Learning a {Maximum} {Margin} {Subspace} for {Image} {Retrieval}},
	volume = {20},
	issn = {1041-4347},
	url = {http://ieeexplore.ieee.org/document/4358969/},
	doi = {10.1109/TKDE.2007.190692},
	number = {2},
	urldate = {2017-11-21},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {{Xiaofei He} and {Deng Cai} and {Jiawei Han}},
	month = feb,
	year = {2008},
	pages = {189--201},
	file = {[Xiaofei He.2008] Learning a Maximum Margin Subspace for Image Retrieval.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/16. MMP/[Xiaofei He.2008] Learning a Maximum Margin Subspace for Image Retrieval.pdf:application/pdf}
}

@inproceedings{cai_locality_2007,
	address = {San Francisco, CA, USA},
	series = {{IJCAI}'07},
	title = {Locality {Sensitive} {Discriminant} {Analysis}},
	url = {http://dl.acm.org/citation.cfm?id=1625275.1625389},
	booktitle = {Proceedings of the 20th {International} {Joint} {Conference} on {Artifical} {Intelligence}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Cai, Deng and He, Xiaofei and Zhou, Kun and Han, Jiawei and Bao, Hujun},
	year = {2007},
	pages = {708--713},
	file = {[Cai.2007] Locality Sensitive Discriminant Analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/17. LSDA/[Cai.2007] Locality Sensitive Discriminant Analysis.pdf:application/pdf}
}

@article{zou_sparse_2006,
	title = {Sparse {Principal} {Component} {Analysis}},
	volume = {15},
	issn = {1061-8600, 1537-2715},
	url = {http://www.tandfonline.com/doi/abs/10.1198/106186006X113430},
	doi = {10.1198/106186006X113430},
	language = {en},
	number = {2},
	urldate = {2017-11-26},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Zou, Hui and Hastie, Trevor and Tibshirani, Robert},
	month = jun,
	year = {2006},
	pages = {265--286},
	annote = {Original Paper on SPCA},
	file = {[Zou.2006] Sparse Principal Component Analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/18. SPCA/[Zou.2006] Sparse Principal Component Analysis.pdf:application/pdf}
}

@article{daspremont_direct_2007,
	title = {A {Direct} {Formulation} for {Sparse} {PCA} {Using} {Semidefinite} {Programming}},
	volume = {49},
	issn = {0036-1445, 1095-7200},
	url = {http://epubs.siam.org/doi/10.1137/050645506},
	doi = {10.1137/050645506},
	language = {en},
	number = {3},
	urldate = {2017-11-26},
	journal = {SIAM Review},
	author = {d'Aspremont, Alexandre and El Ghaoui, Laurent and Jordan, Michael I. and Lanckriet, Gert R. G.},
	month = jan,
	year = {2007},
	pages = {434--448},
	annote = {SDP Relaxation of SPCA},
	file = {[d'Aspremont.2007] A Direct Formulation for Sparse PCA Using Semidefinite Programming.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/18. SPCA/[d'Aspremont.2007] A Direct Formulation for Sparse PCA Using Semidefinite Programming.pdf:application/pdf}
}

@article{wang_survey_2015,
	title = {Survey on distance metric learning and dimensionality reduction in data mining},
	volume = {29},
	issn = {1384-5810, 1573-756X},
	url = {http://link.springer.com/10.1007/s10618-014-0356-z},
	doi = {10.1007/s10618-014-0356-z},
	language = {en},
	number = {2},
	urldate = {2017-11-27},
	journal = {Data Mining and Knowledge Discovery},
	author = {Wang, Fei and Sun, Jimeng},
	month = mar,
	year = {2015},
	pages = {534--564},
	file = {[Wang_Sun.2015] Survey on distance metric learning and dimensionality reduction in data mining.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S3. Notes/7. metric learning/[Wang_Sun.2015] Survey on distance metric learning and dimensionality reduction in data mining.pdf:application/pdf}
}

@inproceedings{goldberger_neighbourhood_2004,
	title = {Neighbourhood components analysis},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 17},
	publisher = {MIT Press},
	author = {Goldberger, Jacob and Roweis, Sam and Hinton, Geoff and Salakhutdinov, Ruslan},
	year = {2004},
	pages = {513--520},
	file = {[Goldberger.2004] Neighbourhood components analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/19. NCA/[Goldberger.2004] Neighbourhood components analysis.pdf:application/pdf}
}

@inproceedings{wang_feature_2007,
	title = {Feature {Extraction} by {Maximizing} the {Average} {Neighborhood} {Margin}},
	doi = {10.1109/CVPR.2007.383124},
	booktitle = {2007 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Wang, F. and Zhang, C.},
	month = jun,
	year = {2007},
	keywords = {Data mining, ANMM, average neighborhood margin maximization, computer vision, Computer vision, Covariance matrix, face recognition, feature extraction, Feature extraction, Kernel, linear discriminant analysis, Linear discriminant analysis, optimisation, Pattern recognition, Principal component analysis, Scattering, supervised linear feature extraction, Tensile stress},
	pages = {1--8},
	file = {[Wang_Zhang.2007] Feature Extraction by Maximizing the Average Neighborhood Margin.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S1. Linear/20. ANMM/[Wang_Zhang.2007] Feature Extraction by Maximizing the Average Neighborhood Margin.pdf:application/pdf}
}

@inproceedings{shaw_minimum_2007,
	title = {Minimum {Volume} {Embedding}},
	volume = {2 of JMLR: W\&CP},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Artificial} {Intelligence} and {Statistics} {March} 21-24, 2007, {San} {Juan}, {Puerto} {Rico}},
	author = {Shaw, B. and Jebara, T.},
	editor = {Meila, Marina and Shen, Xiaotong},
	month = mar,
	year = {2007},
	pages = {460--467},
	file = {[Shaw_Jebara.2007] Minimum Volume Embedding.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/50. MVE/[Shaw_Jebara.2007] Minimum Volume Embedding.pdf:application/pdf}
}

@article{bickel_covariance_2008,
	title = {Covariance regularization by thresholding},
	volume = {36},
	issn = {0090-5364},
	url = {http://projecteuclid.org/euclid.aos/1231165180},
	doi = {10.1214/08-AOS600},
	language = {en},
	number = {6},
	urldate = {2017-12-01},
	journal = {The Annals of Statistics},
	author = {Bickel, Peter J. and Levina, Elizaveta},
	month = dec,
	year = {2008},
	pages = {2577--2604},
	file = {[Bickel_Levina.2008] Covariance regularization by thresholding.pdf:/home/kisung/Dropbox/V3. Statistics/P2. Covariance/S1. CovEst/[Bickel_Levina.2008] Covariance regularization by thresholding.pdf:application/pdf}
}

@article{fan_overview_2016,
	title = {An overview of the estimation of large covariance and precision matrices: {Large} covariance estimation},
	volume = {19},
	issn = {13684221},
	shorttitle = {An overview of the estimation of large covariance and precision matrices},
	url = {http://doi.wiley.com/10.1111/ectj.12061},
	doi = {10.1111/ectj.12061},
	language = {en},
	number = {1},
	urldate = {2017-12-01},
	journal = {The Econometrics Journal},
	author = {Fan, Jianqing and Liao, Yuan and Liu, Han},
	month = feb,
	year = {2016},
	pages = {C1--C32},
	file = {[Fan.2016] An overview of the estimation of large covariance and precision matrices.pdf:/home/kisung/Dropbox/V3. Statistics/P2. Covariance/[Fan.2016] An overview of the estimation of large covariance and precision matrices.pdf:application/pdf}
}

@article{arenas-garcia_kernel_2013,
	title = {Kernel {Multivariate} {Analysis} {Framework} for {Supervised} {Subspace} {Learning}: {A} {Tutorial} on {Linear} and {Kernel} {Multivariate} {Methods}},
	volume = {30},
	issn = {1053-5888},
	shorttitle = {Kernel {Multivariate} {Analysis} {Framework} for {Supervised} {Subspace} {Learning}},
	url = {http://ieeexplore.ieee.org/document/6530763/},
	doi = {10.1109/MSP.2013.2250591},
	number = {4},
	urldate = {2017-12-01},
	journal = {IEEE Signal Processing Magazine},
	author = {Arenas-Garcia, Jeronimo and Petersen, Kaare Brandt and Camps-Valls, Gustavo and Hansen, Lars Kai},
	month = jul,
	year = {2013},
	pages = {16--29},
	file = {[Arenas-Garcia.2013] Kernel Multivariate Analysis Framework for Supervised Subspace Learning.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/17. kMVA/[Arenas-Garcia.2013] Kernel Multivariate Analysis Framework for Supervised Subspace Learning.pdf:application/pdf}
}

@article{tipping_probabilistic_1999,
	title = {Probabilistic {Principal} {Component} {Analysis}},
	volume = {61},
	issn = {1369-7412, 1467-9868},
	url = {http://doi.wiley.com/10.1111/1467-9868.00196},
	doi = {10.1111/1467-9868.00196},
	language = {en},
	number = {3},
	urldate = {2017-12-01},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Tipping, Michael E. and Bishop, Christopher M.},
	month = aug,
	year = {1999},
	pages = {611--622},
	file = {[Tipping_Bishop.1999] Probabilistic Principal Component Analysis.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/08. PPCA+BPCA/[Tipping_Bishop.1999] Probabilistic Principal Component Analysis.pdf:application/pdf}
}

@incollection{lawrence_gaussian_2003,
	address = {Cambridge, MA},
	title = {Gaussian {Process} {Latent} {Variable} {Models} for {Visualisation} of {High} {Dimensional} {Data}},
	url = {http://books.nips.cc/papers/files/nips16/NIPS2003_AA42.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 16},
	publisher = {MIT Press},
	author = {Lawrence, Neil D.},
	editor = {Thrun, Sebastian and Saul, Lawrence and Schölkopf, Bernhard},
	year = {2003},
	keywords = {Gaussian processes, kernel methods, kernel PCA, PCA, visualisation},
	pages = {None},
	file = {[Lawrence.2003] Gaussian Process Latent Variable Models for Visualisation of High Dimensional.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/08. PPCA+GPLVM/[Lawrence.2003] Gaussian Process Latent Variable Models for Visualisation of High Dimensional.pdf:application/pdf}
}

@inproceedings{bishop_bayesian_1999,
	title = {Bayesian {PCA}},
	volume = {11},
	url = {https://www.microsoft.com/en-us/research/publication/bayesian-pca/},
	abstract = {The technique of principal component analysis (PCA) has recently been expressed as the maximum likelihood solution for a generative latent variable model. In this paper we use this probabilistic reformulation as the basis for a Bayesian treatment of PCA. Our key result is that effective dimensionality of the latent space (equivalent to the number of retained principal components) can be determined automatically as part of the Bayesian inference procedure. An important application of this framework is to mixtures of probabilistic PCA models, in which each component can determine its own effective complexity.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Bishop, Christopher},
	month = jan,
	year = {1999},
	pages = {382--388},
	file = {[Bishop.1999] Bayesian PCA.pdf:/home/kisung/Dropbox/V3. Statistics/P3. Dimension Reduction/S2. Nonlinear/08. PPCA+BPCA/[Bishop.1999] Bayesian PCA.pdf:application/pdf}
}

@incollection{bishop_bayesian_1999-1,
	title = {Bayesian {PCA}},
	url = {http://papers.nips.cc/paper/1549-bayesian-pca.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 11},
	publisher = {MIT Press},
	author = {Bishop, Christopher M.},
	editor = {Kearns, M. J. and Solla, S. A. and Cohn, D. A.},
	year = {1999},
	pages = {382--388}
}